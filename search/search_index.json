{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#flowerpower-data-pipeline-orchestration","title":"FlowerPower: Data Pipeline Orchestration","text":"<p>Welcome to the official documentation for FlowerPower, a powerful Python library designed to help you build, configure, schedule, and execute data processing pipelines with ease.</p> <p> </p> <p>FlowerPower streamlines complex data workflows by integrating the modularity of Hamilton for pipeline logic with optional job scheduling capabilities.</p>"},{"location":"#get-started","title":"Get Started","text":"<p>Ready to dive in? Our Quickstart Guide will walk you through installing FlowerPower and running your first pipeline in just a few minutes.</p>"},{"location":"#core-concepts","title":"Core Concepts","text":"<p>FlowerPower is built around a few key concepts that make it both powerful and flexible:</p> <ul> <li>Modular Pipeline Design: Define your data transformations as a collection of simple Python functions. FlowerPower, using Hamilton, automatically understands their dependencies and assembles them into a Directed Acyclic Graph (DAG).</li> <li>Configuration-Driven: Separate your pipeline logic from its execution parameters. Environments, data sources, and pipeline settings are all managed through clear and simple YAML files.<ul> <li>Precedence (highest wins): runtime kwargs/RunConfig &gt; env overlays (<code>FP_PIPELINE__*</code>, <code>FP_PROJECT__*</code>) &gt; YAML (after <code>${VAR}</code> interpolation) &gt; global shims (<code>FP_LOG_LEVEL</code>, <code>FP_EXECUTOR</code>, \u2026) &gt; code defaults.</li> <li>YAML supports Docker Compose\u2013style env interpolation: <code>${VAR}</code>, <code>${VAR:-default}</code>, <code>${VAR?err}</code>; JSON values are coerced when valid.</li> </ul> </li> <li>Configurable Pipeline Scheduling: Define scheduling parameters for pipelines via configuration files. FlowerPower supports configuring job scheduling options, but runtime scheduling is not yet implemented.</li> <li>Unified Project Interface: Interact with your pipelines through the method that suits you best\u2014a Python API (<code>FlowerPowerProject</code>), a command-line interface (CLI), or a web-based UI for visualization and monitoring.</li> <li>Extensible I/O: Easily read from and write to various data sources with built-in and custom I/O plugins, ensuring your pipelines can connect to any data, anywhere.</li> </ul> <p>A Note on Hamilton</p> <p>FlowerPower acts as an orchestrator, not a replacement. You will still write your pipeline logic using Hamilton's function-based syntax. FlowerPower's role is to provide a structured project environment and simplify pipeline management.</p>"},{"location":"advanced/","title":"Advanced Usage","text":""},{"location":"advanced/#advanced-usage","title":"Advanced Usage","text":"<p>Welcome to the advanced usage guide for FlowerPower. This document covers more complex configurations and use cases to help you get the most out of the library.</p>"},{"location":"advanced/#configuration-flexibility","title":"Configuration Flexibility","text":"<p>FlowerPower offers multiple ways to configure your project, ensuring flexibility for different environments and workflows. Configuration is applied in this order (highest wins):</p> <ol> <li>Runtime kwargs / RunConfig (programmatic overrides at execution time)</li> <li>Environment overlays via <code>FP_PIPELINE__*</code> / <code>FP_PROJECT__*</code> variables</li> <li>YAML files after env interpolation (<code>${VAR}</code>, <code>${VAR:-default}</code>, etc.)</li> <li>Global env shims like <code>FP_LOG_LEVEL</code>, <code>FP_EXECUTOR</code>, etc. (applied only if more specific keys not set)</li> <li>Code defaults (struct defaults)</li> </ol>"},{"location":"advanced/#programmatic-configuration-recommended","title":"Programmatic Configuration (recommended)","text":"<p>Use <code>RunConfig</code> or kwargs when executing to override YAML/env at runtime.</p> <pre><code>from flowerpower.pipeline import PipelineManager\nfrom flowerpower.cfg.pipeline.run import RunConfig\n\npm = PipelineManager()\ncfg = RunConfig(\n    inputs={\"input_data\": \"path/to/data.csv\"},\n    log_level=\"DEBUG\",\n)\nresult = pm.run(\"sales_etl\", run_config=cfg)\n\n# or with kwargs (overrides RunConfig fields)\nresult = pm.run(\n    \"sales_etl\",\n    inputs={\"input_data\": \"path/to/other.csv\"},\n    log_level=\"INFO\",\n)\n</code></pre>"},{"location":"advanced/#environment-variable-overlays","title":"Environment Variable Overlays","text":"<p>You can set typed, nested overrides using double-underscore paths:</p> <ul> <li><code>FP_PIPELINE__RUN__LOG_LEVEL=DEBUG</code></li> <li><code>FP_PIPELINE__RUN__EXECUTOR__TYPE=threadpool</code></li> <li><code>FP_PROJECT__ADAPTER__HAMILTON_TRACKER__API_KEY=...</code></li> </ul> <p>Global shims still work and are applied only if pipeline/project-specific keys are not set:</p> <ul> <li><code>FP_LOG_LEVEL=INFO</code></li> <li><code>FP_EXECUTOR=threadpool</code>, <code>FP_EXECUTOR_MAX_WORKERS=8</code>, <code>FP_EXECUTOR_NUM_CPUS=4</code></li> <li><code>FP_MAX_RETRIES=3</code>, <code>FP_RETRY_DELAY=2.0</code>, <code>FP_JITTER_FACTOR=0.2</code></li> </ul> <p>Values are strictly coerced (bool/int/float) and JSON is supported for objects/lists.</p>"},{"location":"advanced/#yaml-environment-interpolation","title":"YAML Environment Interpolation","text":"<p>YAML supports Docker Compose\u2013style expansion inside values. Examples:</p> <pre><code>run:\n  log_level: ${FP_LOG_LEVEL:-INFO}\n  executor: ${FP_PIPELINE__RUN__EXECUTOR:-{\"type\":\"synchronous\"}}\nadapter:\n  hamilton_tracker:\n    api_key: ${HAMILTON_API_KEY:?Missing tracker key}\nparams:\n  data_path: ${DATA_PATH:-data/input.csv}\n</code></pre> <p>Supported forms: <code>${VAR}</code>, <code>${VAR:-default}</code> (unset or empty), <code>${VAR-default}</code> (unset), <code>${VAR:?err}</code> / <code>${VAR?err}</code> (require), <code>$${...}</code> escapes <code>$</code>. If the expanded value is valid JSON, it becomes a typed object/list/number/bool/null.</p>"},{"location":"advanced/#direct-module-usage","title":"Direct Module Usage","text":"<p>For fine-grained control, you can work directly with <code>PipelineManager</code>.</p>"},{"location":"advanced/#pipelinemanager","title":"<code>PipelineManager</code>","text":"<p>The <code>PipelineManager</code> is responsible for loading, validating, and executing data pipelines.</p> <pre><code>from flowerpower.pipeline import PipelineManager\nfrom flowerpower.cfg.pipeline.run import RunConfig\n\n# Initialize the manager\npipeline_manager = PipelineManager()\n\n# Access the registry to load a specific pipeline\npipeline = pipeline_manager.registry.get_pipeline(\"sales_etl\")\n\n# Execute the pipeline with RunConfig\nresult = pipeline.run(run_config=RunConfig(inputs={\"input_data\": \"path/to/data.csv\"}))\nprint(result)\n</code></pre>"},{"location":"advanced/#hooks","title":"Hooks","text":"<p>Hooks allow you to inject custom logic at specific points in the pipeline lifecycle, such as pre-execution validation or post-execution logging.</p>"},{"location":"advanced/#adding-hooks","title":"Adding Hooks","text":"<p>Use the <code>add_hook</code> method in the PipelineRegistry to add hooks to your pipeline.</p> <pre><code>from flowerpower.pipeline import PipelineManager\nfrom flowerpower.pipeline.hooks import HookType\n\nmanager = PipelineManager()\n\nmanager.registry.add_hook(\n    name=\"my_pipeline\",\n    type=HookType.MQTT_BUILD_CONFIG,\n    to=None,  # Defaults to hooks/my_pipeline/hook.py\n    function_name=\"build_mqtt_config\"  # Optional; defaults to type value\n)\n</code></pre> <p>This appends a template function to the hook file. Customize the function in <code>hooks/my_pipeline/hook.py</code> to implement your logic, e.g., for MQTT config building.</p> <p>Hooks are executed automatically during pipeline runs based on their type.</p>"},{"location":"advanced/#adapters","title":"Adapters","text":"<p>Integrate with popular MLOps and observability tools using adapters.</p> <ul> <li>Hamilton Tracker: For dataflow and lineage tracking.</li> <li>MLflow: For experiment tracking.</li> <li>OpenTelemetry: For distributed tracing and metrics.</li> </ul>"},{"location":"advanced/#filesystem-abstraction","title":"Filesystem Abstraction","text":"<p>FlowerPower uses the library <code>fsspeckit</code> to provide a unified interface for interacting with different filesystems, including local storage, S3, and GCS. This allows you to switch between storage backends without changing your code.</p>"},{"location":"advanced/#security","title":"Security","text":"<p>FlowerPower includes built-in security features to prevent common vulnerabilities, such as directory traversal attacks. All file paths provided to configuration loaders and filesystem utilities are validated to ensure they are within the project's base directory.</p> <pre><code>from flowerpower.utils.security import validate_file_path\n\n# This will pass\nvalidate_file_path(\"my/safe/path.yml\")\n\n# This will raise a ConfigPathError\ntry:\n    validate_file_path(\"../../../etc/passwd\")\nexcept Exception as e:\n    print(e)\n</code></pre>"},{"location":"advanced/#extensible-io-plugins","title":"Extensible I/O Plugins","text":"<p>The FlowerPower plugin <code>flowerpower-io</code> enhances FlowerPower's I/O capabilities, allowing you to connect to various data sources and sinks using a simple plugin architecture.</p> <p>Supported Types Include:</p> <ul> <li>CSV, JSON, Parquet</li> <li>DeltaTable</li> <li>DuckDB, PostgreSQL, MySQL, MSSQL, Oracle, SQLite</li> <li>MQTT</li> </ul> <p>To use a plugin, simply specify its type in your pipeline configuration.</p>"},{"location":"advanced/#troubleshooting","title":"Troubleshooting","text":"<p>Here are some common issues and how to resolve them:</p> <ul> <li>Redis Connection Error: Ensure your Redis server is running and accessible. Check the <code>redis.host</code> and <code>redis.port</code> settings in your configuration.</li> <li>Configuration Errors: Use the <code>flowerpower pipeline show-summary</code> command to inspect the loaded configuration and identify any misconfigurations.</li> <li>Module Not Found: Make sure your pipeline and task modules are in Python's path. You can add directories to the path using the <code>PYTHONPATH</code> environment variable.</li> </ul> <p>Note</p> <p>For more detailed information, refer to the API documentation.</p>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#architecture-overview","title":"Architecture Overview","text":""},{"location":"architecture/#introduction","title":"Introduction","text":"<p>Welcome to the architectural overview of FlowerPower. This document provides a high-level look at the library's design, its core components, and the principles that guide its development. Our goal is to create a powerful, flexible, and easy-to-use platform for building data pipelines.</p>"},{"location":"architecture/#core-design-principles","title":"Core Design Principles","text":"<p>FlowerPower is built on a foundation of modularity and clear separation of concerns. Key design principles include:</p> <ul> <li>Modular and Configuration-Driven: Components are designed to be self-contained and configurable, allowing you to easily swap implementations and adapt the library to your needs.</li> <li>Unified Interface: A single, clean entry point (<code>FlowerPowerProject</code>) simplifies interaction with the library's powerful features.</li> <li>Extensibility: The library is designed to be extended with custom plugins and adapters for I/O, messaging, and more.</li> </ul>"},{"location":"architecture/#key-components","title":"Key Components","text":"<p>The library's architecture is centered around a few key components that work together to provide a seamless experience.</p> <pre><code>graph TD\n    A[FlowerPowerProject] --&gt;|Manages| B(PipelineManager)\n    B --&gt;|Uses| C[Hamilton]\n\n    subgraph \"Core Components\"\n        B\n    end\n\n    subgraph \"External Dependencies\"\n        C\n    end</code></pre>"},{"location":"architecture/#flowerpowerproject","title":"<code>FlowerPowerProject</code>","text":"<p>The <code>FlowerPowerProject</code> class is the main entry point and public-facing API of the library. It acts as a facade, providing a unified interface to the underlying <code>PipelineManager</code>. This simplifies the user experience by abstracting away the complexities of the individual components.</p>"},{"location":"architecture/#pipelinemanager","title":"<code>PipelineManager</code>","text":"<p>The <code>PipelineManager</code> is responsible for everything related to data pipelines:</p> <ul> <li>Configuration: It loads and manages pipeline definitions from YAML files.</li> <li>Execution orchestration: It coordinates with the new runtime stack (<code>PipelineRunner</code>, <code>ExecutionContextBuilder</code>, <code>RetryManager</code>) to execute Hamilton dataflows defined as a Directed Acyclic Graph (DAG) of Python functions.</li> <li>Visualization: It provides tools for visualizing pipeline graphs.</li> <li>I/O: It handles data loading and saving through an extensible system of I/O adapters.</li> </ul>"},{"location":"architecture/#execution-runtime-stack","title":"Execution Runtime Stack","text":"<p>To keep the <code>Pipeline</code> class lean and focused on configuration, the runtime responsibilities are delegated to specialised helpers:</p> <ul> <li><code>PipelineRunner</code> \u2013 Owns the sync/async execution flow, applies <code>RunConfig</code> overrides, reloads modules when requested, and ensures logging/telemetry are initialised once per process.</li> <li><code>ExecutionContextBuilder</code> \u2013 Resolves adapters and executors based on the merged configuration, including Ray shutdown hooks and custom adapters supplied at runtime.</li> <li><code>RetryManager</code> \u2013 Implements retry/backoff logic, including jitter, callbacks, and parity between synchronous and asynchronous execution paths.</li> <li>Telemetry &amp; Logging helpers \u2013 Consolidated utilities (<code>initialize_telemetry</code>, <code>ensure_logging_initialized</code>) eliminate import-time side effects and make log-level overrides predictable.</li> </ul> <p>This separation keeps responsibilities clear and makes it easier to extend or test the execution pipeline without touching configuration loading.</p>"},{"location":"architecture/#hamilton-integration","title":"Hamilton Integration","text":"<p>FlowerPower leverages Hamilton to define the logic of its data pipelines. Hamilton's declarative, function-based approach allows you to define complex dataflows in a clear and maintainable way. Each function in a Hamilton module represents a node in the DAG, and Hamilton automatically resolves the dependencies and executes the functions in the correct order.</p> <p>Note</p> <p>To learn more about Hamilton, visit the official documentation.</p>"},{"location":"architecture/#filesystem-abstraction","title":"Filesystem Abstraction","text":"<p>FlowerPower includes a filesystem abstraction layer that allows you to work with local and remote filesystems (e.g., S3, GCS) using a consistent API. This makes it easy to build pipelines that can read from and write to various storage backends without changing your core logic.</p>"},{"location":"architecture/#conclusion","title":"Conclusion","text":"<p>FlowerPower's architecture is designed to be both powerful and flexible. By leveraging Hamilton for dataflow definition, it provides a comprehensive solution for a wide range of data-intensive applications. The modular design and unified interface make it easy to get started, while the extensible nature of the library allows it to grow with your needs.</p>"},{"location":"cli/","title":"CLI Reference","text":""},{"location":"cli/#cli-reference","title":"CLI Reference","text":"<p>The FlowerPower CLI provides command-line tools for managing projects and pipelines. It is built with Typer and accessible via the <code>flowerpower</code> command.</p>"},{"location":"cli/#usage","title":"Usage","text":"<pre><code>flowerpower [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Run <code>flowerpower --help</code> for a full list of commands.</p>"},{"location":"cli/#commands","title":"Commands","text":""},{"location":"cli/#pipeline","title":"pipeline","text":"<p>Manage pipelines.</p>"},{"location":"cli/#pipeline-run","title":"pipeline run","text":"<p>Run a pipeline.</p> <p>Usage: </p><pre><code>flowerpower pipeline run [OPTIONS] NAME\n</code></pre><p></p> <p>Arguments: - <code>NAME</code>: Name of the pipeline to run [required]</p> <p>Options: - <code>--executor TEXT</code>: Executor to use for running the pipeline - <code>--base-dir TEXT</code>: Base directory for the pipeline - <code>--inputs TEXT</code>: Input parameters as JSON, dict string, or key=value pairs - <code>--final-vars TEXT, --outputs TEXT, -o TEXT</code>: Final variables as JSON or list (alias: <code>--outputs</code>) - <code>--config TEXT</code>: Config for the hamilton pipeline executor - <code>--cache TEXT</code>: Cache configuration as JSON or dict string - <code>--storage-options TEXT</code>: Storage options as JSON, dict string, or key=value pairs - <code>--log-level TEXT</code>: Logging level (debug, info, warning, error, critical) - <code>--with-adapter TEXT</code>: Adapter configuration as JSON or dict string - <code>--max-retries INTEGER</code>: Maximum number of retry attempts on failure [default: 0] (deprecated; prefer nested <code>retry</code> config) - <code>--retry-delay FLOAT</code>: Base delay between retries in seconds [default: 1.0] (deprecated; prefer nested <code>retry</code> config) - <code>--jitter-factor FLOAT</code>: Random factor applied to delay for jitter (0-1) [default: 0.1] (deprecated; prefer nested <code>retry</code> config)</p> <p>Examples: </p><pre><code># Basic run\nflowerpower pipeline run my_pipeline\n\n# With custom inputs\nflowerpower pipeline run my_pipeline --inputs '{\"data_date\": \"2025-04-28\"}'\n\n# Specify final variables\nflowerpower pipeline run my_pipeline --final-vars '[\"result\"]' --log-level DEBUG\n\n# Provide nested retry configuration via RunConfig\nflowerpower pipeline run my_pipeline --run-config '{\"retry\": {\"max_retries\": 3, \"retry_delay\": 2.0}}'\n</code></pre><p></p>"},{"location":"cli/#pipeline-new","title":"pipeline new","text":"<p>Create a new pipeline.</p> <p>Usage: </p><pre><code>flowerpower pipeline new [OPTIONS] NAME\n</code></pre><p></p> <p>Arguments: - <code>NAME</code>: Name of the pipeline to create [required]</p> <p>Options: - <code>--base-dir TEXT</code>: Base directory for the pipeline - <code>--storage-options TEXT</code>: Storage options as JSON, dict string, or key=value pairs - <code>--log-level TEXT</code>: Logging level (debug, info, warning, error, critical) - <code>--overwrite</code>: Overwrite existing pipeline if it exists [default: no]</p> <p>Examples: </p><pre><code># Create new pipeline\nflowerpower pipeline new my_pipeline\n\n# Overwrite if exists\nflowerpower pipeline new my_pipeline --overwrite\n</code></pre><p></p>"},{"location":"cli/#pipeline-delete","title":"pipeline delete","text":"<p>Delete a pipeline.</p> <p>Usage: </p><pre><code>flowerpower pipeline delete [OPTIONS] NAME\n</code></pre><p></p> <p>Arguments: - <code>NAME</code>: Name of the pipeline to delete [required]</p> <p>Options: - <code>--base-dir TEXT</code>: Base directory for the pipeline - <code>--storage-options TEXT</code>: Storage options as JSON, dict string, or key=value pairs - <code>--log-level TEXT</code>: Logging level (debug, info, warning, error, critical) - <code>--cfg</code>: Delete only the configuration file [default: no] - <code>--module</code>: Delete only the pipeline module [default: no]</p> <p>Examples: </p><pre><code># Delete pipeline (config and module)\nflowerpower pipeline delete my_pipeline\n\n# Delete only config\nflowerpower pipeline delete my_pipeline --cfg\n</code></pre><p></p>"},{"location":"cli/#pipeline-show-dag","title":"pipeline show-dag","text":"<p>Show the DAG of a pipeline.</p> <p>Usage: </p><pre><code>flowerpower pipeline show-dag [OPTIONS] NAME\n</code></pre><p></p> <p>Arguments: - <code>NAME</code>: Name of the pipeline to visualize [required]</p> <p>Options: - <code>--base-dir TEXT</code>: Base directory for the pipeline - <code>--storage-options TEXT</code>: Storage options as JSON, dict string, or key=value pairs - <code>--log-level TEXT</code>: Logging level (debug, info, warning, error, critical) - <code>--format TEXT</code>: Output format (e.g., png, svg, pdf). If 'raw', returns object. [default: png]</p> <p>Examples: </p><pre><code># Show DAG\nflowerpower pipeline show-dag my_pipeline\n\n# SVG format\nflowerpower pipeline show-dag my_pipeline --format svg\n</code></pre><p></p>"},{"location":"cli/#pipeline-save-dag","title":"pipeline save-dag","text":"<p>Save the DAG of a pipeline to a file.</p> <p>Usage: </p><pre><code>flowerpower pipeline save-dag [OPTIONS] NAME\n</code></pre><p></p> <p>Arguments: - <code>NAME</code>: Name of the pipeline to visualize [required]</p> <p>Options: - <code>--base-dir TEXT</code>: Base directory for the pipeline - <code>--storage-options TEXT</code>: Storage options as JSON, dict string, or key=value pairs - <code>--log-level TEXT</code>: Logging level (debug, info, warning, error, critical) - <code>--format TEXT</code>: Output format (e.g., png, svg, pdf) [default: png] - <code>--output-path TEXT</code>: Custom path to save the file (default: .)</p> <p>Examples: </p><pre><code># Save DAG\nflowerpower pipeline save-dag my_pipeline\n\n# Custom path\nflowerpower pipeline save-dag my_pipeline --output-path ./vis/my_graph.png --format svg\n</code></pre><p></p>"},{"location":"cli/#pipeline-show-pipelines","title":"pipeline show-pipelines","text":"<p>List all pipelines.</p> <p>Usage: </p><pre><code>flowerpower pipeline show-pipelines [OPTIONS]\n</code></pre><p></p> <p>Options: - <code>--base-dir TEXT</code>: Base directory for the pipeline - <code>--storage-options TEXT</code>: Storage options as JSON, dict string, or key=value pairs - <code>--log-level TEXT</code>: Logging level (debug, info, warning, error, critical) - <code>--format TEXT</code>: Output format (table, json, yaml) [default: table]</p> <p>Examples: </p><pre><code># List pipelines\nflowerpower pipeline show-pipelines\n\n# JSON format\nflowerpower pipeline show-pipelines --format json\n</code></pre><p></p>"},{"location":"cli/#pipeline-show-summary","title":"pipeline show-summary","text":"<p>Show summary of pipelines.</p> <p>Usage: </p><pre><code>flowerpower pipeline show-summary [OPTIONS]\n</code></pre><p></p> <p>Options: - <code>--name TEXT</code>: Name of specific pipeline (all if not specified) - <code>--cfg</code>: Include configuration details [default: True] - <code>--code</code>: Include code/module details [default: True] - <code>--project</code>: Include project context [default: True] - <code>--base-dir TEXT</code>: Base directory for the pipeline - <code>--storage-options TEXT</code>: Storage options as JSON, dict string, or key=value pairs - <code>--log-level TEXT</code>: Logging level (debug, info, warning, error, critical) - <code>--to-html</code>: Output summary as HTML [default: no] - <code>--to-svg</code>: Output summary as SVG (if applicable) [default: no] - <code>--output-file TEXT</code>: Save output to file instead of printing</p> <p>Examples: </p><pre><code># Summary for all pipelines\nflowerpower pipeline show-summary\n\n# Summary for specific pipeline\nflowerpower pipeline show-summary --name my_pipeline --cfg --code --no-project\n</code></pre><p></p>"},{"location":"cli/#pipeline-add-hook","title":"pipeline add-hook","text":"<p>Add a hook to a pipeline.</p> <p>Usage: </p><pre><code>flowerpower pipeline add-hook [OPTIONS] NAME\n</code></pre><p></p> <p>Arguments: - <code>NAME</code>: Name of the pipeline to add the hook to [required]</p> <p>Options: - <code>--function TEXT</code>: Name of the hook function [required] - <code>--type [MQTT_BUILD_CONFIG]</code>: Type of hook to add [default: MQTT_BUILD_CONFIG] - <code>--to TEXT</code>: Target node name or tag (required for node hooks) - <code>--base-dir TEXT</code>: Base directory for the pipeline - <code>--storage-options TEXT</code>: Storage options as JSON, dict string, or key=value pairs - <code>--log-level TEXT</code>: Logging level (debug, info, warning, error, critical)</p> <p>Examples: </p><pre><code># Add hook\nflowerpower pipeline add-hook my_pipeline --function log_results --type MQTT_BUILD_CONFIG\n</code></pre><p></p>"},{"location":"cli/#init","title":"init","text":"<p>Initialize a new FlowerPower project.</p> <p>Usage: </p><pre><code>flowerpower init [OPTIONS] [NAME]\n</code></pre><p></p> <p>Options: - <code>--name TEXT</code>: The name of the project - <code>--base-dir TEXT</code>: Base directory where the project will be created - <code>--storage-options TEXT</code>: Storage options as JSON, dict string, or key=value pairs - <code>--log-level TEXT</code>: Logging level (debug, info, warning, error, critical)</p> <p>Examples: ```bash</p>"},{"location":"cli/#initialize-project","title":"Initialize project","text":"<p>flowerpower init --name my_project</p>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing-to-flowerpower","title":"Contributing to FlowerPower","text":"<p>First off, thank you for considering contributing to FlowerPower! It's people like you that make open source such a great community.</p> <p>We welcome contributions in various forms, from reporting bugs and suggesting enhancements to submitting pull requests with new features or bug fixes.</p>"},{"location":"contributing/#reporting-issues","title":"Reporting Issues","text":"<p>If you encounter a bug or have a suggestion for a new feature, please open an issue on our GitHub Issue Tracker.</p> <p>When reporting a bug, please include the following to help us resolve it quickly: - A clear and descriptive title. - A detailed description of the problem, including steps to reproduce it. - Your operating system, Python version, and FlowerPower version. - Any relevant logs or tracebacks.</p>"},{"location":"contributing/#submitting-pull-requests","title":"Submitting Pull Requests","text":"<p>We love pull requests! To ensure a smooth process, please follow these guidelines:</p> <ol> <li>Fork the repository and create a new branch for your feature or bug fix.</li> <li>Set up your development environment (see \"Development Setup\" below).</li> <li>Make your changes and ensure the code is well-tested.</li> <li>Update the documentation if your changes affect it.</li> <li>Ensure your code passes all tests before submitting.</li> <li>Submit a pull request with a clear description of your changes.</li> </ol>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<p>We use <code>uv</code> for managing dependencies and running our development environment.</p> <ol> <li> <p>Install <code>uv</code>:     Follow the official instructions to install <code>uv</code>.</p> </li> <li> <p>Create a virtual environment:     </p><pre><code>uv venv\n</code></pre><p></p> </li> <li> <p>Activate the environment:     </p><pre><code>source .venv/bin/activate\n</code></pre><p></p> </li> <li> <p>Install dependencies:     To install the base dependencies along with the development and test dependencies, run:     </p><pre><code>uv pip install -e \".[dev,test]\"\n</code></pre><p></p> <p>Note</p> <p>If you need to install optional dependencies for specific features (e.g., <code>mqtt</code>, <code>redis</code>), you can add them to the install command: <code>uv pip install -e \".[dev,test,mqtt,redis]\"</code>.</p> </li> <li> <p>Run tests:     To ensure everything is working correctly, run the test suite:     </p><pre><code>uv run pytest\n</code></pre><p></p> </li> </ol>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>We are committed to providing a welcoming and inclusive environment for everyone. Please read and follow our Code of Conduct (assuming one exists or will be created).</p> <p>Thank you for your contribution!</p>"},{"location":"examples/","title":"Examples","text":""},{"location":"examples/#examples","title":"Examples","text":"<p>This section provides an overview of various example projects built with FlowerPower. These examples demonstrate different use cases and functionalities of the framework, from simple \"Hello World\" setups to complex machine learning pipelines and data processing workflows. You can find the source code for these examples in the FlowerPower GitHub repository.</p>"},{"location":"examples/#available-examples","title":"Available Examples","text":""},{"location":"examples/#data-etl-pipeline","title":"<code>data-etl-pipeline/</code>","text":"<p>This example demonstrates a typical Extract, Transform, Load (ETL) pipeline, showcasing how FlowerPower can be used to process and move data between different systems.</p>"},{"location":"examples/#hello-world","title":"<code>hello-world/</code>","text":"<p>A basic \"Hello World\" example illustrating the fundamental structure of a FlowerPower project and how to define and run a simple pipeline.</p>"},{"location":"examples/#ml-training-pipeline","title":"<code>ml-training-pipeline/</code>","text":"<p>Showcases how to build a machine learning training pipeline with FlowerPower, including data preparation, model training, and evaluation steps.</p>"},{"location":"examples/#pipeline-only-example","title":"<code>pipeline-only-example/</code>","text":"<p>This example highlights the core pipeline functionality of FlowerPower, demonstrating how to define and execute a sequence of interconnected tasks.</p>"},{"location":"examples/#scheduled-reports","title":"<code>scheduled-reports/</code>","text":"<p>Demonstrates how to use FlowerPower to automate the generation and distribution of scheduled reports, leveraging its scheduling and task management features.</p>"},{"location":"examples/#web-scraping-pipeline","title":"<code>web-scraping-pipeline/</code>","text":"<p>An example illustrating a web scraping workflow implemented as a FlowerPower pipeline, showing how to extract data from websites and process it.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":"<p>Welcome to the FlowerPower installation guide. This page will walk you through the steps to get FlowerPower up and running on your system.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li> <p>Python 3.8 or higher: FlowerPower requires a modern version of Python. You can check your Python version by running:</p> <pre><code>python --version\n</code></pre> </li> <li> <p>A package manager: We recommend using a modern package manager like <code>uv</code> or <code>pip</code> for a smooth installation experience.</p> </li> </ul> <p>Project and Environment Management</p> <p>For robust project management, we highly recommend using tools like <code>uv</code> or <code>pixi</code>. These tools help you manage dependencies and ensure your projects are reproducible.</p>"},{"location":"installation/#standard-installation","title":"Standard Installation","text":"<p>The recommended way to install FlowerPower is with <code>uv pip</code>:</p> <pre><code>uv pip install flowerpower\n</code></pre> <p>Alternatively, you can use <code>pip</code>:</p> <pre><code>pip install flowerpower\n</code></pre> <p>This will install the core FlowerPower library with all the essential features to get you started.</p>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>FlowerPower offers optional dependencies that you can install to enable additional functionality.</p> <ul> <li> <p>I/O Plugins: For additional I/O capabilities, install the <code>[io]</code> extra:</p> <pre><code>uv pip install 'flowerpower[io]'\n</code></pre> </li> <li> <p>Hamilton UI: To use the Hamilton UI for interactive dataflow visualization, install the <code>[ui]</code> extra:</p> <pre><code>uv pip install 'flowerpower[ui]'\n</code></pre> </li> <li> <p>All Extras: To install all optional dependencies at once, use the <code>[all]</code> extra:</p> <pre><code>uv pip install 'flowerpower[all]'\n</code></pre> </li> </ul>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues during installation, here are a few tips:</p> <ul> <li> <p>Use a Virtual Environment: It is highly recommended to install FlowerPower in a virtual environment to avoid conflicts with other packages. You can create one with <code>uv</code>:</p> <pre><code>uv venv\nsource .venv/bin/activate\n</code></pre> </li> <li> <p>Check Your PATH: Ensure that your Python and script installation directories are in your system's <code>PATH</code>. If you can't run <code>flowerpower</code> from your terminal, this might be the issue.</p> </li> <li> <p>Permissions: If you get a permission error, you might be trying to install the package globally without the necessary privileges. Using a virtual environment is the best way to avoid this.</p> </li> </ul> <p>If you continue to have problems, please open an issue on our GitHub repository.</p>"},{"location":"quickstart/","title":"Quickstart","text":""},{"location":"quickstart/#quickstart","title":"Quickstart","text":"<p>Welcome to the FlowerPower quickstart guide! This guide will walk you through the process of creating a \"Hello World\" project to demonstrate the core functionalities of the library.</p>"},{"location":"quickstart/#installation","title":"Installation","text":"<p>First, ensure you have FlowerPower installed. We recommend using <code>uv</code> for a fast and reliable installation.</p> <pre><code># Create and activate a virtual environment\nuv venv\nsource .venv/bin/activate\n\n# Install FlowerPower\nuv pip install flowerpower\n</code></pre>"},{"location":"quickstart/#1-initialize-your-project","title":"1. Initialize Your Project","text":"<p>You can create a new project using either the CLI or the Python API.</p>"},{"location":"quickstart/#using-the-cli","title":"Using the CLI","text":"<pre><code>flowerpower init --name hello-flowerpower\ncd hello-flowerpower\n</code></pre>"},{"location":"quickstart/#using-the-python-api","title":"Using the Python API","text":"<pre><code>from flowerpower import FlowerPowerProject\n\n# Initialize a new project\nproject = FlowerPowerProject.new(\n    name='hello-flowerpower'\n)\n</code></pre> <p>This creates a standard project structure with <code>conf/</code> and <code>pipelines/</code> directories.</p>"},{"location":"quickstart/#2-configure-your-project","title":"2. Configure Your Project","text":"<p>The <code>conf/project.yml</code> file contains global settings for your project.</p> <pre><code># conf/project.yml\nname: hello-flowerpower\n</code></pre>"},{"location":"quickstart/#3-create-a-pipeline","title":"3. Create a Pipeline","text":"<p>Next, create a pipeline to define your data processing logic.</p>"},{"location":"quickstart/#using-the-cli_1","title":"Using the CLI","text":"<pre><code>flowerpower pipeline new hello_world\n</code></pre>"},{"location":"quickstart/#using-the-python-api_1","title":"Using the Python API","text":"<pre><code>from flowerpower import FlowerPowerProject\n\nproject = FlowerPowerProject.load('.')\nproject.pipeline_manager.new(name='hello_world')\n</code></pre> <p>This generates <code>pipelines/hello_world.py</code> for your pipeline logic and <code>conf/pipelines/hello_world.yml</code> for its configuration.</p>"},{"location":"quickstart/#4-implement-the-pipeline","title":"4. Implement the Pipeline","text":"<p>Open <code>pipelines/hello_world.py</code> and add your Hamilton functions.</p> <pre><code># pipelines/hello_world.py\nfrom pathlib import Path\nfrom hamilton.function_modifiers import parameterize\nfrom flowerpower.cfg.project import ProjectConfig\nfrom flowerpower.cfg.pipeline import PipelineConfig\n\n# Load project and pipeline configurations separately\nproject_cfg = ProjectConfig.load(name=\"hello-flowerpower\")\npipeline_cfg = PipelineConfig.load(name=\"hello_world\")\nPARAMS = pipeline_cfg.params  # Access params from pipeline config\n\n@parameterize(**PARAMS.get(\"greeting_message\", {}))\ndef greeting_message(message: str) -&gt; str:\n    return f\"{message},\"\n\n@parameterize(**PARAMS.target_name)\ndef target_name(name: str) -&gt; str:\n    return f\"{name}!\"\n\ndef full_greeting(greeting_message: str, target_name: str) -&gt; str:\n    \"\"\"Combines the greeting and target.\"\"\"\n    print(f\"Executing pipeline: {greeting_message} {target_name}\")\n    return f\"{greeting_message} {target_name}\"\n</code></pre>"},{"location":"quickstart/#5-configure-the-pipeline","title":"5. Configure the Pipeline","text":"<p>In <code>conf/pipelines/hello_world.yml</code>, define the parameters and execution details for your pipeline.</p> <pre><code># conf/pipelines/hello_world.yml\nparams:\n  greeting_message:\n    message: \"Hello\"\n  target_name:\n    name: \"World\"\n\nrun:\n  final_vars:\n    - full_greeting\n</code></pre>"},{"location":"quickstart/#6-run-the-pipeline","title":"6. Run the Pipeline","text":"<p>You can run your pipeline synchronously for quick tests.</p>"},{"location":"quickstart/#synchronous-execution","title":"Synchronous Execution","text":"<p>This is useful for debugging and local development.</p>"},{"location":"quickstart/#using-the-cli_2","title":"Using the CLI","text":"<p>The <code>run</code> command now primarily accepts a <code>RunConfig</code> object, but also allows individual parameters to be passed via <code>**kwargs</code> which override <code>RunConfig</code> attributes.</p> <pre><code># Basic pipeline execution\nflowerpower pipeline run hello_world\n\n# Run with individual parameters (kwargs)\nflowerpower pipeline run hello_world --inputs '{\"greeting_message\": \"Hi\", \"target_name\": \"FlowerPower\"}' --final-vars '[\"full_greeting\"]' --log-level DEBUG\n\n# Run using a RunConfig from a YAML file\n# Assuming you have a run_config.yaml like:\n# inputs:\n#   greeting_message: \"Hola\"\n#   target_name: \"Amigo\"\n# log_level: \"INFO\"\nflowerpower pipeline run hello_world --run-config ./run_config.yaml\n\n# Run using a RunConfig provided as a JSON string\nflowerpower pipeline run hello_world --run-config '{\"inputs\": {\"greeting_message\": \"Bonjour\", \"target_name\": \"Monde\"}, \"log_level\": \"INFO\"}'\n\n# Mixing RunConfig with individual parameters (kwargs overrides RunConfig)\n# This will run with log_level=\"DEBUG\" and inputs={\"greeting_message\": \"Howdy\", \"target_name\": \"Partner\"}\nflowerpower pipeline run hello_world --run-config '{\"inputs\": {\"greeting_message\": \"Original\", \"target_name\": \"Value\"}, \"log_level\": \"INFO\"}' --inputs '{\"greeting_message\": \"Howdy\", \"target_name\": \"Partner\"}' --log-level DEBUG\n</code></pre>"},{"location":"quickstart/#using-the-python-api_2","title":"Using the Python API","text":"<pre><code>from flowerpower import FlowerPowerProject\n\nproject = FlowerPowerProject.load('.')\nresult = project.run('hello_world')\nprint(result)\n</code></pre>"},{"location":"quickstart/#advanced-pipeline-execution-with-runconfig","title":"Advanced Pipeline Execution with RunConfig","text":"<p>For more control over pipeline execution, you can use the <code>RunConfig</code> class to configure execution parameters.</p>"},{"location":"quickstart/#using-runconfig-directly","title":"Using RunConfig Directly","text":"<pre><code>from flowerpower import FlowerPowerProject\nfrom flowerpower.cfg.pipeline.run import RunConfig\n\nproject = FlowerPowerProject.load('.')\n\n# Create a configuration with custom parameters\nconfig = RunConfig(\n    inputs={\"greeting_message\": \"Hi\", \"target_name\": \"FlowerPower\"},\n    final_vars=[\"full_greeting\"],\n    log_level=\"DEBUG\"\n)\n\nresult = project.run('hello_world', run_config=config)\nprint(result)\n</code></pre>"},{"location":"quickstart/#using-runconfigbuilder-recommended","title":"Using RunConfigBuilder (Recommended)","text":"<p>The <code>RunConfigBuilder</code> provides a fluent interface for building complex configurations:</p> <pre><code>from flowerpower import FlowerPowerProject\nfrom flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\nproject = FlowerPowerProject.load('.')\n\n# Build a configuration using the builder pattern\nconfig = (\n    RunConfigBuilder(pipeline_name='hello_world')\n    .with_inputs({\"greeting_message\": \"Hello\", \"target_name\": \"World\"})\n    .with_final_vars([\"full_greeting\"])\n    .with_log_level(\"DEBUG\")\n    .with_retry_config(max_retries=3, retry_delay=1.0)\n    .build()\n)\n\nresult = project.run('hello_world', run_config=config)\nprint(result)\n</code></pre>"},{"location":"quickstart/#mixing-runconfig-with-individual-parameters","title":"Mixing RunConfig with Individual Parameters","text":"<p>You can also combine <code>RunConfig</code> with individual parameters, where individual parameters take precedence:</p> <pre><code>from flowerpower import FlowerPowerProject\nfrom flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\nproject = FlowerPowerProject.load('.')\n\n# Create a base configuration\nbase_config = RunConfigBuilder().with_log_level(\"INFO\").build()\n\n# Run with base config but override specific parameters\nresult = project.run(\n    'hello_world',\n    run_config=base_config,\n    inputs={\"greeting_message\": \"Greetings\", \"target_name\": \"Universe\"}\n)\nprint(result)\n</code></pre> <p>For more details on managing your project, refer to the API documentation for <code>FlowerPowerProject</code>, <code>PipelineManager</code>, and <code>RunConfig</code>.</p>"},{"location":"api/","title":"Overview","text":""},{"location":"api/#api-reference","title":"API Reference","text":"<p>This section provides a detailed reference for the FlowerPower API.</p>"},{"location":"api/#core-components","title":"Core Components","text":"<ul> <li>FlowerPowerProject</li> <li>PipelineManager</li> <li>RunConfig</li> </ul>"},{"location":"api/#configuration","title":"Configuration","text":"<ul> <li>Configuration</li> </ul>"},{"location":"api/#top-level-functions","title":"Top-Level Functions","text":"<ul> <li>initialize_project</li> <li>create_project (aliased as FlowerPower)</li> </ul>"},{"location":"api/#cli-reference","title":"CLI Reference","text":"<ul> <li>CLI Overview</li> <li>CLI Pipeline Commands</li> <li>CLI MQTT Commands</li> </ul>"},{"location":"api/cli/","title":"CLI","text":""},{"location":"api/cli/#cli-reference","title":"CLI Reference","text":"<p>This section provides a comprehensive reference for the FlowerPower Command Line Interface (CLI).</p>"},{"location":"api/cli/#main-commands","title":"Main Commands","text":""},{"location":"api/cli/#flowerpower-init","title":"flowerpower init","text":"<p>Initialize a new FlowerPower project.</p> <p>This command creates a new FlowerPower project with the necessary directory structure and configuration files. If no project name is provided, the current directory name will be used as the project name.</p>"},{"location":"api/cli/#usage","title":"Usage","text":"<pre><code>flowerpower init [options]\n</code></pre>"},{"location":"api/cli/#options","title":"Options","text":"Name Type Description Default --name str Name of the FlowerPower project to create. If not provided, current directory name is used. None --base-dir str Base directory where the project will be created. If not provided, uses current working directory. None --storage-options str Storage options as JSON or Python dict string; parsed to dict. None"},{"location":"api/cli/#examples","title":"Examples","text":"<pre><code>$ flowerpower init\n\n# Create a project with a specific name\n</code></pre> <pre><code>$ flowerpower init --name my-awesome-project\n\n# Create a project in a specific location\n</code></pre> <pre><code>$ flowerpower init --name my-project --base-dir /path/to/projects\n</code></pre>"},{"location":"api/cli/#flowerpower-ui","title":"flowerpower ui","text":"<p>Start the Hamilton UI web application.</p> <p>This command launches the Hamilton UI, which provides a web interface for visualizing and interacting with your FlowerPower pipelines. The UI allows you to explore pipeline execution graphs and view results.</p>"},{"location":"api/cli/#usage_1","title":"Usage","text":"<pre><code>flowerpower ui [options]\n</code></pre>"},{"location":"api/cli/#options_1","title":"Options","text":"Name Type Description Default --port int Port to run the UI server on 8241 --base-dir str Base directory where the UI will store its data ~/.hamilton/db --no-migration bool Skip running database migrations on startup False --no-open bool Prevent automatically opening the browser False --settings str Settings profile to use (mini, dev, prod) \"mini\" --config str Optional custom configuration file path None <p>Note: Requires <code>sf-hamilton[ui]</code>. If not installed, the command prints guidance to install it.</p>"},{"location":"api/cli/#examples_1","title":"Examples","text":"<pre><code>$ flowerpower ui\n\n# Run the UI on a specific port\n</code></pre> <pre><code>$ flowerpower ui --port 9000\n\n# Use a custom data directory\n</code></pre> <pre><code>$ flowerpower ui --base-dir ~/my-project/.hamilton-data\n\n# Start without opening a browser\n</code></pre> <pre><code>$ flowerpower ui --no-open\n\n# Use production settings\n</code></pre> <pre><code>$ flowerpower ui --settings prod\n</code></pre>"},{"location":"api/cli_pipeline/","title":"Pipeline CLI","text":""},{"location":"api/cli_pipeline/#flowerpower-pipeline","title":"flowerpower pipeline Commands","text":"<p>This section details the commands available under <code>flowerpower pipeline</code>.</p>"},{"location":"api/cli_pipeline/#flowerpower-run","title":"run","text":"<p>Run a pipeline immediately.</p> <p>This command executes a pipeline with the specified configuration and inputs. The pipeline will run synchronously, and the command will wait for completion.</p>"},{"location":"api/cli_pipeline/#usage","title":"Usage","text":"<pre><code>flowerpower pipeline run [options]\n</code></pre>"},{"location":"api/cli_pipeline/#options","title":"Options","text":"Name Type Description Default name str (arg) Name of the pipeline to run. \u2014 --executor str Executor type: one of \"synchronous\", \"threadpool\", \"processpool\", \"ray\", \"dask\". None --executor-cfg str Executor configuration as JSON/dict; supports keys: <code>type</code>, <code>max_workers</code>, <code>num_cpus</code>. None --executor-max-workers int Convenience: set <code>executor.max_workers</code>. None --executor-num-cpus int Convenience: set <code>executor.num_cpus</code>. None --base-dir str Base directory for the pipeline/project. None --inputs str Inputs as JSON/dict string; parsed to dict. None --final-vars str Final variables as JSON/list string; parsed to list. None --config str Hamilton runtime config as JSON/dict string. None --cache str Cache config as JSON/dict string. None --storage-options str Storage options as JSON/dict string; parsed to dict. None --log-level str Logging level: debug, info, warning, error, critical. None --with-adapter str Adapter config as JSON/dict string. None --max-retries int Max retry attempts on failure. 0 --retry-delay float Base delay between retries (seconds). 1.0 --jitter-factor float Random jitter factor [0-1]. 0.1"},{"location":"api/cli_pipeline/#examples","title":"Examples","text":"<pre><code># Basic pipeline execution\n$ flowerpower pipeline run my_pipeline\n\n# Run with individual parameters (kwargs)\n$ flowerpower pipeline run my_pipeline --inputs '{\"data_path\": \"data/myfile.csv\"}' --final-vars '[\"output_table\", \"summary_metrics\"]'\n\n# Configure automatic retries on failure using kwargs\n$ flowerpower pipeline run my_pipeline --max-retries 3 --retry-delay 2.0 --jitter-factor 0.2\n\n# Select synchronous executor (sequential)\n$ flowerpower pipeline run my_pipeline --executor synchronous\n\n### Environment Overrides\n\nYou can override run settings using environment variables without changing the YAML:\n\n```bash\nexport FP_PIPELINE__RUN__LOG_LEVEL=DEBUG\nexport FP_PIPELINE__RUN__EXECUTOR__TYPE=threadpool\nexport FP_LOG_LEVEL=INFO  # global shim, used only if pipeline-specific not set\n</code></pre> <p>YAML values support <code>${VAR}</code> interpolation. Example in <code>conf/pipelines/&lt;name&gt;.yml</code>:</p> <pre><code>run:\n  log_level: ${FP_LOG_LEVEL:-INFO}\n</code></pre> <p>Executor config JSON example (shell-escaped):</p> <pre><code>flowerpower pipeline run my_pipeline --executor-cfg '{\"type\":\"threadpool\",\"max_workers\":4}'\n</code></pre> <p>Convenience flags example:</p> <p></p><pre><code>flowerpower pipeline run my_pipeline \\\n  --executor threadpool \\\n  --executor-max-workers 8 \\\n  --executor-num-cpus 4\n</code></pre> <pre><code>---\n\n## new { #flowerpower-new }\n\nCreate a new pipeline structure.\n\nThis command creates a new pipeline with the necessary directory structure,\nconfiguration file, and skeleton module file. It prepares all the required\ncomponents for you to start implementing your pipeline logic.\n\n### Usage\n\n```bash\nflowerpower pipeline new [options]\n</code></pre><p></p>"},{"location":"api/cli_pipeline/#options_1","title":"Options","text":"Name Type Description Default name str (arg) Name for the new pipeline \u2014 --base-dir str Base directory to create the pipeline in None --storage-options str Options for storage backends (JSON/dict string) None --log-level str Logging level (debug, info, warning, error, critical) None --overwrite bool Overwrite existing pipeline if it exists False"},{"location":"api/cli_pipeline/#examples_1","title":"Examples","text":"<pre><code>$ pipeline new my_new_pipeline\n\n# Create a pipeline, overwriting if it exists\n</code></pre> <pre><code>$ pipeline new my_new_pipeline --overwrite\n\n# Create a pipeline in a specific directory\n</code></pre> <pre><code>$ pipeline new my_new_pipeline --base-dir /path/to/project\n</code></pre>"},{"location":"api/cli_pipeline/#flowerpower-delete","title":"delete","text":"<p>Delete a pipeline's configuration and/or module files.</p> <p>This command removes a pipeline's configuration file and/or module file from the project. If neither --cfg nor --module is specified, both will be deleted.</p>"},{"location":"api/cli_pipeline/#usage_1","title":"Usage","text":"<pre><code>flowerpower pipeline delete [options]\n</code></pre>"},{"location":"api/cli_pipeline/#options_2","title":"Options","text":"Name Type Description Default name str (arg) Name of the pipeline to delete \u2014 --base-dir str Base directory containing the pipeline None --cfg bool Delete only the configuration file False --module bool Delete only the pipeline module False --storage-options str Options for storage backends (JSON/dict string) None --log-level str Logging level None <p>Behavior: If neither <code>--cfg</code> nor <code>--module</code> is specified, both config and module are deleted.</p>"},{"location":"api/cli_pipeline/#examples_2","title":"Examples","text":"<pre><code>$ pipeline delete my_pipeline\n\n# Delete only the configuration file\n</code></pre> <pre><code>$ pipeline delete my_pipeline --cfg\n\n# Delete only the module file\n</code></pre> <pre><code>$ pipeline delete my_pipeline --module\n</code></pre>"},{"location":"api/cli_pipeline/#flowerpower-show_dag","title":"show_dag","text":"<p>Show the DAG (Directed Acyclic Graph) of a pipeline.</p> <p>This command generates and displays a visual representation of the pipeline's execution graph, showing how nodes are connected and dependencies between them.</p>"},{"location":"api/cli_pipeline/#usage_2","title":"Usage","text":"<pre><code>flowerpower pipeline show_dag [options]\n</code></pre>"},{"location":"api/cli_pipeline/#options_3","title":"Options","text":"Name Type Description Default name str (arg) Name of the pipeline to visualize \u2014 --base-dir str Base directory containing the pipeline None --storage-options str Options for storage backends (JSON/dict string) None --log-level str Logging level None --format str Output format: png, svg, pdf; <code>raw</code> returns the graph object \"png\""},{"location":"api/cli_pipeline/#examples_3","title":"Examples","text":"<pre><code>$ pipeline show-dag my_pipeline\n\n# Generate SVG format visualization\n</code></pre> <pre><code>$ pipeline show-dag my_pipeline --format svg\n\n# Get raw graphviz object\n</code></pre> <pre><code>$ pipeline show-dag my_pipeline --format raw\n</code></pre>"},{"location":"api/cli_pipeline/#flowerpower-save_dag","title":"save_dag","text":"<p>Save the DAG (Directed Acyclic Graph) of a pipeline to a file.</p> <p>This command generates a visual representation of the pipeline's execution graph and saves it to a file in the specified format.</p>"},{"location":"api/cli_pipeline/#usage_3","title":"Usage","text":"<pre><code>flowerpower pipeline save_dag [options]\n</code></pre>"},{"location":"api/cli_pipeline/#options_4","title":"Options","text":"Name Type Description Default name str (arg) Name of the pipeline to visualize \u2014 --base-dir str Base directory containing the pipeline None --storage-options str Options for storage backends (JSON/dict string) None --log-level str Logging level None --format str Output format: png, svg, pdf \"png\" --output-path str Custom file path to save the output (default: .) None"},{"location":"api/cli_pipeline/#examples_4","title":"Examples","text":"<pre><code>$ pipeline save-dag my_pipeline\n\n# Save in SVG format\n</code></pre> <pre><code>$ pipeline save-dag my_pipeline --format svg\n\n# Save to a custom location\n</code></pre> <pre><code>$ pipeline save-dag my_pipeline --output-path ./visualizations/my_graph.png\n</code></pre>"},{"location":"api/cli_pipeline/#flowerpower-show_pipelines","title":"show_pipelines","text":"<p>List all available pipelines in the project.</p> <p>This command displays a list of all pipelines defined in the project, providing an overview of what pipelines are available to run.</p>"},{"location":"api/cli_pipeline/#usage_4","title":"Usage","text":"<pre><code>flowerpower pipeline show_pipelines [options]\n</code></pre>"},{"location":"api/cli_pipeline/#options_5","title":"Options","text":"Name Type Description Default --base-dir str Base directory containing pipelines None --storage-options str Options for storage backends (JSON/dict string) None --log-level str Logging level None --format str Output format (table, json, yaml) \"table\""},{"location":"api/cli_pipeline/#examples_5","title":"Examples","text":"<pre><code>$ pipeline show-pipelines\n\n# Output in JSON format\n</code></pre> <pre><code>$ pipeline show-pipelines --format json\n\n# List pipelines from a specific directory\n</code></pre> <pre><code>$ pipeline show-pipelines --base-dir /path/to/project\n</code></pre>"},{"location":"api/cli_pipeline/#flowerpower-show_summary","title":"show_summary","text":"<p>Show summary information for one or all pipelines.</p> <p>This command displays detailed information about pipelines including their configuration, code structure, and project context. You can view information for a specific pipeline or get an overview of all pipelines.</p>"},{"location":"api/cli_pipeline/#usage_5","title":"Usage","text":"<pre><code>flowerpower pipeline show_summary [options]\n</code></pre>"},{"location":"api/cli_pipeline/#options_6","title":"Options","text":"Name Type Description Default --name str Name of specific pipeline to summarize (all if not specified) None --cfg bool Include configuration details True --code bool Include code/module details True --project bool Include project context information True --base-dir str Base directory containing pipelines None --storage-options str Options for storage backends (JSON/dict string) None --log-level str Logging level None --to-html bool Generate HTML output instead of text False --to-svg bool Generate SVG output (where applicable) False --output-file str File path to save the output instead of printing to console None"},{"location":"api/cli_pipeline/#examples_6","title":"Examples","text":"<pre><code>$ pipeline show-summary\n\n# Show summary for a specific pipeline\n</code></pre> <pre><code>$ pipeline show-summary --name my_pipeline\n\n# Show only configuration information\n</code></pre> <pre><code>$ pipeline show-summary --name my_pipeline --cfg --no-code --no-project\n\n# Generate HTML report\n</code></pre> <pre><code>$ pipeline show-summary --to-html --output-file pipeline_report.html\n</code></pre>"},{"location":"api/cli_pipeline/#flowerpower-add_hook","title":"add_hook","text":"<p>Add a hook to a pipeline configuration.</p> <p>This command adds a hook function to a pipeline's configuration. Hooks are functions that are called at specific points during pipeline execution to perform additional tasks like logging, monitoring, or data validation.</p>"},{"location":"api/cli_pipeline/#usage_6","title":"Usage","text":"<pre><code>flowerpower pipeline add_hook [options]\n</code></pre>"},{"location":"api/cli_pipeline/#arguments","title":"Arguments","text":"Name Type Description Default name str Name of the pipeline to add the hook to Required function_name str Name of the hook function (must be defined in the pipeline module) Required type str Type of hook (determines when the hook is called during execution) Required to str Target node or tag (required for node-specific hooks) Required base_dir str Base directory containing the pipeline Required storage_options str Options for storage backends Required log_level str Set the logging level Required"},{"location":"api/cli_pipeline/#examples_7","title":"Examples","text":"<pre><code>$ pipeline add-hook my_pipeline --function log_results\n\n# Add a pre-run hook\n</code></pre> <pre><code>$ pipeline add-hook my_pipeline --function validate_inputs --type PRE_RUN\n\n# Add a node-specific hook (executed before a specific node runs)\n</code></pre> <pre><code>$ pipeline add-hook my_pipeline --function validate_data --type NODE_PRE_EXECUTE --to data_processor\n\n# Add a hook for all nodes with a specific tag\n</code></pre> <pre><code>$ pipeline add-hook my_pipeline --function log_metrics --type NODE_POST_EXECUTE --to @metrics\n</code></pre>"},{"location":"api/configuration/","title":"Configuration","text":""},{"location":"api/configuration/#configuration","title":"Configuration","text":"<p>FlowerPower uses a hierarchical configuration system to manage project and pipeline settings. The main configuration classes are:</p> <ul> <li><code>Config</code></li> <li><code>ProjectConfig</code></li> <li><code>PipelineConfig</code></li> <li><code>BaseConfig</code></li> </ul> <p>The <code>Config</code> class serves as a composite that combines <code>ProjectConfig</code> and <code>PipelineConfig</code>, providing a unified interface to access both project-level and pipeline-specific settings. All configuration classes inherit from <code>BaseConfig</code>, which provides common functionality for configuration management.</p>"},{"location":"api/configuration/#classes","title":"Classes","text":""},{"location":"api/configuration/#baseconfig","title":"BaseConfig","text":"<p>Module: <code>flowerpower.cfg.base.BaseConfig</code></p> <p>The <code>BaseConfig</code> class is the foundation for all configuration classes in FlowerPower. It provides common functionality including YAML serialization/deserialization, dictionary conversion, and configuration manipulation methods.</p> <p>Methods:</p> Method Description <code>to_dict()</code> Converts the configuration instance to a dictionary. <code>to_yaml(path, fs)</code> Saves the configuration to a YAML file using the specified filesystem. <code>from_dict(data)</code> Creates a configuration instance from a dictionary. <code>from_yaml(path, fs)</code> Loads a configuration instance from a YAML file. <code>update(d)</code> Updates this instance with values from the provided dictionary. <code>merge_dict(d)</code> Creates a copy of this instance and updates the copy with values from the provided dictionary. <code>merge(source)</code> Creates a copy of this instance and updates the copy with non-default values from the source struct."},{"location":"api/configuration/#example","title":"Example","text":"<pre><code>from flowerpower.cfg.base import BaseConfig\n\n# Update configuration with dictionary values\nconfig.update({\"param1\": \"value1\", \"nested\": {\"key\": \"value\"}})\n\n# Create a new configuration with merged values\nnew_config = config.merge_dict({\"param2\": \"value2\"})\n\n# Merge with another configuration instance\nmerged_config = config.merge(other_config)\n</code></pre>"},{"location":"api/configuration/#config","title":"Config","text":"<p>Module: <code>flowerpower.cfg.Config</code></p> <p>The <code>Config</code> class is the main configuration class that combines project and pipeline settings. It serves as the central configuration manager and provides a unified interface to access both <code>ProjectConfig</code> and <code>PipelineConfig</code>.</p> <p>Attributes:</p> Attribute Type Description <code>pipeline</code> <code>PipelineConfig</code> A <code>PipelineConfig</code> object containing pipeline-specific settings. <code>project</code> <code>ProjectConfig</code> A <code>ProjectConfig</code> object containing project-level settings. <code>fs</code> <code>AbstractFileSystem \\| None</code> Filesystem abstraction for I/O operations. <code>base_dir</code> <code>str \\| Path \\| None</code> Base directory for the configuration. <code>storage_options</code> <code>dict \\| Munch</code> Options for filesystem operations."},{"location":"api/configuration/#example_1","title":"Example","text":"<pre><code>from flowerpower.cfg import Config\n\n# Load default configuration\nconfig = Config()\n\n# Access project and pipeline settings\nprint(config.project.name)\nprint(config.pipeline.name)\n\n# Load configuration from directory\nconfig = Config.load(base_dir=\"my_project\", name=\"project1\", pipeline_name=\"data-pipeline\")\n\n# Save configuration\nconfig.save(project=True, pipeline=True)\n</code></pre>"},{"location":"api/configuration/#environment-overlays-and-yaml-interpolation","title":"Environment Overlays and YAML Interpolation","text":"<p>FlowerPower applies configuration from multiple sources with a predictable precedence:</p> <ol> <li>Programmatic overrides at execution time (kwargs, <code>RunConfig</code>)</li> <li>Environment overlays via namespaced variables <code>FP_PIPELINE__...</code> / <code>FP_PROJECT__...</code></li> <li>YAML files after environment interpolation (see below)</li> <li>Global env shims like <code>FP_LOG_LEVEL</code>, <code>FP_EXECUTOR</code>, <code>FP_MAX_RETRIES</code> (used only if specific keys are not provided)</li> <li>Code defaults</li> </ol>"},{"location":"api/configuration/#environment-overlays","title":"Environment Overlays","text":"<ul> <li>Nested keys are expressed with double-underscores and mapped to config trees.</li> <li>Examples:</li> <li><code>FP_PIPELINE__RUN__LOG_LEVEL=DEBUG</code></li> <li><code>FP_PIPELINE__RUN__EXECUTOR__TYPE=threadpool</code></li> <li><code>FP_PROJECT__ADAPTER__HAMILTON_TRACKER__API_KEY=...</code></li> <li>Global shims:</li> <li><code>FP_LOG_LEVEL</code>, <code>FP_EXECUTOR</code>, <code>FP_EXECUTOR_MAX_WORKERS</code>, <code>FP_EXECUTOR_NUM_CPUS</code></li> <li><code>FP_MAX_RETRIES</code>, <code>FP_RETRY_DELAY</code>, <code>FP_JITTER_FACTOR</code></li> <li>Values are strictly coerced (bool/int/float); JSON values (objects/arrays) are supported.</li> </ul>"},{"location":"api/configuration/#yaml-environment-interpolation","title":"YAML Environment Interpolation","text":"<p>String values in YAML support Docker Compose\u2013style variable expansion:</p> <pre><code>run:\n  log_level: ${FP_LOG_LEVEL:-INFO}\n  executor: ${FP_PIPELINE__RUN__EXECUTOR:-{\"type\":\"synchronous\"}}\nadapter:\n  hamilton_tracker:\n    api_key: ${HAMILTON_API_KEY:?Missing tracker key}\n</code></pre> <p>Supported syntax: <code>${VAR}</code>, <code>${VAR:-default}</code>, <code>${VAR-default}</code>, <code>${VAR:?err}</code>, <code>${VAR?err}</code>, <code>$${...}</code> to escape. If the final string parses as JSON, it is converted to the corresponding typed value.</p>"},{"location":"api/configuration/#retry-normalization","title":"Retry Normalization","text":"<p><code>RunConfig.retry</code> is the canonical place for retry settings. Legacy top-level fields (<code>max_retries</code>, <code>retry_delay</code>, <code>jitter_factor</code>, <code>retry_exceptions</code>) are still accepted but are normalized into the nested <code>retry</code> block on load and now emit <code>DeprecationWarning</code> when set explicitly. Update configuration files to prefer the nested structure (e.g. <code>retry: {max_retries: 3, retry_delay: 2.0}</code>). Environment shims (<code>FP_MAX_RETRIES</code>, etc.) continue to work but likewise trigger deprecation notices.</p>"},{"location":"api/configuration/#projectconfig","title":"ProjectConfig","text":"<p>Module: <code>flowerpower.cfg.ProjectConfig</code></p> <p>The <code>ProjectConfig</code> class manages project-level settings, including adapter configurations.</p> <p>Attributes:</p> Attribute Type Description <code>name</code> <code>str</code> The name of the project. <code>adapter</code> <code>AdapterConfig</code> An <code>AdapterConfig</code> object for the project-level adapter settings."},{"location":"api/configuration/#example_2","title":"Example","text":"<pre><code>from flowerpower.cfg import ProjectConfig\n\n# Load project configuration\nproject_config = ProjectConfig()\n\n# Access project settings\nprint(project_config.name)\n</code></pre>"},{"location":"api/configuration/#pipelineconfig","title":"PipelineConfig","text":"<p>Module: <code>flowerpower.cfg.PipelineConfig</code></p> <p>The <code>PipelineConfig</code> class manages pipeline-specific settings, including run settings, scheduling, parameters, and adapter configurations.</p> <p>Attributes:</p> Attribute Type Description <code>name</code> <code>str</code> The name of the pipeline. <code>run</code> <code>RunConfig</code> A <code>RunConfig</code> object for pipeline execution settings. <code>schedule</code> <code>ScheduleConfig</code> A <code>ScheduleConfig</code> object for pipeline scheduling. <code>params</code> <code>dict</code> A dictionary of pipeline parameters. <code>adapter</code> <code>AdapterConfig</code> An <code>AdapterConfig</code> object for pipeline-specific adapter settings."},{"location":"api/configuration/#example_3","title":"Example","text":"<pre><code>from flowerpower.cfg import PipelineConfig\n\n# Load pipeline configuration\npipeline_config = PipelineConfig()\n\n# Access pipeline settings\nprint(pipeline_config.name)\nprint(pipeline_config.run.executor)\n</code></pre>"},{"location":"api/configuration/#executorconfig","title":"ExecutorConfig","text":"<p>Module: <code>flowerpower.cfg.ExecutorConfig</code></p> <p>Defines the configuration for the pipeline executor (synchronous or distributed backends).</p> <p>Supported types: <code>\"synchronous\"</code>, <code>\"threadpool\"</code>, <code>\"processpool\"</code>, <code>\"ray\"</code>, <code>\"dask\"</code>.</p> <p>Attributes:</p> Attribute Type Description <code>type</code> <code>str</code> Executor type (see supported types). <code>max_workers</code> <code>int | None</code> Max parallel tasks for thread/process executors. <code>num_cpus</code> <code>int | None</code> CPU allocation for distributed executors (ray/dask)."},{"location":"api/configuration/#examples","title":"Examples","text":"<pre><code>from flowerpower.cfg import ExecutorConfig\n\n# Synchronous (sequential) execution\nExecutorConfig(type=\"synchronous\")\n\n# Thread pool with 4 workers\nExecutorConfig(type=\"threadpool\", max_workers=4)\n\n# Ray with CPU allocation\nExecutorConfig(type=\"ray\", num_cpus=4)\n</code></pre>"},{"location":"api/configuration/#withadapterconfig","title":"WithAdapterConfig","text":"<p>Module: <code>flowerpower.cfg.WithAdapterConfig</code></p> <p>Defines settings for using adapters during pipeline execution.</p> <p>Attributes:</p> Attribute Type Description <code>adapter_name</code> <code>str</code> The name of the adapter. <code>enabled</code> <code>bool</code> Whether the adapter is enabled. <code>config</code> <code>dict</code> Adapter-specific configurations."},{"location":"api/configuration/#example_4","title":"Example","text":"<pre><code>from flowerpower.cfg import WithAdapterConfig\n\n# Create a WithAdapterConfig\nadapter_config = WithAdapterConfig(adapter_name=\"opentelemetry\", enabled=True)\nprint(adapter_config.enabled)\n</code></pre>"},{"location":"api/configuration/#adapterconfig","title":"AdapterConfig","text":"<p>Module: <code>flowerpower.cfg.AdapterConfig</code></p> <p>A base class for adapter configurations, used for both project and pipeline-level settings.</p> <p>Attributes:</p> Attribute Type Description <code>type</code> <code>str</code> The type of adapter. <code>config</code> <code>dict</code> A dictionary of adapter-specific configurations."},{"location":"api/configuration/#example_5","title":"Example","text":"<pre><code>from flowerpower.cfg import AdapterConfig\n\n# Create an AdapterConfig\nadapter_config = AdapterConfig(type=\"tracker\", config={\"project_id\": \"abc\"})\nprint(adapter_config.type)\n</code></pre>"},{"location":"api/create_project/","title":"create_project","text":""},{"location":"api/create_project/#create_project","title":"create_project","text":"<p>Module: <code>flowerpower.flowerpower</code></p> <p>The <code>create_project</code> function either loads an existing FlowerPower project or raises an error if the project does not exist. It is a convenient top-level function.</p> <pre><code>create_project(name: str | None = None, base_dir: str | None = None, storage_options: dict | BaseStorageOptions | None = {}, fs: AbstractFileSystem | None = None, hooks_dir: str = settings.HOOKS_DIR) -&gt; FlowerPowerProject\n</code></pre> <p>Loads an existing FlowerPower project.</p> Parameter Type Description <code>name</code> <code>str</code> | <code>None</code> The name of the project. Defaults to the current directory name. <code>base_dir</code> <code>str</code> | <code>None</code> The base directory where the project will be created or loaded from. Defaults to the current working directory. <code>storage_options</code> <code>dict</code> | <code>BaseStorageOptions</code> | <code>None</code> Storage options for the filesystem. <code>fs</code> <code>AbstractFileSystem</code> | <code>None</code> An instance of AbstractFileSystem to use for file operations. <code>hooks_dir</code> <code>str</code> The directory where the project hooks will be stored. <p>Returns: A <code>FlowerPowerProject</code> instance.</p> <p>Raises: <code>FileNotFoundError</code> if the project does not exist at the specified base directory.</p>"},{"location":"api/create_project/#example","title":"Example","text":"<pre><code>from flowerpower import create_project\n\n# Load an existing project\nproject = create_project(base_dir=\".\")\n\n# Attempt to load a non-existent project (will raise FileNotFoundError)\ntry:\n    project = create_project(base_dir=\"./non_existent_project\")\nexcept FileNotFoundError as e:\n    print(e)\n</code></pre> <p>```python from flowerpower import FlowerPower</p>"},{"location":"api/create_project/#alias-for-create_project","title":"Alias for create_project","text":"<p>project = FlowerPower(base_dir=\".\")</p>"},{"location":"api/executor/","title":"PipelineExecutor","text":""},{"location":"api/executor/#pipelineexecutor","title":"PipelineExecutor","text":"<p>Module: <code>flowerpower.pipeline.executor.PipelineExecutor</code></p> <p>The <code>PipelineExecutor</code> handles pipeline execution with comprehensive parameter handling. It is responsible for executing pipelines with various configurations, merging runtime parameters with pipeline defaults, and delegating to Pipeline objects for execution.</p>"},{"location":"api/executor/#initialization","title":"Initialization","text":""},{"location":"api/executor/#init","title":"init","text":"<pre><code>__init__(self, config_manager: PipelineConfigManager, registry: PipelineRegistry, project_context: Optional[Any] = None)\n</code></pre> <p>Initialize the pipeline executor.</p> <p>Parameters: - <code>config_manager</code>: Configuration manager for accessing pipeline configs - <code>registry</code>: Pipeline registry for accessing pipeline objects - <code>project_context</code>: Optional project context for execution</p> <p>Example: </p><pre><code>from flowerpower.pipeline.config_manager import PipelineConfigManager\nfrom flowerpower.pipeline.registry import PipelineRegistry\n\nconfig_manager = PipelineConfigManager(...)\nregistry = PipelineRegistry(...)\nexecutor = PipelineExecutor(config_manager, registry)\n</code></pre><p></p>"},{"location":"api/executor/#methods","title":"Methods","text":""},{"location":"api/executor/#run","title":"run","text":"<pre><code>run(self, name: str, run_config: RunConfig | None = None, **kwargs) -&gt; dict[str, Any]\n</code></pre> <p>Execute a pipeline synchronously and return its results.</p> <p>This is the main method for running pipelines directly. It loads configuration, builds an execution context, and delegates to the <code>PipelineRunner</code> for Hamilton execution.</p> <p>Parameters: - <code>name</code>: Name of the pipeline to run. Must be a valid identifier. - <code>run_config</code>: Run configuration object containing all execution parameters. If None, the default configuration from the pipeline will be used. - <code>**kwargs</code>: Additional parameters to override the run_config. Supported parameters include inputs, final_vars, config, cache, executor_cfg, with_adapter_cfg, pipeline_adapter_cfg, project_adapter_cfg, adapter, reload, log_level, on_success, on_failure. Legacy retry kwargs (<code>max_retries</code>, <code>retry_delay</code>, <code>jitter_factor</code>, <code>retry_exceptions</code>) are still accepted but emit a <code>DeprecationWarning</code>; prefer setting <code>run_config.retry</code>.</p> <p>Returns: - <code>dict[str, Any]</code>: Pipeline execution results, mapping output variable names to their computed values.</p> <p>Raises: - <code>ValueError</code>: If pipeline configuration cannot be loaded - <code>ImportError</code>: If pipeline module cannot be imported - <code>RuntimeError</code>: If execution fails due to pipeline or adapter errors</p> <p>Example: </p><pre><code>from flowerpower.pipeline import PipelineManager\nfrom flowerpower.cfg.pipeline.run import RunConfig\n\nmanager = PipelineManager()\nconfig = RunConfig(retry={\"max_retries\": 3, \"retry_delay\": 2.0})\nresults = manager.run(\"my_pipeline\", run_config=config)\n</code></pre><p></p>"},{"location":"api/executor/#run_async","title":"run_async","text":"<pre><code>async run_async(self, name: str, run_config: RunConfig | None = None, **kwargs) -&gt; dict[str, Any]\n</code></pre> <p>Execute a pipeline asynchronously and return its results.</p> <p>Parameters: - <code>name</code>: Name of the pipeline to run - <code>run_config</code>: Run configuration object - <code>**kwargs</code>: Additional parameters to override the run_config</p> <p>Returns: - <code>dict[str, Any]</code>: Results of pipeline execution</p> <p>Example: ```python from flowerpower.pipeline import PipelineManager from flowerpower.cfg.pipeline.run import RunConfig</p> <p>manager = PipelineManager() config = RunConfig(retry={\"max_retries\": 2}) results = await manager.run_async(\"my_pipeline\", run_config=config)</p>"},{"location":"api/flowerpower/","title":"FlowerPower","text":""},{"location":"api/flowerpower/#flowerpower","title":"FlowerPower","text":"<p>Module: <code>flowerpower</code></p> <p>The <code>FlowerPower</code> name is an alias for the <code>create_project</code> function. It is the primary entry point for loading FlowerPower projects. It acts as a factory for <code>FlowerPowerProject</code> instances for existing projects; use <code>initialize_project</code> or <code>FlowerPowerProject.new()</code> to create new projects.</p> <p>Note: <code>FlowerPower</code> and <code>create_project</code> are functionally identical. <code>FlowerPower</code> is provided as an alias for convenience and backward compatibility.</p>"},{"location":"api/flowerpower/#initialization","title":"Initialization","text":""},{"location":"api/flowerpower/#create_project-aliased-as-flowerpower","title":"create_project (aliased as FlowerPower)","text":"<pre><code>create_project(name: str | None = None, base_dir: str | None = None, storage_options: dict | BaseStorageOptions | None = {}, fs: AbstractFileSystem | None = None, hooks_dir: str = settings.HOOKS_DIR) -&gt; FlowerPowerProject\n...\n</code></pre> <p>This function is called when you use <code>FlowerPower()</code> or <code>create_project()</code>. It loads an existing project at <code>base_dir</code>. If the project does not exist, it raises <code>FileNotFoundError</code> with guidance to initialize a new project.</p> Parameter Type Description Default <code>name</code> <code>str \\| None</code> The name of the project. If <code>None</code>, it defaults to the current directory name. <code>None</code> <code>base_dir</code> <code>str \\| None</code> The base directory where the project will be created or loaded. If <code>None</code>, it defaults to the current working directory. <code>None</code> <code>storage_options</code> <code>dict \\| BaseStorageOptions \\| None</code> Storage options for the filesystem. <code>{}</code> <code>fs</code> <code>AbstractFileSystem \\| None</code> An fsspec-compatible filesystem instance to use for file operations. If None, uses the <code>get_filesystem</code> helper. <code>None</code> <code>hooks_dir</code> <code>str</code> The directory where the project hooks will be stored. <code>settings.HOOKS_DIR</code> <p>Returns: <code>FlowerPowerProject</code> - An instance of <code>FlowerPowerProject</code> for the loaded project.</p> <p>Raises: <code>FileNotFoundError</code> if the project does not exist at <code>base_dir</code>.</p>"},{"location":"api/flowerpower/#example","title":"Example","text":"<pre><code>from flowerpower import FlowerPower, create_project\n\n# Load a project in the current directory using the alias\nproject = FlowerPower()\n\n# Load a project in a specific directory\nproject = create_project(base_dir=\"/path/to/existing/project\")\n\n# Initialize a new project instead of loading\nfrom flowerpower import initialize_project\nproject = initialize_project(name=\"my-data-project\")\n</code></pre> <p>For documentation on the <code>FlowerPowerProject</code> class and its methods, see FlowerPowerProject.</p>"},{"location":"api/flowerpowerproject/","title":"FlowerPowerProject","text":""},{"location":"api/flowerpowerproject/#flowerpowerproject","title":"FlowerPowerProject","text":"<p>Module: <code>flowerpower.flowerpower.FlowerPowerProject</code></p> <p>The <code>FlowerPowerProject</code> class represents an initialized FlowerPower project, providing an interface to manage pipelines and project-level settings.</p>"},{"location":"api/flowerpowerproject/#initialization","title":"Initialization","text":""},{"location":"api/flowerpowerproject/#init","title":"init","text":"<pre><code>__init__(self, pipeline_manager: PipelineManager)\n...\n</code></pre> <p>Initializes a <code>FlowerPowerProject</code> instance. This constructor is typically called internally by <code>FlowerPowerProject.load()</code> or <code>FlowerPowerProject.new()</code>.</p> Parameter Type Description <code>pipeline_manager</code> <code>PipelineManager</code> An instance of <code>PipelineManager</code> to manage pipelines within this project."},{"location":"api/flowerpowerproject/#attributes","title":"Attributes","text":"Attribute Type Description <code>pipeline_manager</code> <code>PipelineManager</code> Manages pipelines within the project. <code>name</code> <code>str</code> The name of the current project."},{"location":"api/flowerpowerproject/#methods","title":"Methods","text":""},{"location":"api/flowerpowerproject/#run","title":"run","text":"<pre><code>run(self, name: str, run_config: RunConfig | None = None, inputs: dict | None = None, final_vars: list[str] | None = None, config: dict | None = None, cache: dict | None = None, executor_cfg: str | dict | ExecutorConfig | None = None, with_adapter_cfg: dict | WithAdapterConfig | None = None, pipeline_adapter_cfg: dict | PipelineAdapterConfig | None = None, project_adapter_cfg: dict | ProjectAdapterConfig | None = None, adapter: dict[str, Any] | None = None, reload: bool = False, log_level: str | None = None, max_retries: int | None = None, retry_delay: float | None = None, jitter_factor: float | None = None, retry_exceptions: tuple | list | None = None, on_success: Callable | tuple[Callable, tuple | None, dict | None] | None = None, on_failure: Callable | tuple[Callable, tuple | None, dict | None] | None = None) -&gt; dict[str, Any]\n...\n</code></pre> <p>Execute a pipeline synchronously and return its results.</p> <p>Legacy retry kwargs</p> <p>The standalone retry kwargs are retained for backwards compatibility and now emit <code>DeprecationWarning</code>. Prefer supplying retry settings via <code>run_config.retry</code> or the builder helpers.</p> <p>This is a convenience method that delegates to the pipeline manager. It provides the same functionality as <code>self.pipeline_manager.run()</code>.</p> <p>This method supports two primary ways of providing execution configuration: 1. Using a <code>RunConfig</code> object (recommended): Provides a structured way to pass all execution parameters. 2. Using individual parameters (<code>**kwargs</code>): Allows specifying parameters directly, which will override corresponding values in the <code>RunConfig</code> if both are provided.</p> <p>When both <code>run_config</code> and individual parameters (<code>**kwargs</code>) are provided, the individual parameters take precedence over the corresponding values in <code>run_config</code>.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to run. Must be a valid identifier. <code>run_config</code> <code>RunConfig \\| None</code> Configuration object containing all execution parameters. See RunConfig for details. <code>None</code> <code>inputs</code> <code>dict \\| None</code> Override pipeline input values. Example: <code>{\"data_date\": \"2025-04-28\"}</code> <code>None</code> <code>final_vars</code> <code>list[str] \\| None</code> Specify which output variables to return. Example: <code>[\"model\", \"metrics\"]</code> <code>None</code> <code>config</code> <code>dict \\| None</code> Configuration for Hamilton pipeline executor. Example: <code>{\"model\": \"LogisticRegression\"}</code> <code>None</code> <code>cache</code> <code>dict \\| None</code> Cache configuration for results. Example: <code>{\"recompute\": [\"node1\", \"final_node\"]}</code> <code>None</code> <code>executor_cfg</code> <code>str \\| dict \\| ExecutorConfig \\| None</code> Execution configuration, can be: - <code>str</code>: Executor type, one of \"synchronous\", \"threadpool\", \"processpool\", \"ray\", \"dask\" - <code>dict</code>: Raw config, e.g. <code>{\"type\": \"threadpool\", \"max_workers\": 4}</code> - <code>ExecutorConfig</code>: Structured config object <code>None</code> <code>with_adapter_cfg</code> <code>dict \\| WithAdapterConfig \\| None</code> Adapter settings for pipeline execution. Example: <code>{\"opentelemetry\": True, \"tracker\": False}</code> <code>None</code> <code>pipeline_adapter_cfg</code> <code>dict \\| PipelineAdapterConfig \\| None</code> Pipeline-specific adapter settings. Example: <code>{\"tracker\": {\"project_id\": \"123\", \"tags\": {\"env\": \"prod\"}}}</code> <code>None</code> <code>project_adapter_cfg</code> <code>dict \\| ProjectAdapterConfig \\| None</code> Project-level adapter settings. Example: <code>{\"opentelemetry\": {\"host\": \"http://localhost:4317\"}}</code> <code>None</code> <code>adapter</code> <code>dict[str, Any] \\| None</code> Custom adapter instance for pipeline Example: <code>{\"ray_graph_adapter\": RayGraphAdapter()}</code> <code>None</code> <code>reload</code> <code>bool</code> Force reload of pipeline configuration. <code>False</code> <code>log_level</code> <code>str \\| None</code> Logging level for the execution. Valid values: \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\" <code>None</code> <code>max_retries</code> <code>int \\| None</code> Deprecated. Legacy retry override; use <code>run_config.retry</code>. <code>None</code> <code>retry_delay</code> <code>float \\| None</code> Deprecated. Legacy retry override; use <code>run_config.retry</code>. <code>None</code> <code>jitter_factor</code> <code>float \\| None</code> Deprecated. Legacy retry override; use <code>run_config.retry</code>. <code>None</code> <code>retry_exceptions</code> <code>tuple \\| list \\| None</code> Deprecated. Legacy retry override; use <code>run_config.retry</code>. <code>None</code> <code>on_success</code> <code>Callable \\| tuple[Callable, tuple | None, dict | None] \\| None</code> Callback to run on successful pipeline execution. <code>None</code> <code>on_failure</code> <code>Callable \\| tuple[Callable, tuple | None, dict | None] \\| None</code> Callback to run on pipeline execution failure. <code>None</code> <p>Returns: <code>dict[str, Any]</code> - Pipeline execution results, mapping output variable names to their computed values.</p> <p>Raises:</p> <ul> <li><code>ValueError</code>: If pipeline name doesn't exist or configuration is invalid.</li> <li><code>ImportError</code>: If pipeline module cannot be imported.</li> <li><code>RuntimeError</code>: If execution fails due to pipeline or adapter errors.</li> </ul>"},{"location":"api/flowerpowerproject/#example","title":"Example","text":"<pre><code>from flowerpower import FlowerPowerProject\nfrom flowerpower.cfg.pipeline.run import RunConfig\nfrom flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\nproject = FlowerPowerProject.load(\".\")\n\n# Simple execution\nresult = project.run(\"my_pipeline\")\n\n# Using individual parameters (kwargs)\nresult = project.run(\n    \"ml_pipeline\",\n    inputs={\"data_date\": \"2025-01-01\"},\n    final_vars=[\"model\", \"metrics\"]\n)\n\n# Using RunConfig directly\nconfig = RunConfig(\n    inputs={\"data_date\": \"2025-01-01\"},\n    final_vars=[\"model\", \"metrics\"],\n    log_level=\"DEBUG\",\n    retry={\"max_retries\": 2, \"retry_delay\": 1.0}\n)\nresult = project.run(\"ml_pipeline\", run_config=config)\n\n# Using RunConfigBuilder from flowerpower.cfg.pipeline.builder (recommended)\nconfig = (\n    RunConfigBuilder()\n    .with_inputs({\"data_date\": \"2025-01-01\"})\n    .with_final_vars([\"model\", \"metrics\"])\n    .with_log_level(\"DEBUG\")\n    .with_retry_config(max_retries=3, retry_delay=1.0)\n    .build()\n)\nresult = project.run(\"ml_pipeline\", run_config=config)\n\n# Mixing RunConfig with individual parameters (kwargs)\n# Individual parameters take precedence over RunConfig values\nbase_config = RunConfigBuilder().with_log_level(\"INFO\").build()\nresult = project.run(\n    \"ml_pipeline\",\n    run_config=base_config,\n    inputs={\"data_date\": \"2025-01-01\"},  # Overrides inputs in base_config\n    final_vars=[\"model\"]  # Overrides final_vars in base_config\n)\n</code></pre>"},{"location":"api/flowerpowerproject/#load","title":"load","text":"<pre><code>load(cls, base_dir: str | None = None, storage_options: dict | BaseStorageOptions | None = {}, fs: AbstractFileSystem | None = None, log_level: str | None = None) -&gt; \"FlowerPowerProject | None\"\n...\n</code></pre> <p>Load an existing FlowerPower project.</p> <p>If the project does not exist, it returns <code>None</code> and logs an error message.</p> Parameter Type Description Default <code>base_dir</code> <code>str \\| None</code> The base directory of the project. If <code>None</code>, it defaults to the current working directory. <code>None</code> <code>storage_options</code> <code>dict \\| BaseStorageOptions \\| None</code> Storage options for the filesystem. <code>{}</code> <code>fs</code> <code>AbstractFileSystem \\| None</code> An instance of <code>AbstractFileSystem</code> to use for file operations. <code>None</code> <code>log_level</code> <code>str \\| None</code> The logging level to set for the project. If <code>None</code>, it uses the default log level. <code>None</code> <p>Returns: <code>FlowerPowerProject | None</code> - An instance if the project exists, otherwise <code>None</code>.</p>"},{"location":"api/flowerpowerproject/#example_1","title":"Example","text":"<pre><code>from flowerpower import FlowerPowerProject\n\n# Load a project from the current directory\nproject = FlowerPowerProject.load(\".\")\n\n# Load a project from a specific path\nproject = FlowerPowerProject.load(\"/path/to/my/project\")\n</code></pre>"},{"location":"api/flowerpowerproject/#new","title":"new","text":"<pre><code>new(cls, name: str | None = None, base_dir: str | None = None, storage_options: dict | BaseStorageOptions | None = {}, fs: AbstractFileSystem | None = None, hooks_dir: str = settings.HOOKS_DIR, log_level: str | None = None, overwrite: bool = False) -&gt; \"FlowerPowerProject\"\n...\n</code></pre> <p>Initialize a new FlowerPower project.</p> Parameter Type Description Default <code>name</code> <code>str \\| None</code> The name of the project. If <code>None</code>, it defaults to the current directory name. <code>None</code> <code>base_dir</code> <code>str \\| None</code> The base directory where the project will be created. If <code>None</code>, it defaults to the current working directory. <code>None</code> <code>storage_options</code> <code>dict \\| BaseStorageOptions \\| None</code> Storage options for the filesystem. <code>{}</code> <code>fs</code> <code>AbstractFileSystem \\| None</code> An instance of <code>AbstractFileSystem</code> to use for file operations. If None, uses the <code>get_filesystem</code> helper. <code>None</code> <code>hooks_dir</code> <code>str</code> The directory where the project hooks will be stored. <code>settings.HOOKS_DIR</code> <code>log_level</code> <code>str \\| None</code> The logging level to set for the project. If <code>None</code>, it uses the default log level. <code>None</code> <code>overwrite</code> <code>bool</code> Whether to overwrite an existing project at the specified base directory. <code>False</code> <p>Returns: <code>FlowerPowerProject</code> - An instance of <code>FlowerPowerProject</code> initialized with the new project.</p> <p>Raises: <code>FileExistsError</code>: If the project already exists at the specified base directory.</p>"},{"location":"api/flowerpowerproject/#example_2","title":"Example","text":"<pre><code>from flowerpower import FlowerPowerProject\n\n# Initialize a new project in the current directory\nproject = FlowerPowerProject.new()\n\n# Initialize a new project with a specific name\nproject = FlowerPowerProject.new(name=\"my-new-project\")\n</code></pre>"},{"location":"api/initialize_project/","title":"initialize_project","text":""},{"location":"api/initialize_project/#initialize_project","title":"initialize_project","text":"<p>Module: <code>flowerpower.flowerpower</code></p> <p>The <code>initialize_project</code> function initializes a new FlowerPower project. It is a convenient top-level function that wraps <code>FlowerPowerProject.new()</code>.</p> <pre><code>initialize_project(name: str | None = None, base_dir: str | None = None, storage_options: dict | BaseStorageOptions | None = {}, fs: AbstractFileSystem | None = None, hooks_dir: str = settings.HOOKS_DIR, log_level: str | None = None) -&gt; FlowerPowerProject\n</code></pre> <p>Initializes a new FlowerPower project.</p> Parameter Type Description <code>name</code> <code>str</code> | <code>None</code> The name of the project. Defaults to the current directory name. <code>base_dir</code> <code>str</code> | <code>None</code> The base directory where the project will be created. Defaults to the current working directory. <code>storage_options</code> <code>dict</code> | <code>BaseStorageOptions</code> | <code>None</code> Storage options for the filesystem. <code>fs</code> <code>AbstractFileSystem</code> | <code>None</code> An instance of AbstractFileSystem to use for file operations. <code>hooks_dir</code> <code>str</code> The directory where the project hooks will be stored. <code>log_level</code> <code>str</code> | <code>None</code> The logging level to set for the project. If None, it uses the default log level. <p>Returns: A <code>FlowerPowerProject</code> instance initialized with the new project.</p> <p>Raises: <code>FileExistsError</code> if the project already exists at the specified base directory.</p>"},{"location":"api/initialize_project/#example","title":"Example","text":"<p>```python from flowerpower import initialize_project</p>"},{"location":"api/initialize_project/#initialize-a-new-project","title":"Initialize a new project","text":"<p>project = initialize_project(name=\"my-new-project\")</p>"},{"location":"api/initialize_project/#to-overwrite-an-existing-project-use-flowerpowerprojectnew-overwritetrue","title":"To overwrite an existing project, use <code>FlowerPowerProject.new(..., overwrite=True)</code>","text":""},{"location":"api/pipelinemanager/","title":"PipelineManager","text":""},{"location":"api/pipelinemanager/#pipelinemanager","title":"PipelineManager","text":"<p>Module: <code>flowerpower.pipeline.PipelineManager</code></p> <p>The <code>PipelineManager</code> is the central class for managing pipeline operations in FlowerPower. It provides a unified interface for creating, running, and managing pipelines.</p>"},{"location":"api/pipelinemanager/#initialization","title":"Initialization","text":""},{"location":"api/pipelinemanager/#init","title":"init","text":"<pre><code>__init__(self, base_dir: str | None = None, storage_options: dict | Munch | BaseStorageOptions | None = None, fs: AbstractFileSystem | None = None, cfg_dir: str | None = None, pipelines_dir: str | None = None, log_level: str | None = None)\n</code></pre> <p>Initializes the <code>PipelineManager</code>, setting up project paths and loading configurations.</p> Parameter Type Description <code>base_dir</code> <code>str \\| None</code> The base directory of the project. Defaults to the current working directory. <code>storage_options</code> <code>dict \\| Munch \\| BaseStorageOptions \\| None</code> Configuration options for filesystem access (e.g., S3, GCS). <code>fs</code> <code>AbstractFileSystem \\| None</code> An fsspec-compatible filesystem instance. <code>cfg_dir</code> <code>str \\| None</code> Override the default configuration directory name. <code>pipelines_dir</code> <code>str \\| None</code> Override the default pipelines directory name. <code>log_level</code> <code>str \\| None</code> The logging level for the manager. <p>Example:</p> <pre><code>from flowerpower.pipeline import PipelineManager\n\n# Initialize a manager for the project in the current directory\nmanager = PipelineManager()\n</code></pre>"},{"location":"api/pipelinemanager/#methods","title":"Methods","text":""},{"location":"api/pipelinemanager/#attributes","title":"Attributes","text":"Attribute Type Description <code>registry</code> <code>PipelineRegistry</code> Handles pipeline registration and discovery. <code>visualizer</code> <code>PipelineVisualizer</code> Handles pipeline visualization. <code>io</code> <code>PipelineIOManager</code> Handles pipeline import/export operations, consolidating common logic. <code>project_cfg</code> <code>ProjectConfig</code> Current project configuration. <code>pipeline_cfg</code> <code>PipelineConfig</code> Current pipeline configuration. <code>pipelines</code> <code>list[str]</code> List of available pipeline names. <code>current_pipeline_name</code> <code>str</code> Name of the currently loaded pipeline. <code>summary</code> <code>dict[str, dict \\| str]</code> Summary of all pipelines. <code>_base_dir</code> <code>str</code> The base directory of the project. <code>_fs</code> <code>AbstractFileSystem</code> The filesystem instance used by the manager. <code>_storage_options</code> <code>dict \\| Munch \\| BaseStorageOptions</code> Storage options for the filesystem. <code>_cfg_dir</code> <code>str</code> The directory for configuration files. <code>_pipelines_dir</code> <code>str</code> The directory for pipeline modules. <code>_project_context</code> <code>FlowerPowerProject \\| None</code> Reference to the FlowerPowerProject instance."},{"location":"api/pipelinemanager/#methods_1","title":"Methods","text":""},{"location":"api/pipelinemanager/#run","title":"run","text":"<pre><code>run(self, name: str, run_config: RunConfig | None = None, inputs: dict | None = None, final_vars: list[str] | None = None, config: dict | None = None, cache: dict | None = None, executor_cfg: str | dict | ExecutorConfig | None = None, with_adapter_cfg: dict | WithAdapterConfig | None = None, pipeline_adapter_cfg: dict | PipelineAdapterConfig | None = None, project_adapter_cfg: dict | ProjectAdapterConfig | None = None, adapter: dict[str, Any] | None = None, reload: bool = False, log_level: str | None = None, max_retries: int | None = None, retry_delay: float | None = None, jitter_factor: float | None = None, retry_exceptions: tuple | list | None = None, on_success: Callable | tuple[Callable, tuple | None, dict | None] | None = None, on_failure: Callable | tuple[Callable, tuple | None, dict | None] | None = None)\n</code></pre> <p>Execute a pipeline synchronously and return its results. Parameters related to retries (<code>max_retries</code>, <code>retry_delay</code>, <code>jitter_factor</code>, <code>retry_exceptions</code>) configure the internal retry mechanism.</p> <p>Legacy retry kwargs</p> <p>The standalone retry kwargs are retained for backwards compatibility and now emit <code>DeprecationWarning</code>. Prefer supplying retry settings via <code>run_config.retry</code> or the builder helpers.</p> <p>This method supports two primary ways of providing execution configuration: 1. Using a <code>RunConfig</code> object (recommended): Provides a structured way to pass all execution parameters. 2. Using individual parameters (<code>**kwargs</code>): Allows specifying parameters directly, which will override corresponding values in the <code>RunConfig</code> if both are provided.</p> <p>When both <code>run_config</code> and individual parameters (<code>**kwargs</code>) are provided, the individual parameters take precedence over the corresponding values in <code>run_config</code>.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to run. Must be a valid identifier. <code>run_config</code> <code>RunConfig \\| None</code> Configuration object containing all execution parameters. See RunConfig for details. <code>None</code> <code>inputs</code> <code>dict \\| None</code> Override pipeline input values. Example: <code>{\"data_date\": \"2025-04-28\"}</code> <code>None</code> <code>final_vars</code> <code>list[str] \\| None</code> Specify which output variables to return. Example: <code>[\"model\", \"metrics\"]</code> <code>None</code> <code>config</code> <code>dict \\| None</code> Configuration for Hamilton pipeline executor. Example: <code>{\"model\": \"LogisticRegression\"}</code> <code>None</code> <code>cache</code> <code>dict \\| None</code> Cache configuration for results. Example: <code>{\"recompute\": [\"node1\", \"final_node\"]}</code> <code>None</code> <code>executor_cfg</code> <code>str \\| dict \\| ExecutorConfig \\| None</code> Execution configuration, can be: - <code>str</code>: Executor type, one of \"synchronous\", \"threadpool\", \"processpool\", \"ray\", \"dask\" - <code>dict</code>: Raw config, e.g. <code>{\"type\": \"threadpool\", \"max_workers\": 4}</code> - <code>ExecutorConfig</code>: Structured config object <code>None</code> <code>with_adapter_cfg</code> <code>dict \\| WithAdapterConfig \\| None</code> Adapter settings for pipeline execution. Example: <code>{\"opentelemetry\": True, \"tracker\": False}</code> <code>None</code> <code>pipeline_adapter_cfg</code> <code>dict \\| PipelineAdapterConfig \\| None</code> Pipeline-specific adapter settings. Example: <code>{\"tracker\": {\"project_id\": \"123\", \"tags\": {\"env\": \"prod\"}}}</code> <code>None</code> <code>project_adapter_cfg</code> <code>dict \\| ProjectAdapterConfig \\| None</code> Project-level adapter settings. Example: <code>{\"opentelemetry\": {\"host\": \"http://localhost:4317\"}}</code> <code>None</code> <code>adapter</code> <code>dict[str, Any] \\| None</code> Custom adapter instance for pipeline Example: <code>{\"ray_graph_adapter\": RayGraphAdapter()}</code> <code>None</code> <code>reload</code> <code>bool</code> Force reload of pipeline configuration. <code>False</code> <code>log_level</code> <code>str \\| None</code> Logging level for the execution. Valid values: \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\" <code>None</code> <code>max_retries</code> <code>int \\| None</code> Deprecated. Legacy retry override; use <code>run_config.retry</code>. <code>None</code> <code>retry_delay</code> <code>float \\| None</code> Deprecated. Legacy retry override; use <code>run_config.retry</code>. <code>None</code> <code>jitter_factor</code> <code>float \\| None</code> Deprecated. Legacy retry override; use <code>run_config.retry</code>. <code>None</code> <code>retry_exceptions</code> <code>tuple \\| list \\| None</code> Deprecated. Legacy retry override; use <code>run_config.retry</code>. <code>None</code> <code>on_success</code> <code>Callable \\| tuple[Callable, tuple \\| None, dict \\| None] \\| None</code> Callback to run on successful pipeline execution. <code>None</code> <code>on_failure</code> <code>Callable \\| tuple[Callable, tuple \\| None, dict \\| None] \\| None</code> Callback to run on pipeline execution failure. <code>None</code> <p>Returns: <code>dict[str, Any]</code> - Pipeline execution results, mapping output variable names to their computed values.</p> <p>Raises:</p> <ul> <li><code>ValueError</code>: If pipeline name doesn't exist or configuration is invalid.</li> <li><code>ImportError</code>: If pipeline module cannot be imported.</li> <li><code>RuntimeError</code>: If execution fails due to pipeline or adapter errors.</li> </ul>"},{"location":"api/pipelinemanager/#example","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\nfrom flowerpower.cfg.pipeline.run import RunConfig\nfrom flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\nmanager = PipelineManager()\n\n# Simple execution\nresult = manager.run(\"my_pipeline\")\n\n# Using individual parameters (kwargs)\nresult = manager.run(\n    \"ml_pipeline\",\n    inputs={\"data_date\": \"2025-01-01\"},\n    final_vars=[\"model\", \"metrics\"]\n)\n\n# Using RunConfig directly\nconfig = RunConfig(\n    inputs={\"data_date\": \"2025-01-01\"},\n    final_vars=[\"model\", \"metrics\"],\n    log_level=\"DEBUG\"\n)\nresult = manager.run(\"ml_pipeline\", run_config=config)\n\n# Using RunConfigBuilder from flowerpower.cfg.pipeline.builder (recommended)\nconfig = (\n    RunConfigBuilder()\n    .with_inputs({\"data_date\": \"2025-01-01\"})\n    .with_final_vars([\"model\", \"metrics\"])\n    .with_log_level(\"DEBUG\")\n    .with_retry_config(max_retries=3, retry_delay=1.0)\n    .build()\n)\nresult = manager.run(\"ml_pipeline\", run_config=config)\n\n# Mixing RunConfig with individual parameters (kwargs)\n# Individual parameters take precedence over RunConfig values\nbase_config = RunConfigBuilder().with_log_level(\"INFO\").build()\nresult = manager.run(\n    \"ml_pipeline\",\n    run_config=base_config,\n    inputs={\"data_date\": \"2025-01-01\"},  # Overrides inputs in base_config\n    final_vars=[\"model\"]  # Overrides final_vars in base_config\n)\n</code></pre>"},{"location":"api/pipelinemanager/#new","title":"new","text":"<pre><code>new(self, name: str, overwrite: bool = False)\n</code></pre> <p>Create a new pipeline with the given name.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name for the new pipeline. Must be a valid Python identifier. <code>overwrite</code> <code>bool</code> Whether to overwrite existing pipeline with same name. <code>False</code> <p>Returns: <code>None</code></p> <p>Raises:</p> <ul> <li><code>ValueError</code>: If name is invalid or pipeline exists and overwrite=<code>False</code>.</li> <li><code>RuntimeError</code>: If file creation fails.</li> <li><code>PermissionError</code>: If lacking write permissions.</li> </ul>"},{"location":"api/pipelinemanager/#example_1","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\n# Create new pipeline\nmanager = PipelineManager()\nmanager.new(\"data_transformation\")\n\n# Overwrite existing pipeline\nmanager.new(\"data_transformation\", overwrite=True)\n</code></pre>"},{"location":"api/pipelinemanager/#delete","title":"delete","text":"<pre><code>delete(self, name: str)\n</code></pre> <p>Delete an existing pipeline.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to delete. <p>Returns: <code>None</code></p> <p>Raises:</p> <ul> <li><code>FileNotFoundError</code>: If the pipeline does not exist.</li> <li><code>RuntimeError</code>: If deletion fails.</li> </ul>"},{"location":"api/pipelinemanager/#example_2","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\nmanager = PipelineManager()\nmanager.delete(\"old_pipeline\")\n</code></pre>"},{"location":"api/pipelinemanager/#show_pipelines","title":"show_pipelines","text":"<pre><code>show_pipelines(self, format: str = \"table\") -&gt; None\n</code></pre> <p>Display a summary of all available pipelines.</p> Parameter Type Description Default <code>format</code> <code>str</code> Output format (\"table\", \"json\", \"yaml\"). <code>\"table\"</code> <p>Returns: <code>None</code></p>"},{"location":"api/pipelinemanager/#list_pipelines","title":"list_pipelines","text":"<pre><code>list_pipelines(self) -&gt; list[str]\n</code></pre> <p>Return a sorted list of available pipeline names.</p>"},{"location":"api/pipelinemanager/#example_3","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\nmanager = PipelineManager()\n\n# Show pipelines in table format (default)\nmanager.show_pipelines()\n\n# Show pipelines in JSON format\nmanager.show_pipelines(format=\"json\")\n</code></pre>"},{"location":"api/pipelinemanager/#add_hook","title":"add_hook","text":"<pre><code>add_hook(self, name: str, type: HookType, to: str, function_name: str)\n</code></pre> <p>Add a hook to a specific pipeline.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to add the hook to. <code>type</code> <code>HookType</code> Type of the hook (e.g., <code>HookType.MQTT_BUILD_CONFIG</code>). <code>to</code> <code>str</code> Destination of the hook (e.g., \"mqtt\"). <code>function_name</code> <code>str</code> Name of the function to be called as the hook. <p>Returns: <code>None</code></p> <p>Raises:</p> <ul> <li><code>ValueError</code>: If the pipeline does not exist or hook type is invalid.</li> <li><code>FileExistsError</code>: If a hook with the same name and type already exists.</li> </ul>"},{"location":"api/pipelinemanager/#example_4","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager, HookType\n\nmanager = PipelineManager()\nmanager.add_hook(\n    name=\"my_pipeline\",\n    type=HookType.MQTT_BUILD_CONFIG,\n    to=\"mqtt\",\n    function_name=\"build_mqtt_config\"\n)\n</code></pre>"},{"location":"api/pipelinemanager/#remove_hook","title":"remove_hook","text":"<pre><code>remove_hook(self, name: str, type: HookType, function_name: str)\n</code></pre> <p>Remove a hook from a specific pipeline.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to remove the hook from. <code>type</code> <code>HookType</code> Type of the hook to remove. <code>function_name</code> <code>str</code> Name of the function that was used as the hook. <p>Returns: <code>None</code></p> <p>Raises: <code>FileNotFoundError</code>: If the pipeline or hook does not exist.</p>"},{"location":"api/pipelinemanager/#example_5","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager, HookType\n\nmanager = PipelineManager()\nmanager.remove_hook(\n    name=\"my_pipeline\",\n    type=HookType.MQTT_BUILD_CONFIG,\n    function_name=\"build_mqtt_config\"\n)\n</code></pre>"},{"location":"api/pipelinemanager/#import_pipeline","title":"import_pipeline","text":"<pre><code>import_pipeline(self, name: str, src_base_dir: str, src_fs: AbstractFileSystem | None = None, src_storage_options: dict | BaseStorageOptions | None = None, overwrite: bool = False)\n</code></pre> <p>Import a pipeline from another FlowerPower project.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name for the new pipeline in the current project. <code>src_base_dir</code> <code>str</code> Source FlowerPower project directory or URI. Examples: - Local: <code>\"/path/to/other/project\"</code> - S3: <code>\"s3://bucket/project\"</code> - GitHub: <code>\"github://org/repo/project\"</code> <code>src_fs</code> <code>AbstractFileSystem \\| None</code> Pre-configured source filesystem. Example: <code>S3FileSystem(anon=False)</code> <code>None</code> <code>src_storage_options</code> <code>dict \\| BaseStorageOptions \\| None</code> Options for source filesystem access. Example: <code>{\"key\": \"ACCESS_KEY\", \"secret\": \"SECRET_KEY\"}</code> <code>None</code> <code>overwrite</code> <code>bool</code> Whether to replace existing pipeline if name exists. <code>False</code> <p>Returns: <code>None</code></p> <p>Raises:</p> <ul> <li><code>ValueError</code>: If pipeline name exists and <code>overwrite=False</code>.</li> <li><code>FileNotFoundError</code>: If source pipeline not found.</li> <li><code>RuntimeError</code>: If import fails.</li> </ul>"},{"location":"api/pipelinemanager/#example_6","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\nfrom s3fs import S3FileSystem\n\nmanager = PipelineManager()\n\n# Import from local filesystem\nmanager.import_pipeline(\n    \"new_pipeline\",\n    \"/path/to/other/project\"\n)\n\n# Import from S3 with custom filesystem\ns3 = S3FileSystem(anon=False)\nmanager.import_pipeline(\n    \"s3_pipeline\",\n    \"s3://bucket/project\",\n    src_fs=s3\n)\n</code></pre>"},{"location":"api/pipelinemanager/#import_many","title":"import_many","text":"<pre><code>import_many(self, names: list[str], src_base_dir: str, src_fs: AbstractFileSystem | None = None, src_storage_options: dict | BaseStorageOptions | None = None, overwrite: bool = False)\n</code></pre> <p>Import multiple pipelines from another FlowerPower project.</p> Parameter Type Description Default <code>names</code> <code>list[str]</code> List of pipeline names to import. <code>src_base_dir</code> <code>str</code> Source FlowerPower project directory or URI. Examples: - Local: <code>\"/path/to/other/project\"</code> - S3: <code>\"s3://bucket/project\"</code> - GitHub: <code>\"github://org/repo/project\"</code> <code>src_fs</code> <code>AbstractFileSystem \\| None</code> Pre-configured source filesystem. Example: <code>S3FileSystem(anon=False)</code> <code>None</code> <code>src_storage_options</code> <code>dict \\| BaseStorageOptions \\| None</code> Options for source filesystem access. Example: <code>{\"key\": \"ACCESS_KEY\", \"secret\": \"SECRET_KEY\"}</code> <code>None</code> <code>overwrite</code> <code>bool</code> Whether to replace existing pipelines if names exist. <code>False</code> <p>Returns: <code>None</code></p> <p>Raises:</p> <ul> <li><code>ValueError</code>: If any pipeline name exists and <code>overwrite=False</code>.</li> <li><code>FileNotFoundError</code>: If any source pipeline not found.</li> <li><code>RuntimeError</code>: If import fails.</li> </ul>"},{"location":"api/pipelinemanager/#example_7","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\nmanager = PipelineManager()\n\n# Import multiple pipelines\nmanager.import_many(\n    names=[\"pipeline1\", \"pipeline2\"],\n    src_base_dir=\"/path/to/other/project\"\n)\n\n# Import multiple pipelines from S3\nmanager.import_many(\n    names=[\"s3_pipeline_a\", \"s3_pipeline_b\"],\n    src_base_dir=\"s3://bucket/source\",\n    src_storage_options={\n        \"key\": \"ACCESS_KEY\",\n        \"secret\": \"SECRET_KEY\"\n    }\n)\n</code></pre>"},{"location":"api/pipelinemanager/#export_pipeline","title":"export_pipeline","text":"<pre><code>export_pipeline(self, name: str, dest_base_dir: str, dest_fs: AbstractFileSystem | None = None, dest_storage_options: dict | BaseStorageOptions | None = None, overwrite: bool = False)\n</code></pre> <p>Export a pipeline to another FlowerPower project.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to export. <code>dest_base_dir</code> <code>str</code> Destination FlowerPower project directory or URI. Examples: - Local: <code>\"/path/to/backup\"</code> - S3: <code>\"s3://bucket/backups\"</code> - GCS: <code>\"gs://bucket/backups\"</code> <code>dest_fs</code> <code>AbstractFileSystem \\| None</code> Pre-configured destination filesystem. Example: <code>GCSFileSystem(project='my-project')</code> <code>None</code> <code>dest_storage_options</code> <code>dict \\| BaseStorageOptions \\| None</code> Options for destination filesystem access. Example: <code>{\"token\": \"my_token\"}</code> <code>None</code> <code>overwrite</code> <code>bool</code> Whether to replace existing pipeline in destination if name exists. <code>False</code> <p>Returns: <code>None</code></p> <p>Raises:</p> <ul> <li><code>FileNotFoundError</code>: If the pipeline does not exist in the current project.</li> <li><code>FileExistsError</code>: If destination pipeline exists and <code>overwrite=False</code>.</li> <li><code>RuntimeError</code>: If export fails.</li> </ul>"},{"location":"api/pipelinemanager/#example_8","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\nfrom gcsfs import GCSFileSystem\n\nmanager = PipelineManager()\n\n# Export to local backup\nmanager.export_pipeline(\n    \"my_pipeline\",\n    \"/path/to/backup\"\n)\n\n# Export to Google Cloud Storage\ngcs = GCSFileSystem(project='my-project')\nmanager.export_pipeline(\n    \"prod_pipeline\",\n    \"gs://my-bucket/backups\",\n    dest_fs=gcs\n)\n</code></pre>"},{"location":"api/pipelinemanager/#export_many","title":"export_many","text":"<pre><code>export_many(self, names: list[str], dest_base_dir: str, dest_fs: AbstractFileSystem | None = None, dest_storage_options: dict | BaseStorageOptions | None = None, overwrite: bool = False)\n</code></pre> <p>Export multiple pipelines to another FlowerPower project.</p> Parameter Type Description Default <code>names</code> <code>list[str]</code> List of pipeline names to export. <code>dest_base_dir</code> <code>str</code> Destination FlowerPower project directory or URI. Examples: - Local: <code>\"/path/to/backup\"</code> - S3: <code>\"s3://bucket/backups\"</code> - GCS: <code>\"gs://bucket/backups\"</code> <code>dest_fs</code> <code>AbstractFileSystem \\| None</code> Pre-configured destination filesystem. Example: <code>GCSFileSystem(project='my-project')</code> <code>None</code> <code>dest_storage_options</code> <code>dict \\| BaseStorageOptions \\| None</code> Options for destination filesystem access. Example: <code>{\"token\": \"my_token\"}</code> <code>None</code> <code>overwrite</code> <code>bool</code> Whether to replace existing pipelines in destination if names exist. <code>False</code> <p>Returns: <code>None</code></p> <p>Raises:</p> <ul> <li><code>FileNotFoundError</code>: If any pipeline does not exist in the current project.</li> <li><code>FileExistsError</code>: If any destination pipeline exists and <code>overwrite=False</code>.</li> <li><code>RuntimeError</code>: If export fails.</li> </ul>"},{"location":"api/pipelinemanager/#example_9","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\nmanager = PipelineManager()\n\n# Export multiple pipelines\nmanager.export_many(\n    names=[\"pipeline1\", \"pipeline2\"],\n    dest_base_dir=\"/path/to/backup\"\n)\n\n# Export multiple pipelines from S3\nmanager.export_many(\n    names=[\"s3_pipeline_a\", \"s3_pipeline_b\"],\n    dest_base_dir=\"s3://bucket/backups\",\n    dest_storage_options={\n        \"key\": \"ACCESS_KEY\",\n        \"secret\": \"SECRET_KEY\"\n    }\n)\n</code></pre>"},{"location":"api/pipelinemanager/#show_dag","title":"show_dag","text":"<pre><code>show_dag(self, name: str, format: str = \"png\", show_outputs: bool = False, display_html: bool = False)\n</code></pre> <p>Generate and display the Directed Acyclic Graph (DAG) of a pipeline.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to visualize. <code>format</code> <code>str</code> Output format for the DAG (\"png\", \"svg\", \"html\", \"dot\"). <code>\"png\"</code> <code>show_outputs</code> <code>bool</code> Whether to include output nodes in the DAG. <code>False</code> <code>display_html</code> <code>bool</code> Whether to display the HTML directly in the notebook (only for \"html\" format). <code>False</code> <p>Returns: <code>None</code> (displays the DAG directly or saves it to a file).</p> <p>Raises:</p> <ul> <li><code>FileNotFoundError</code>: If the pipeline does not exist.</li> <li><code>ValueError</code>: If format is invalid or visualization fails.</li> </ul>"},{"location":"api/pipelinemanager/#example_10","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\nmanager = PipelineManager()\n\n# Show DAG as PNG\nmanager.show_dag(\"my_pipeline\")\n\n# Show DAG as SVG with outputs\nmanager.show_dag(\"ml_pipeline\", format=\"svg\", show_outputs=True)\n</code></pre>"},{"location":"api/pipelinemanager/#show_execution_graph","title":"show_execution_graph","text":"<pre><code>show_execution_graph(self, name: str, format: str = \"png\", show_outputs: bool = False, display_html: bool = False, inputs: dict | None = None, config: dict | None = None)\n</code></pre> <p>Generate and display the execution graph of a pipeline, considering inputs and configuration.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to visualize. <code>format</code> <code>str</code> Output format for the graph (\"png\", \"svg\", \"html\", \"dot\"). <code>\"png\"</code> <code>show_outputs</code> <code>bool</code> Whether to include output nodes in the graph. <code>False</code> <code>display_html</code> <code>bool</code> Whether to display the HTML directly in the notebook (only for \"html\" format). <code>False</code> <code>inputs</code> <code>dict \\| None</code> Input values to consider for graph generation. <code>None</code> <code>config</code> <code>dict \\| None</code> Configuration for Hamilton pipeline executor. <code>None</code> <p>Returns: <code>None</code> (displays the graph directly or saves it to a file).</p> <p>Raises:</p> <ul> <li><code>FileNotFoundError</code>: If the pipeline does not exist.</li> <li><code>ValueError</code>: If format is invalid or visualization fails.</li> </ul>"},{"location":"api/pipelinemanager/#example_11","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\nmanager = PipelineManager()\n\n# Show execution graph\nmanager.show_execution_graph(\"my_pipeline\", inputs={\"data_date\": \"2025-01-01\"})\n</code></pre>"},{"location":"api/registry/","title":"PipelineRegistry","text":""},{"location":"api/registry/#pipelineregistry","title":"PipelineRegistry","text":"<p>Module: <code>flowerpower.pipeline.registry.PipelineRegistry</code></p> <p>The PipelineRegistry manages discovery, listing, creation, and deletion of pipelines. It handles caching of pipeline data and provides methods for pipeline lifecycle management.</p>"},{"location":"api/registry/#initialization","title":"Initialization","text":""},{"location":"api/registry/#from_filesystem","title":"from_filesystem","text":"<pre><code>@classmethod\nfrom_filesystem(base_dir: str, fs: AbstractFileSystem | None = None, storage_options: dict | None = None) -&gt; PipelineRegistry\n</code></pre> <p>Create a PipelineRegistry from filesystem parameters.</p> <p>This factory method creates a complete PipelineRegistry instance by: 1. Creating the filesystem if not provided 2. Loading the ProjectConfig from the base directory 3. Initializing the registry with the loaded configuration</p> <p>Parameters: - <code>base_dir</code>: The base directory path for the FlowerPower project - <code>fs</code>: Optional filesystem instance. If None, will be created from base_dir - <code>storage_options</code>: Optional storage options for filesystem access</p> <p>Returns: PipelineRegistry - A fully configured registry instance</p> <p>Raises: - ValueError: If base_dir is invalid or ProjectConfig cannot be loaded - RuntimeError: If filesystem creation fails</p> <p>Example: </p><pre><code># Create registry from local directory\nregistry = PipelineRegistry.from_filesystem(\"/path/to/project\")\n\n# Create registry with S3 storage\nregistry = PipelineRegistry.from_filesystem(\n    \"s3://my-bucket/project\",\n    storage_options={\"key\": \"ACCESS_KEY\", \"secret\": \"SECRET_KEY\"}\n)\n</code></pre><p></p>"},{"location":"api/registry/#methods","title":"Methods","text":""},{"location":"api/registry/#get_pipeline","title":"get_pipeline","text":"<pre><code>get_pipeline(self, name: str, project_context: FlowerPowerProject, reload: bool = False) -&gt; Pipeline\n</code></pre> <p>Get a Pipeline instance for the given name.</p> <p>This method creates a fully-formed Pipeline object by loading its configuration and Python module, then injecting the project context.</p> <p>Parameters: - <code>name</code>: Name of the pipeline to get - <code>project_context</code>: Reference to the FlowerPowerProject - <code>reload</code>: Whether to reload configuration and module from disk</p> <p>Returns: Pipeline instance ready for execution</p> <p>Raises: - FileNotFoundError: If pipeline configuration or module doesn't exist - ImportError: If pipeline module cannot be imported - ValueError: If pipeline configuration is invalid</p> <p>Example: </p><pre><code>from flowerpower import FlowerPowerProject\n\nproject = FlowerPowerProject.load(\".\")\nregistry = project.pipeline_manager.registry\n\npipeline = registry.get_pipeline(\"my_pipeline\", project)\n</code></pre><p></p>"},{"location":"api/registry/#new","title":"new","text":"<pre><code>new(self, name: str, overwrite: bool = False)\n</code></pre> <p>Add a pipeline with the given name.</p> <p>Parameters: - <code>name</code>: Name for the new pipeline. Must be a valid Python identifier. - <code>overwrite</code>: Whether to overwrite existing pipeline with same name. Defaults to False.</p> <p>Raises: - ValueError: If the configuration or pipeline path does not exist, or if the pipeline already exists.</p> <p>Example: </p><pre><code>registry.new(\"my_new_pipeline\")\n</code></pre><p></p>"},{"location":"api/registry/#delete","title":"delete","text":"<pre><code>delete(self, name: str, cfg: bool = True, module: bool = False)\n</code></pre> <p>Delete a pipeline.</p> <p>Parameters: - <code>name</code>: Name of the pipeline to delete - <code>cfg</code>: Whether to delete the config file. Defaults to True. - <code>module</code>: Whether to delete the module file. Defaults to False.</p> <p>Returns: None</p> <p>Raises: - FileNotFoundError: If the specified files do not exist.</p> <p>Example: </p><pre><code>registry.delete(\"old_pipeline\")\n</code></pre><p></p>"},{"location":"api/registry/#show_pipelines","title":"show_pipelines","text":"<pre><code>show_pipelines(self) -&gt; None\n</code></pre> <p>Print all available pipelines in a formatted table.</p> <p>Example: </p><pre><code>registry.show_pipelines()\n</code></pre><p></p>"},{"location":"api/registry/#list_pipelines","title":"list_pipelines","text":"<pre><code>list_pipelines(self) -&gt; list[str]\n</code></pre> <p>Get a list of all available pipeline names.</p> <p>Returns: List of pipeline names, sorted alphabetically.</p> <p>Example: </p><pre><code>pipelines = registry.list_pipelines()\nprint(pipelines)\n['data_ingestion', 'model_training', 'reporting']\n</code></pre><p></p>"},{"location":"api/registry/#pipelines-property","title":"pipelines (Property)","text":"<pre><code>pipelines: list[str]\n</code></pre> <p>Get list of all available pipeline names.</p> <p>Returns: List of pipeline names.</p> <p>Example: </p><pre><code>print(registry.pipelines)\n['data_ingestion', 'model_training', 'reporting']\n</code></pre><p></p>"},{"location":"api/registry/#summary-property","title":"summary (Property)","text":"<pre><code>summary: dict[str, dict | str]\n</code></pre> <p>Get complete summary of all pipelines.</p> <p>Returns: Full summary including configuration, code, and project settings for all pipelines.</p> <p>Example: </p><pre><code>summary = registry.summary\nfor name, details in summary.items():\n    print(f\"{name}: {details.get('cfg', {}).get('type')}\")\ndata_pipeline: batch\nml_pipeline: streaming\n</code></pre><p></p>"},{"location":"api/registry/#get_summary","title":"get_summary","text":"<pre><code>get_summary(self, name: str | None = None, cfg: bool = True, code: bool = True, project: bool = True) -&gt; dict[str, dict | str]\n</code></pre> <p>Get a detailed summary of pipeline(s) configuration and code.</p> <p>Parameters: - <code>name</code>: Specific pipeline to summarize. If None, summarizes all. - <code>cfg</code>: Include pipeline configuration details. Default True. - <code>code</code>: Include pipeline module code. Default True. - <code>project</code>: Include project configuration. Default True.</p> <p>Returns: Nested dictionary containing requested summaries.</p> <p>Example: </p><pre><code>summary = registry.get_summary(\"data_pipeline\")\nprint(summary[\"pipelines\"][\"data_pipeline\"][\"cfg\"][\"schedule\"][\"enabled\"])\nTrue\n</code></pre><p></p>"},{"location":"api/registry/#add_hook","title":"add_hook","text":"<pre><code>add_hook(self, name: str, type: HookType, to: str | None = None, function_name: str | None = None) -&gt; None\n</code></pre> <p>Add a hook to the pipeline module.</p> <p>Parameters: - <code>name</code>: The name of the pipeline - <code>type</code>: The type of the hook. - <code>to</code>: The name of the file to add the hook to. Defaults to the hook.py file in the pipelines hooks folder. - <code>function_name</code>: The name of the function. If not provided uses default name of hook type.</p> <p>Returns: None</p> <p>Raises: - ValueError: If the hook type is not valid</p> <p>Example: </p><pre><code>from flowerpower.pipeline import HookType\n\nregistry.add_hook(\n    name=\"data_pipeline\",\n    type=HookType.MQTT_BUILD_CONFIG,\n    to=\"pre_execute_hook\",\n    function_name=\"my_pre_execute_function\"\n)\n</code></pre><p></p>"},{"location":"api/registry/#clear_cache","title":"clear_cache","text":"<pre><code>clear_cache(self, name: str | None = None)\n</code></pre> <p>Clear cached pipelines, configurations, and modules.</p> <p>Parameters: - <code>name</code>: If provided, clear cache only for this pipeline. If None, clear entire cache.</p> <p>Example: ```python registry.clear_cache(\"my_pipeline\")  # Clear specific registry.clear_cache()  # Clear all</p>"},{"location":"api/runconfig/","title":"RunConfig","text":""},{"location":"api/runconfig/#runconfig","title":"RunConfig","text":"<p>Module: <code>flowerpower.cfg.pipeline.run</code></p> <p>The <code>RunConfig</code> class encapsulates all configuration parameters for pipeline execution in FlowerPower. It provides a structured way to pass execution settings to both <code>Pipeline.run()</code> and <code>PipelineManager.run()</code> methods.</p>"},{"location":"api/runconfig/#initialization","title":"Initialization","text":""},{"location":"api/runconfig/#init","title":"init","text":"<pre><code>__init__(\n  self,\n  inputs: dict[str, Any] | None = None,\n  final_vars: list[str] | None = None,\n  config: dict[str, Any] | None = None,\n  cache: dict[str, Any] | bool | None = None,\n  with_adapter: WithAdapterConfig | dict = WithAdapterConfig(),\n  executor: ExecutorConfig | dict = ExecutorConfig(),\n  retry: RetryConfig | dict | None = None,\n  log_level: str | None = \"INFO\",\n  max_retries: int = 3,\n  retry_delay: int | float = 1,\n  jitter_factor: float | None = 0.1,\n  retry_exceptions: list[str] = [\"Exception\"],\n  pipeline_adapter_cfg: dict | None = None,\n  project_adapter_cfg: dict | None = None,\n  adapter: dict[str, Any] | None = None,\n  reload: bool = False,\n  on_success: Callable | tuple[Callable, tuple | None, dict | None] | None = None,\n  on_failure: Callable | tuple[Callable, tuple | None, dict | None] | None = None,\n)\n</code></pre> <p>Initializes a <code>RunConfig</code> instance with execution parameters.</p> Parameter Type Description Default <code>inputs</code> <code>dict[str, Any] \\| None</code> Override pipeline input values. Example: <code>{\"data_date\": \"2025-04-28\"}</code> <code>None</code> <code>final_vars</code> <code>list[str] \\| None</code> Specify which output variables to return. Example: <code>[\"model\", \"metrics\"]</code> <code>None</code> <code>config</code> <code>dict[str, Any] \\| None</code> Configuration for Hamilton pipeline executor. Example: <code>{\"model\": \"LogisticRegression\"}</code> <code>None</code> <code>cache</code> <code>dict[str, Any] \\| bool \\| None</code> Cache configuration for results or <code>False</code> to disable. <code>False</code> <code>executor</code> <code>ExecutorConfig \\| dict</code> Execution configuration; dict will be coerced to <code>ExecutorConfig</code>. <code>ExecutorConfig()</code> <code>retry</code> <code>RetryConfig \\| dict \\| None</code> Canonical location for retry settings (max attempts, delay, jitter, exceptions). <code>None</code> <code>with_adapter</code> <code>WithAdapterConfig \\| dict</code> Adapter settings for pipeline execution; dict will be coerced to <code>WithAdapterConfig</code>. <code>WithAdapterConfig()</code> <code>pipeline_adapter_cfg</code> <code>dict \\| PipelineAdapterConfig \\| None</code> Pipeline-specific adapter settings. Example: <code>{\"tracker\": {\"project_id\": \"123\", \"tags\": {\"env\": \"prod\"}}}</code> <code>None</code> <code>project_adapter_cfg</code> <code>dict \\| ProjectAdapterConfig \\| None</code> Project-level adapter settings. Example: <code>{\"opentelemetry\": {\"host\": \"http://localhost:4317\"}}</code> <code>None</code> <code>adapter</code> <code>dict[str, Any] \\| None</code> Custom adapter instance for pipeline Example: <code>{\"ray_graph_adapter\": RayGraphAdapter()}</code> <code>None</code> <code>reload</code> <code>bool</code> Force reload of pipeline configuration. <code>False</code> <code>log_level</code> <code>str \\| None</code> Logging level: \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\" <code>\"INFO\"</code> <code>max_retries</code> <code>int</code> Deprecated. Legacy top-level value normalised into <code>retry</code>. <code>3</code> <code>retry_delay</code> <code>int \\| float</code> Deprecated. Legacy top-level value normalised into <code>retry</code>. <code>1</code> <code>jitter_factor</code> <code>float \\| None</code> Deprecated. Legacy top-level value normalised into <code>retry</code>. <code>0.1</code> <code>retry_exceptions</code> <code>list[str]</code> Deprecated. Legacy top-level value normalised into <code>retry</code>. <code>[\"Exception\"]</code> <code>on_success</code> <code>Callable \\| tuple[Callable, tuple \\| None, dict \\| None] \\| None</code> Callback to run on successful pipeline execution. <code>None</code> <code>on_failure</code> <code>Callable \\| tuple[Callable, tuple \\| None, dict \\| None] \\| None</code> Callback to run on pipeline execution failure. <code>None</code>"},{"location":"api/runconfig/#attributes","title":"Attributes","text":"Attribute Type Description <code>inputs</code> <code>dict[str, Any] \\| None</code> Override pipeline input values. <code>final_vars</code> <code>list[str] \\| None</code> Specify which output variables to return. <code>config</code> <code>dict[str, Any] \\| None</code> Configuration for Hamilton pipeline executor. <code>cache</code> <code>dict[str, Any] \\| None</code> Cache configuration for results. <code>executor</code> <code>ExecutorConfig</code> Execution configuration. <code>executor_override_raw</code> <code>Any \\| None</code> Raw executor override provided at runtime (string/dict/ExecutorConfig). <code>with_adapter</code> <code>WithAdapterConfig</code> Adapter settings for pipeline execution. <code>retry</code> <code>RetryConfig</code> Structured retry configuration used by the runner. <code>pipeline_adapter_cfg</code> <code>dict \\| PipelineAdapterConfig \\| None</code> Pipeline-specific adapter settings. <code>project_adapter_cfg</code> <code>dict \\| ProjectAdapterConfig \\| None</code> Project-level adapter settings. <code>adapter</code> <code>dict[str, Any] \\| None</code> Custom adapter instance for pipeline. <code>reload</code> <code>bool</code> Force reload of pipeline configuration. <code>log_level</code> <code>str \\| None</code> Logging level for the execution. <code>max_retries</code> <code>int \\| None</code> Deprecated. Mirrors <code>retry.max_retries</code> for backwards compatibility. <code>retry_delay</code> <code>float \\| None</code> Deprecated. Mirrors <code>retry.retry_delay</code>. <code>jitter_factor</code> <code>float \\| None</code> Deprecated. Mirrors <code>retry.jitter_factor</code>. <code>retry_exceptions</code> <code>tuple \\| list \\| None</code> Deprecated. Mirrors <code>retry.retry_exceptions</code>. <code>on_success</code> <code>Callable \\| tuple[Callable, tuple \\| None, dict \\| None] \\| None</code> Callback to run on successful pipeline execution. <code>on_failure</code> <code>Callable \\| tuple[Callable, tuple \\| None, dict \\| None] \\| None</code> Callback to run on pipeline execution failure."},{"location":"api/runconfig/#methods","title":"Methods","text":""},{"location":"api/runconfig/#copy","title":"copy","text":"<pre><code>copy(self) -&gt; 'RunConfig'\n</code></pre> <p>Create a shallow copy of the RunConfig instance.</p> <p>Returns: <code>RunConfig</code> - A new RunConfig instance with the same configuration.</p>"},{"location":"api/runconfig/#example","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.run import RunConfig\n\n# Create a base configuration\nbase_config = RunConfig(\n    inputs={\"data_date\": \"2025-01-01\"},\n    log_level=\"INFO\"\n)\n\n# Create a copy and modify it\ncustom_config = base_config.copy()\ncustom_config.final_vars = [\"model\", \"metrics\"]\n</code></pre>"},{"location":"api/runconfig/#update","title":"update","text":"<pre><code>update(self, **kwargs) -&gt; 'RunConfig'\n</code></pre> <p>Update the RunConfig with new values and return self for method chaining.</p> Parameter Type Description <code>**kwargs</code> <code>Any</code> Key-value pairs of attributes to update. <p>Returns: <code>RunConfig</code> - The updated RunConfig instance (self).</p>"},{"location":"api/runconfig/#example_1","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.run import RunConfig\n\n# Create a base configuration\nconfig = RunConfig()\n\n# Update multiple attributes\nconfig.update(\n    inputs={\"data_date\": \"2025-01-01\"},\n    final_vars=[\"model\", \"metrics\"],\n    log_level=\"DEBUG\"\n)\n</code></pre>"},{"location":"api/runconfig/#runconfigbuilder","title":"RunConfigBuilder","text":"<p>Module: <code>flowerpower.cfg.pipeline.builder</code></p> <p>The <code>RunConfigBuilder</code> class provides a fluent interface for constructing <code>RunConfig</code> instances. It allows for method chaining and provides a more readable way to build complex configurations.</p>"},{"location":"api/runconfig/#initialization_1","title":"Initialization","text":""},{"location":"api/runconfig/#init_1","title":"init","text":"<pre><code>__init__(self)\n</code></pre> <p>Initializes a new <code>RunConfigBuilder</code> instance with default values.</p>"},{"location":"api/runconfig/#methods_1","title":"Methods","text":""},{"location":"api/runconfig/#with_inputs","title":"with_inputs","text":"<pre><code>with_inputs(self, inputs: dict[str, Any]) -&gt; 'RunConfigBuilder'\n</code></pre> <p>Set the input values for the pipeline execution.</p> Parameter Type Description <code>inputs</code> <code>dict[str, Any]</code> Input values for the pipeline. <p>Returns: <code>RunConfigBuilder</code> - The builder instance for method chaining.</p>"},{"location":"api/runconfig/#example_2","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\nbuilder = RunConfigBuilder()\nbuilder.with_inputs({\"data_date\": \"2025-01-01\", \"batch_size\": 32})\n</code></pre>"},{"location":"api/runconfig/#with_final_vars","title":"with_final_vars","text":"<pre><code>with_final_vars(self, final_vars: list[str]) -&gt; 'RunConfigBuilder'\n</code></pre> <p>Set the output variables to return from the pipeline execution.</p> Parameter Type Description <code>final_vars</code> <code>list[str]</code> List of output variable names. <p>Returns: <code>RunConfigBuilder</code> - The builder instance for method chaining.</p>"},{"location":"api/runconfig/#example_3","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\nbuilder = RunConfigBuilder()\nbuilder.with_final_vars([\"model\", \"metrics\", \"predictions\"])\n</code></pre>"},{"location":"api/runconfig/#with_config","title":"with_config","text":"<pre><code>with_config(self, config: dict[str, Any]) -&gt; 'RunConfigBuilder'\n</code></pre> <p>Set the configuration for the Hamilton pipeline executor.</p> Parameter Type Description <code>config</code> <code>dict[str, Any]</code> Configuration for the executor. <p>Returns: <code>RunConfigBuilder</code> - The builder instance for method chaining.</p>"},{"location":"api/runconfig/#example_4","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\nbuilder = RunConfigBuilder()\nbuilder.with_config({\"model\": \"LogisticRegression\", \"params\": {\"C\": 1.0}})\n</code></pre>"},{"location":"api/runconfig/#with_cache","title":"with_cache","text":"<pre><code>with_cache(self, cache: dict[str, Any]) -&gt; 'RunConfigBuilder'\n</code></pre> <p>Set the cache configuration for the pipeline execution.</p> Parameter Type Description <code>cache</code> <code>dict[str, Any]</code> Cache configuration. <p>Returns: <code>RunConfigBuilder</code> - The builder instance for method chaining.</p>"},{"location":"api/runconfig/#example_5","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\nbuilder = RunConfigBuilder()\nbuilder.with_cache({\"recompute\": [\"node1\", \"final_node\"]})\n</code></pre>"},{"location":"api/runconfig/#with_executor_config","title":"with_executor_config","text":"<pre><code>with_executor_config(self, executor_cfg: str | dict | ExecutorConfig) -&gt; 'RunConfigBuilder'\n</code></pre> <p>Set the execution configuration for the pipeline.</p> Parameter Type Description <code>executor_cfg</code> <code>str \\| dict \\| ExecutorConfig</code> Execution configuration. <p>Returns: <code>RunConfigBuilder</code> - The builder instance for method chaining.</p>"},{"location":"api/runconfig/#example_6","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\n# Using a string\nbuilder = RunConfigBuilder()\nbuilder.with_executor_config(\"threadpool\")\n\n# Using a dictionary\nbuilder = RunConfigBuilder()\nbuilder.with_executor_config({\"type\": \"threadpool\", \"max_workers\": 4})\n</code></pre>"},{"location":"api/runconfig/#with_adapter_config","title":"with_adapter_config","text":"<pre><code>with_adapter_config(self, with_adapter_cfg: dict | WithAdapterConfig) -&gt; 'RunConfigBuilder'\n</code></pre> <p>Set the adapter settings for pipeline execution.</p> Parameter Type Description <code>with_adapter_cfg</code> <code>dict \\| WithAdapterConfig</code> Adapter settings. <p>Returns: <code>RunConfigBuilder</code> - The builder instance for method chaining.</p>"},{"location":"api/runconfig/#example_7","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\nbuilder = RunConfigBuilder()\nbuilder.with_adapter_config({\"opentelemetry\": True, \"tracker\": False})\n</code></pre>"},{"location":"api/runconfig/#with_pipeline_adapter_config","title":"with_pipeline_adapter_config","text":"<pre><code>with_pipeline_adapter_config(self, pipeline_adapter_cfg: dict | PipelineAdapterConfig) -&gt; 'RunConfigBuilder'\n</code></pre> <p>Set the pipeline-specific adapter settings.</p> Parameter Type Description <code>pipeline_adapter_cfg</code> <code>dict \\| PipelineAdapterConfig</code> Pipeline-specific adapter settings. <p>Returns: <code>RunConfigBuilder</code> - The builder instance for method chaining.</p>"},{"location":"api/runconfig/#example_8","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\nbuilder = RunConfigBuilder()\nbuilder.with_pipeline_adapter_config({\n    \"tracker\": {\"project_id\": \"123\", \"tags\": {\"env\": \"prod\"}}\n})\n</code></pre>"},{"location":"api/runconfig/#with_project_adapter_config","title":"with_project_adapter_config","text":"<pre><code>with_project_adapter_config(self, project_adapter_cfg: dict | ProjectAdapterConfig) -&gt; 'RunConfigBuilder'\n</code></pre> <p>Set the project-level adapter settings.</p> Parameter Type Description <code>project_adapter_cfg</code> <code>dict \\| ProjectAdapterConfig</code> Project-level adapter settings. <p>Returns: <code>RunConfigBuilder</code> - The builder instance for method chaining.</p>"},{"location":"api/runconfig/#example_9","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\nbuilder = RunConfigBuilder()\nbuilder.with_project_adapter_config({\n    \"opentelemetry\": {\"host\": \"http://localhost:4317\"}\n})\n</code></pre>"},{"location":"api/runconfig/#with_adapter","title":"with_adapter","text":"<pre><code>with_adapter(self, adapter: dict[str, Any]) -&gt; 'RunConfigBuilder'\n</code></pre> <p>Set custom adapter instances for the pipeline.</p> Parameter Type Description <code>adapter</code> <code>dict[str, Any]</code> Custom adapter instances. <p>Returns: <code>RunConfigBuilder</code> - The builder instance for method chaining.</p>"},{"location":"api/runconfig/#example_10","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\nfrom some_module import RayGraphAdapter\n\nbuilder = RunConfigBuilder()\nbuilder.with_adapter({\"ray_graph_adapter\": RayGraphAdapter()})\n</code></pre>"},{"location":"api/runconfig/#with_reload","title":"with_reload","text":"<pre><code>with_reload(self, reload: bool = True) -&gt; 'RunConfigBuilder'\n</code></pre> <p>Set whether to force reload of pipeline configuration.</p> Parameter Type Description Default <code>reload</code> <code>bool</code> Whether to force reload. <code>True</code> <p>Returns: <code>RunConfigBuilder</code> - The builder instance for method chaining.</p>"},{"location":"api/runconfig/#example_11","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\nbuilder = RunConfigBuilder()\nbuilder.with_reload(True)\n</code></pre>"},{"location":"api/runconfig/#with_log_level","title":"with_log_level","text":"<pre><code>with_log_level(self, log_level: str) -&gt; 'RunConfigBuilder'\n</code></pre> <p>Set the logging level for the execution.</p> Parameter Type Description <code>log_level</code> <code>str</code> Logging level. Valid values: \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\" <p>Returns: <code>RunConfigBuilder</code> - The builder instance for method chaining.</p>"},{"location":"api/runconfig/#example_12","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\nbuilder = RunConfigBuilder()\nbuilder.with_log_level(\"DEBUG\")\n</code></pre>"},{"location":"api/runconfig/#with_retry_config","title":"with_retry_config","text":"<pre><code>with_retry_config(self, max_retries: int | None = None, retry_delay: float | None = None, jitter_factor: float | None = None, retry_exceptions: tuple | list | None = None) -&gt; 'RunConfigBuilder'\n</code></pre> <p>Set the retry configuration for the execution.</p> Parameter Type Description Default <code>max_retries</code> <code>int \\| None</code> Maximum number of retries. <code>None</code> <code>retry_delay</code> <code>float \\| None</code> Delay between retries in seconds. <code>None</code> <code>jitter_factor</code> <code>float \\| None</code> Random jitter factor to add to retry delay. <code>None</code> <code>retry_exceptions</code> <code>tuple \\| list \\| None</code> Exceptions that trigger a retry. <code>None</code> <p>Returns: <code>RunConfigBuilder</code> - The builder instance for method chaining.</p>"},{"location":"api/runconfig/#example_13","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\nbuilder = RunConfigBuilder()\nbuilder.with_retry_config(\n    max_retries=3,\n    retry_delay=1.0,\n    retry_exceptions=(ValueError, KeyError)\n)\n</code></pre>"},{"location":"api/runconfig/#with_success_callback","title":"with_success_callback","text":"<pre><code>with_success_callback(self, on_success: Callable | tuple[Callable, tuple | None, dict | None]) -&gt; 'RunConfigBuilder'\n</code></pre> <p>Set the callback to run on successful pipeline execution.</p> Parameter Type Description <code>on_success</code> <code>Callable \\| tuple[Callable, tuple \\| None, dict \\| None]</code> Callback function or tuple with function, args, and kwargs. <p>Returns: <code>RunConfigBuilder</code> - The builder instance for method chaining.</p>"},{"location":"api/runconfig/#example_14","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\ndef success_handler(result):\n    print(f\"Pipeline succeeded with result: {result}\")\n\nbuilder = RunConfigBuilder()\nbuilder.with_success_callback(success_handler)\n</code></pre>"},{"location":"api/runconfig/#with_failure_callback","title":"with_failure_callback","text":"<pre><code>with_failure_callback(self, on_failure: Callable | tuple[Callable, tuple | None, dict | None]) -&gt; 'RunConfigBuilder'\n</code></pre> <p>Set the callback to run on pipeline execution failure.</p> Parameter Type Description <code>on_failure</code> <code>Callable \\| tuple[Callable, tuple \\| None, dict \\| None]</code> Callback function or tuple with function, args, and kwargs. <p>Returns: <code>RunConfigBuilder</code> - The builder instance for method chaining.</p>"},{"location":"api/runconfig/#example_15","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\ndef failure_handler(error):\n    print(f\"Pipeline failed with error: {error}\")\n\nbuilder = RunConfigBuilder()\nbuilder.with_failure_callback(failure_handler)\n</code></pre>"},{"location":"api/runconfig/#build","title":"build","text":"<pre><code>build(self) -&gt; RunConfig\n</code></pre> <p>Build and return a <code>RunConfig</code> instance with the configured parameters.</p> <p>Returns: <code>RunConfig</code> - A new RunConfig instance with the configured parameters.</p>"},{"location":"api/runconfig/#example_16","title":"Example","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\n\n# Build a configuration\nconfig = (\n    RunConfigBuilder()\n    .with_inputs({\"data_date\": \"2025-01-01\"})\n    .with_final_vars([\"model\", \"metrics\"])\n    .with_log_level(\"DEBUG\")\n    .with_retry_config(max_retries=3, retry_delay=1.0)\n    .build()\n)\n</code></pre>"},{"location":"api/runconfig/#usage-examples","title":"Usage Examples","text":""},{"location":"api/runconfig/#basic-usage","title":"Basic Usage","text":"<pre><code>from flowerpower.cfg.pipeline.run import RunConfig\nfrom flowerpower.cfg.pipeline.builder import RunConfigBuilder\nfrom flowerpower.pipeline import PipelineManager\n\n# Using RunConfig directly\nconfig = RunConfig(\n    inputs={\"data_date\": \"2025-01-01\"},\n    final_vars=[\"model\", \"metrics\"],\n    log_level=\"DEBUG\"\n)\n\nmanager = PipelineManager()\nresult = manager.run(\"my_pipeline\", run_config=config)\n\n# Using RunConfigBuilder\nconfig = (\n    RunConfigBuilder()\n    .with_inputs({\"data_date\": \"2025-01-01\"})\n    .with_final_vars([\"model\", \"metrics\"])\n    .with_log_level(\"DEBUG\")\n    .build()\n)\n\nresult = manager.run(\"my_pipeline\", run_config=config)\n</code></pre>"},{"location":"api/runconfig/#complex-configuration","title":"Complex Configuration","text":"<pre><code>from flowerpower.cfg.pipeline.builder import RunConfigBuilder\nfrom flowerpower.pipeline import PipelineManager\n\ndef success_handler(result):\n    print(f\"Pipeline succeeded: {result}\")\n\ndef failure_handler(error):\n    print(f\"Pipeline failed: {error}\")\n\n# Build a complex configuration\nconfig = (\n    RunConfigBuilder()\n    .with_inputs({\"data_date\": \"2025-01-01\", \"batch_size\": 32})\n    .with_final_vars([\"model\", \"metrics\", \"predictions\"])\n    .with_config({\"model\": \"LogisticRegression\", \"params\": {\"C\": 1.0}})\n    .with_cache({\"recompute\": [\"preprocessing\"]})\n    .with_executor_config({\"type\": \"threadpool\", \"max_workers\": 4})\n    .with_adapter_config({\"opentelemetry\": True})\n    .with_pipeline_adapter_config({\"tracker\": {\"project_id\": \"123\"}})\n    .with_project_adapter_config({\"opentelemetry\": {\"host\": \"localhost:4317\"}})\n    .with_log_level(\"DEBUG\")\n    .with_retry_config(max_retries=3, retry_delay=1.0)\n    .with_success_callback(success_handler)\n    .with_failure_callback(failure_handler)\n    .build()\n)\n\nmanager = PipelineManager()\nresult = manager.run(\"ml_pipeline\", run_config=config)\n</code></pre>"},{"location":"api/runconfig/#reusing-configurations","title":"Reusing Configurations","text":"<p>```python from flowerpower.cfg.pipeline.run import RunConfig from flowerpower.cfg.pipeline.builder import RunConfigBuilder from flowerpower.pipeline import PipelineManager</p>"},{"location":"api/runconfig/#create-a-base-configuration","title":"Create a base configuration","text":"<p>base_config = (     RunConfigBuilder()     .with_log_level(\"INFO\")     .with_retry_config(max_retries=2, retry_delay=0.5)     .build() )</p>"},{"location":"api/runconfig/#create-specialized-configurations-by-copying-and-modifying","title":"Create specialized configurations by copying and modifying","text":"<p>training_config = base_config.copy() training_config.update(     inputs={\"mode\": \"training\", \"data_split\": 0.8},     final_vars=[\"model\", \"training_metrics\"] )</p> <p>inference_config = base_config.copy() inference_config.update(     inputs={\"mode\": \"inference\", \"model_path\": \"/path/to/model\"},     final_vars=[\"predictions\", \"inference_metrics\"] )</p> <p>manager = PipelineManager()</p>"},{"location":"api/runconfig/#run-with-different-configurations","title":"Run with different configurations","text":"<p>training_result = manager.run(\"ml_pipeline\", run_config=training_config) inference_result = manager.run(\"ml_pipeline\", run_config=inference_config)</p> <p>Legacy retry fields</p> <p>The <code>max_retries</code>, <code>retry_delay</code>, <code>jitter_factor</code>, and <code>retry_exceptions</code> attributes are accepted for backwards compatibility but now trigger a <code>DeprecationWarning</code> when set explicitly. Prefer configuring retries via the nested <code>retry</code> block or the builder helpers.</p>"},{"location":"guide/additional-modules/","title":"Compose Pipelines With Additional Modules","text":""},{"location":"guide/additional-modules/#compose-pipelines-with-additional-modules","title":"Compose Pipelines With Additional Modules","text":"<p>FlowerPower extends Hamilton\u2019s ability to compose DAGs across multiple Python modules. This guide walks through when and how to use the <code>additional_modules</code> argument, how module resolution works, and what to watch out for when you split a pipeline into reusable building blocks.</p>"},{"location":"guide/additional-modules/#why-split-pipelines","title":"Why split pipelines?","text":"<ul> <li>Shared setup \u2013 initialise databases, secrets, or clients once and reuse   them in multiple pipelines.</li> <li>Team ownership \u2013 keep domain-specific logic in separate modules while   still orchestrating a single DAG.</li> <li>Iterative development \u2013 experiment with new nodes alongside the existing   pipeline without touching the production module.</li> </ul> <p>The official <code>examples/hello-world/pipelines/</code> folder includes both <code>hello_world.py</code> and a companion <code>setup.py</code>; the snippets below mirror that structure.</p>"},{"location":"guide/additional-modules/#quick-start","title":"Quick start","text":"<pre><code>from flowerpower import FlowerPowerProject\n\nproject = FlowerPowerProject.load('.')\n\nresult = project.run(\n    'hello_world',\n    additional_modules=['pipeline_setup'],\n    final_vars=['full_greeting'],\n)\nprint(result['full_greeting'])\n</code></pre> <p>The same pattern works with <code>PipelineManager</code>:</p> <pre><code>from flowerpower.pipeline import PipelineManager\n\npm = PipelineManager(base_dir='.')\ncomposed = pm.run(\n    name='hello_world',\n    additional_modules=['pipeline_setup'],\n    final_vars=['full_greeting'],\n)\n</code></pre>"},{"location":"guide/additional-modules/#module-resolution-rules","title":"Module resolution rules","text":"<p>When strings are provided, FlowerPower tries to match them in this order:</p> <ol> <li>Import the string exactly as given (<code>importlib.import_module(value)</code>).</li> <li>Import the value with hyphens replaced by underscores (e.g. <code>data-setup</code>    \u2192 <code>data_setup</code>).</li> <li>Import from the <code>pipelines</code> package (e.g. <code>pipelines.data_setup</code>).</li> </ol> <p>Already-imported module objects can be mixed with strings in the <code>additional_modules</code> list.</p> <p>Tip: Keep the list ordered. Hamilton resolves conflicting node names by using the last module passed to <code>.with_modules(...)</code>. FlowerPower appends the main pipeline module after everything in <code>additional_modules</code>, so it wins ties by default.</p>"},{"location":"guide/additional-modules/#reload-behaviour","title":"Reload behaviour","text":"<p>Setting <code>reload=True</code> on the <code>RunConfig</code> (or passing <code>reload=True</code> to <code>pm.run(...)</code>) reloads every module in the composed list before execution. This mirrors Hamilton\u2019s behaviour and is especially helpful during local development.</p> <pre><code>pm.run(\n    'hello_world',\n    additional_modules=['pipeline_setup'],\n    reload=True,\n)\n</code></pre>"},{"location":"guide/additional-modules/#visualising-composed-dags","title":"Visualising composed DAGs","text":"<p>The visualiser accepts the same flag, letting you inspect the combined graph:</p> <pre><code>pm.visualizer.save_dag(\n    name='hello_world',\n    base_dir='.',\n    additional_modules=['pipeline_setup'],\n)\n\npm.visualizer.show_dag(\n    name='hello_world',\n    additional_modules=['pipeline_setup'],\n    raw=False,\n)\n</code></pre>"},{"location":"guide/additional-modules/#troubleshooting","title":"Troubleshooting","text":"Symptom Cause Fix <code>ImportError: Could not import additional module</code> Module string cannot be resolved Ensure the module is on <code>PYTHONPATH</code> or lives in the <code>pipelines/</code> folder. Use dotted paths for nested modules. Unexpected node value Same node defined in multiple modules Reorder <code>additional_modules</code> so the desired version is last, or rename the node. Changes not reflected Modules cached by Python Use <code>reload=True</code> during iterative development."},{"location":"guide/additional-modules/#related-reading","title":"Related reading","text":"<ul> <li>Repository README \u2013 section \u201cCompose Pipelines With Additional Modules\u201d for a   concise quick-start.</li> <li>Example modules: <code>examples/hello-world/pipelines/hello_world.py</code> and   <code>examples/hello-world/pipelines/setup.py</code></li> </ul>"}]}