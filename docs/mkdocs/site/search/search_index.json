{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"FlowerPower: Data Pipeline Orchestration","text":"<p>Welcome to the official documentation for FlowerPower, a powerful Python library designed to help you build, configure, schedule, and execute data processing pipelines with ease.</p> <p> </p> <p>FlowerPower streamlines complex data workflows by integrating the modularity of Hamilton for pipeline logic and the robustness of Redis Queue (RQ) for asynchronous job processing.</p>"},{"location":"#get-started","title":"Get Started","text":"<p>Ready to dive in? Our Quickstart Guide will walk you through installing FlowerPower and running your first pipeline in just a few minutes.</p>"},{"location":"#core-concepts","title":"Core Concepts","text":"<p>FlowerPower is built around a few key concepts that make it both powerful and flexible:</p> <ul> <li>Modular Pipeline Design: Define your data transformations as a collection of simple Python functions. FlowerPower, using Hamilton, automatically understands their dependencies and assembles them into a Directed Acyclic Graph (DAG).</li> <li>Configuration-Driven: Separate your pipeline logic from its execution parameters. Environments, data sources, and pipeline settings are all managed through clear and simple YAML files.</li> <li>Job Queue Integration: Scale your data processing by offloading tasks to a distributed job queue. FlowerPower provides a seamless interface for sending, managing, and monitoring asynchronous jobs with RQ.</li> <li>Unified Project Interface: Interact with your pipelines through the method that suits you best\u2014a Python API (<code>FlowerPowerProject</code>), a command-line interface (CLI), or a web-based UI for visualization and monitoring.</li> <li>Extensible I/O: Easily read from and write to various data sources with built-in and custom I/O plugins, ensuring your pipelines can connect to any data, anywhere.</li> </ul> <p>A Note on Hamilton and RQ</p> <p>FlowerPower acts as an orchestrator, not a replacement. You will still write your pipeline logic using Hamilton's function-based syntax and interact with job queue concepts from RQ. FlowerPower's role is to connect these two ecosystems, providing a structured project environment and simplifying their combined use.</p>"},{"location":"advanced/","title":"Advanced Usage","text":"<p>Welcome to the advanced usage guide for FlowerPower. This document covers more complex configurations and use cases to help you get the most out of the library.</p>"},{"location":"advanced/#configuration-flexibility","title":"Configuration Flexibility","text":"<p>FlowerPower offers multiple ways to configure your project, ensuring flexibility for different environments and workflows. The configuration is loaded in the following order of precedence:</p> <ol> <li>Programmatic Overrides: Highest priority.</li> <li>Environment Variables: Set in your shell or <code>.env</code> file.</li> <li><code>settings.py</code>: A dedicated settings module.</li> <li>YAML files: <code>anypath.yaml</code> for your project.</li> </ol>"},{"location":"advanced/#programmatic-configuration","title":"Programmatic Configuration","text":"<p>You can override configuration settings directly in your Python code. This is useful for dynamic adjustments or for settings that are determined at runtime.</p> <pre><code>from flowerpower.core.config import settings\n\n# Override the default Redis host\nsettings.set('redis.host', 'localhost')\n\n# You can also update nested settings\nsettings.set('pipelines.my_pipeline.retries', 3)\n</code></pre>"},{"location":"advanced/#direct-module-usage","title":"Direct Module Usage","text":"<p>For fine-grained control, you can work directly with <code>PipelineManager</code> and <code>JobQueueManager</code>.</p>"},{"location":"advanced/#pipelinemanager","title":"<code>PipelineManager</code>","text":"<p>The <code>PipelineManager</code> is responsible for loading, validating, and executing data pipelines.</p> <pre><code>from flowerpower.core.pipeline import PipelineManager\n\n# Initialize the manager\npipeline_manager = PipelineManager()\n\n# Load a specific pipeline\npipeline = pipeline_manager.get_pipeline(\"sales_etl\")\n\n# Execute the pipeline\nresult = pipeline.run(input_data=\"path/to/data.csv\")\nprint(result)\n</code></pre>"},{"location":"advanced/#jobqueuemanager","title":"<code>JobQueueManager</code>","text":"<p>The <code>JobQueueManager</code> handles job queuing, scheduling, and worker management.</p> <pre><code>from flowerpower.core.job_queue import JobQueueManager\n\n# Initialize the manager\njob_queue_manager = JobQueueManager()\n\n# Enqueue a job\njob = job_queue_manager.enqueue(\"my_task\", arg1=\"value1\", arg2=\"value2\")\nprint(f\"Job {job.id} enqueued.\")\n\n# Schedule a job to run at a specific time\njob_queue_manager.schedule(\"my_task\", cron=\"0 0 * * *\") # Daily at midnight\n</code></pre>"},{"location":"advanced/#adapters","title":"Adapters","text":"<p>Integrate with popular MLOps and observability tools using adapters.</p> <ul> <li>Hamilton Tracker: For dataflow and lineage tracking.</li> <li>MLflow: For experiment tracking.</li> <li>OpenTelemetry: For distributed tracing and metrics.</li> </ul>"},{"location":"advanced/#filesystem-abstraction","title":"Filesystem Abstraction","text":"<p>FlowerPower uses the library <code>fsspec</code> to provide a unified interface for interacting with different filesystems, including local storage, S3, and GCS. This allows you to switch between storage backends without changing your code.</p>"},{"location":"advanced/#worker-management","title":"Worker Management","text":"<p>You can manage workers to process your queued jobs.</p>"},{"location":"advanced/#single-worker","title":"Single Worker","text":"<p>Start a single worker in the foreground:</p> <pre><code>flowerpower job-queue start-worker\n</code></pre>"},{"location":"advanced/#worker-pool","title":"Worker Pool","text":"<p>Start a pool of workers in the background: <pre><code>flowerpower job-queue start-worker --pool-size 5 --background\n</code></pre></p> <p>To stop background workers: <pre><code>flowerpower job-queue stop-worker\n\n```bash\nflowerpower job-queue start-worker stop\n</code></pre></p>"},{"location":"advanced/#scheduling-options","title":"Scheduling Options","text":"<p>FlowerPower supports several scheduling strategies for your jobs:</p> <ul> <li>Cron: For recurring jobs at specific times (e.g., <code>0 2 * * *</code>).</li> <li>Interval: For jobs that run at regular intervals (e.g., every 30 minutes).</li> <li>Date: For jobs that run once at a specific date and time.</li> </ul>"},{"location":"advanced/#extensible-io-plugins","title":"Extensible I/O Plugins","text":"<p>The FlowerPower plugin <code>flowerpower-io</code> enhances FlowerPower's I/O capabilities, allowing you to connect to various data sources and sinks using a simple plugin architecture.</p> <p>Supported Types Include:</p> <ul> <li>CSV, JSON, Parquet</li> <li>DeltaTable</li> <li>DuckDB, PostgreSQL, MySQL, MSSQL, Oracle, SQLite</li> <li>MQTT</li> </ul> <p>To use a plugin, simply specify its type in your pipeline configuration.</p>"},{"location":"advanced/#troubleshooting","title":"Troubleshooting","text":"<p>Here are some common issues and how to resolve them:</p> <ul> <li>Redis Connection Error: Ensure your Redis server is running and accessible. Check the <code>redis.host</code> and <code>redis.port</code> settings in your configuration.</li> <li>Configuration Errors: Use the <code>flowerpower config show</code> command to inspect the loaded configuration and identify any misconfigurations.</li> <li>Module Not Found: Make sure your pipeline and task modules are in Python's path. You can add directories to the path using the <code>PYTHONPATH</code> environment variable.</li> </ul> <p>Note</p> <p>For more detailed information, refer to the API documentation.</p>"},{"location":"architecture/","title":"Architecture Overview","text":""},{"location":"architecture/#introduction","title":"Introduction","text":"<p>Welcome to the architectural overview of FlowerPower. This document provides a high-level look at the library's design, its core components, and the principles that guide its development. Our goal is to create a powerful, flexible, and easy-to-use platform for building data pipelines and managing asynchronous jobs.</p>"},{"location":"architecture/#core-design-principles","title":"Core Design Principles","text":"<p>FlowerPower is built on a foundation of modularity and clear separation of concerns. Key design principles include:</p> <ul> <li>Modular and Configuration-Driven: Components are designed to be self-contained and configurable, allowing you to easily swap implementations and adapt the library to your needs.</li> <li>Unified Interface: A single, clean entry point (<code>FlowerPowerProject</code>) simplifies interaction with the library's powerful features.</li> <li>Separation of Concerns: Pipeline execution (the \"what\") is decoupled from job queue management (the \"how\" and \"when\").</li> <li>Extensibility: The library is designed to be extended with custom plugins and adapters for I/O, messaging, and more.</li> </ul>"},{"location":"architecture/#key-components","title":"Key Components","text":"<p>The library's architecture is centered around a few key components that work together to provide a seamless experience.</p> <pre><code>graph TD\n    A[FlowerPowerProject] --&gt;|Manages| B(PipelineManager)\n    A --&gt;|Manages| C(JobQueueManager)\n    B --&gt;|Uses| D[Hamilton]\n    C --&gt;|Uses| E[RQManager]\n    E --&gt;|Uses| F[Redis]\n\n    subgraph \"Core Components\"\n        B\n        C\n        E\n    end\n\n    subgraph \"External Dependencies\"\n        D\n        F\n    end\n</code></pre>"},{"location":"architecture/#flowerpowerproject","title":"<code>FlowerPowerProject</code>","text":"<p>The <code>FlowerPowerProject</code> class is the main entry point and public-facing API of the library. It acts as a facade, providing a unified interface to the underlying <code>PipelineManager</code> and <code>JobQueueManager</code>. This simplifies the user experience by abstracting away the complexities of the individual components.</p>"},{"location":"architecture/#pipelinemanager","title":"<code>PipelineManager</code>","text":"<p>The <code>PipelineManager</code> is responsible for everything related to data pipelines:</p> <ul> <li>Configuration: It loads and manages pipeline definitions from YAML files.</li> <li>Execution: It uses the Hamilton library to execute dataflows defined as a Directed Acyclic Graph (DAG) of Python functions.</li> <li>Visualization: It provides tools for visualizing pipeline graphs.</li> <li>I/O: It handles data loading and saving through an extensible system of I/O adapters.</li> </ul>"},{"location":"architecture/#hamilton-integration","title":"Hamilton Integration","text":"<p>FlowerPower leverages Hamilton to define the logic of its data pipelines. Hamilton's declarative, function-based approach allows you to define complex dataflows in a clear and maintainable way. Each function in a Hamilton module represents a node in the DAG, and Hamilton automatically resolves the dependencies and executes the functions in the correct order.</p> <p>Note</p> <p>To learn more about Hamilton, visit the official documentation.</p>"},{"location":"architecture/#jobqueuemanager-and-rqmanager","title":"<code>JobQueueManager</code> and <code>RQManager</code>","text":"<p>The <code>JobQueueManager</code> is a factory responsible for creating and managing job queue backends. Currently, the primary implementation is the <code>RQManager</code>, which uses the powerful Redis Queue (RQ) library.</p> <p>The <code>RQManager</code> handles:</p> <ul> <li>Asynchronous Processing: It allows you to offload long-running tasks to background workers, keeping your application responsive.</li> <li>Job Scheduling: You can enqueue jobs to run at a specific time or on a recurring schedule.</li> <li>Distributed Workers: RQ's worker-based architecture enables you to distribute tasks across multiple machines for parallel processing.</li> </ul>"},{"location":"architecture/#rq-and-redis","title":"RQ and Redis","text":"<p>RQ uses Redis as its message broker and storage backend. This provides a robust and performant foundation for the job queueing system.</p> <p>Tip</p> <p>You can monitor and manage your RQ queues using tools like <code>rq-dashboard</code>.</p>"},{"location":"architecture/#filesystem-abstraction","title":"Filesystem Abstraction","text":"<p>FlowerPower includes a filesystem abstraction layer that allows you to work with local and remote filesystems (e.g., S3, GCS) using a consistent API. This makes it easy to build pipelines that can read from and write to various storage backends without changing your core logic.</p>"},{"location":"architecture/#conclusion","title":"Conclusion","text":"<p>FlowerPower's architecture is designed to be both powerful and flexible. By combining the strengths of Hamilton for dataflow definition and RQ for asynchronous processing, it provides a comprehensive solution for a wide range of data-intensive applications. The modular design and unified interface make it easy to get started, while the extensible nature of the library allows it to grow with your needs.</p>"},{"location":"contributing/","title":"Contributing to FlowerPower","text":"<p>First off, thank you for considering contributing to FlowerPower! It's people like you that make open source such a great community.</p> <p>We welcome contributions in various forms, from reporting bugs and suggesting enhancements to submitting pull requests with new features or bug fixes.</p>"},{"location":"contributing/#reporting-issues","title":"Reporting Issues","text":"<p>If you encounter a bug or have a suggestion for a new feature, please open an issue on our GitHub Issue Tracker.</p> <p>When reporting a bug, please include the following to help us resolve it quickly: - A clear and descriptive title. - A detailed description of the problem, including steps to reproduce it. - Your operating system, Python version, and FlowerPower version. - Any relevant logs or tracebacks.</p>"},{"location":"contributing/#submitting-pull-requests","title":"Submitting Pull Requests","text":"<p>We love pull requests! To ensure a smooth process, please follow these guidelines:</p> <ol> <li>Fork the repository and create a new branch for your feature or bug fix.</li> <li>Set up your development environment (see \"Development Setup\" below).</li> <li>Make your changes and ensure the code is well-tested.</li> <li>Update the documentation if your changes affect it.</li> <li>Ensure your code passes all tests before submitting.</li> <li>Submit a pull request with a clear description of your changes.</li> </ol>"},{"location":"contributing/#development-setup","title":"Development Setup","text":"<p>We use <code>uv</code> for managing dependencies and running our development environment.</p> <ol> <li> <p>Install <code>uv</code>:     Follow the official instructions to install <code>uv</code>.</p> </li> <li> <p>Create a virtual environment:     <pre><code>uv venv\n</code></pre></p> </li> <li> <p>Activate the environment:     <pre><code>source .venv/bin/activate\n</code></pre></p> </li> <li> <p>Install dependencies:     To install the base dependencies along with the development and test dependencies, run:     <pre><code>uv pip install -e \".[dev,test]\"\n</code></pre></p> <p>Note</p> <p>If you need to install optional dependencies for specific features (e.g., <code>mqtt</code>, <code>redis</code>), you can add them to the install command: <code>uv pip install -e \".[dev,test,mqtt,redis]\"</code>.</p> </li> <li> <p>Run tests:     To ensure everything is working correctly, run the test suite:     <pre><code>uv run pytest\n</code></pre></p> </li> </ol>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>We are committed to providing a welcoming and inclusive environment for everyone. Please read and follow our Code of Conduct (assuming one exists or will be created).</p> <p>Thank you for your contribution!</p>"},{"location":"examples/","title":"Examples","text":"<p>Welcome to the FlowerPower examples section! Here, you'll find a variety of projects demonstrating the library's capabilities in different scenarios. Each example is designed to be a practical, hands-on guide to help you get started.</p>"},{"location":"examples/#available-examples","title":"Available Examples","text":"<p>The <code>examples/</code> directory in the project repository contains the following examples:</p> <ul> <li>Data ETL Pipeline: Demonstrates how to build a classic Extract, Transform, Load (ETL) pipeline. This example reads raw data, cleans and processes it, and saves the output, showcasing FlowerPower's ability to manage data-centric workflows.</li> <li>Hello World: A simple, introductory example to help you verify your setup and understand the basic concepts of creating and running a FlowerPower project.</li> <li>Job Queue Only: Shows how to use FlowerPower's job queue functionality independently of the pipeline engine. This is useful for applications that need a robust background task processor without a complex, multi-stage pipeline.</li> <li>ML Training Pipeline: Illustrates how to structure a machine learning workflow, from data loading and preprocessing to model training and evaluation.</li> <li>Pipeline Only: A focused example that highlights the pipeline creation and execution features without involving a job queue.</li> <li>Scheduled Reports: Shows how to create pipelines that run on a schedule to generate and save reports, a common use case for business intelligence and monitoring.</li> <li>Web Scraping Pipeline: Demonstrates how to build a pipeline that scrapes data from websites, processes it, and stores the results.</li> </ul>"},{"location":"examples/#example-in-depth-data-etl-pipeline","title":"Example in Depth: Data ETL Pipeline","text":"<p>This example demonstrates a common use case for FlowerPower: creating a data pipeline to process sales data. The pipeline reads a CSV file, cleans the data, and computes a summary.</p> <p>To run this example, navigate to the <code>examples/data-etl-pipeline</code> directory and execute the main script.</p> <pre><code>cd examples/data-etl-pipeline\nuv run python scripts/run_example.py\n</code></pre> <p>Below is a simplified version of the pipeline definition, which can be found in <code>pipelines/sales_etl.py</code>.</p> <pre><code># examples/data-etl-pipeline/pipelines/sales_etl.py\n\nimport pandas as pd\nfrom flowerpower.pipeline import Pipeline, pipeline_node\n\n@pipeline_node\ndef load_sales_data(file_path: str) -&gt; pd.DataFrame:\n    \"\"\"Loads sales data from a CSV file.\"\"\"\n    return pd.read_csv(file_path)\n\n@pipeline_node\ndef clean_data(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Removes rows with missing values.\"\"\"\n    return df.dropna()\n\n@pipeline_node\ndef generate_summary(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Generates a summary of total sales per product.\"\"\"\n    return df.groupby(\"product\")[\"sales\"].sum().reset_index()\n\n@pipeline_node\ndef save_summary(df: pd.DataFrame, output_path: str):\n    \"\"\"Saves the summary to a new CSV file.\"\"\"\n    df.to_csv(output_path, index=False)\n    print(f\"Sales summary saved to {output_path}\")\n\ndef create_pipeline() -&gt; Pipeline:\n    \"\"\"Creates the sales ETL pipeline.\"\"\"\n    return Pipeline(\n        nodes=[\n            load_sales_data,\n            clean_data,\n            generate_summary,\n            save_summary,\n        ],\n        name=\"sales_etl_pipeline\",\n    )\n</code></pre> <p>Note</p> <p>Each function decorated with <code>@pipeline_node</code> becomes a step in our pipeline. FlowerPower automatically manages the data flow between these nodes.</p>"},{"location":"examples/#example-in-depth-job-queue-only","title":"Example in Depth: Job Queue Only","text":"<p>This example showcases how to use FlowerPower's job queue for running background tasks. It's ideal for offloading long-running processes from a web server or other main application thread.</p> <p>The core of this example is a simple task that processes some data.</p> <pre><code># examples/job-queue-only-example/tasks/data_processing.py\n\nimport time\n\ndef process_data_task(record_id: int, data: dict):\n    \"\"\"\n    A sample task that simulates processing a record.\n    \"\"\"\n    print(f\"Processing record {record_id}...\")\n    # Simulate a long-running task\n    time.sleep(5)\n    print(f\"Finished processing record {record_id}. Data: {data}\")\n    return {\"record_id\": record_id, \"status\": \"processed\"}\n</code></pre> <p>To enqueue this task, you would use a script similar to the one in <code>scripts/run_example.py</code>.</p> <pre><code># examples/job-queue-only-example/scripts/run_example.py\n\nfrom flowerpower.job_queue import JobQueue\nfrom tasks.data_processing import process_data_task\n\n# Initialize the job queue\njq = JobQueue.from_config()\n\n# Enqueue a job\njob = jq.enqueue(process_data_task, record_id=123, data={\"value\": 42})\nprint(f\"Enqueued job {job.id} to process record 123.\")\n</code></pre> <p>Note</p> <p>To run this example, you'll need a running Redis server and a FlowerPower worker. The worker will pick up and execute the enqueued jobs.</p>"},{"location":"installation/","title":"Installation","text":"<p>Welcome to the FlowerPower installation guide. This page will walk you through the steps to get FlowerPower up and running on your system.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li> <p>Python 3.8 or higher: FlowerPower requires a modern version of Python. You can check your Python version by running:</p> <pre><code>python --version\n</code></pre> </li> <li> <p>A package manager: We recommend using a modern package manager like <code>uv</code> or <code>pip</code> for a smooth installation experience.</p> </li> </ul> <p>Project and Environment Management</p> <p>For robust project management, we highly recommend using tools like <code>uv</code> or <code>pixi</code>. These tools help you manage dependencies and ensure your projects are reproducible.</p>"},{"location":"installation/#standard-installation","title":"Standard Installation","text":"<p>The recommended way to install FlowerPower is with <code>uv pip</code>:</p> <pre><code>uv pip install flowerpower\n</code></pre> <p>Alternatively, you can use <code>pip</code>:</p> <pre><code>pip install flowerpower\n</code></pre> <p>This will install the core FlowerPower library with all the essential features to get you started.</p>"},{"location":"installation/#optional-dependencies","title":"Optional Dependencies","text":"<p>FlowerPower offers optional dependencies that you can install to enable additional functionality.</p> <ul> <li> <p>RQ Job Queue Support: To use FlowerPower with the Redis Queue (RQ) job queue, install the <code>[rq]</code> extra:</p> <pre><code>uv pip install 'flowerpower[rq]'\n</code></pre> </li> <li> <p>I/O Plugins: For additional I/O capabilities, install the <code>[io]</code> extra:</p> <pre><code>uv pip install 'flowerpower[io]'\n</code></pre> </li> <li> <p>Hamilton UI: To use the Hamilton UI for interactive dataflow visualization, install the <code>[ui]</code> extra:</p> <pre><code>uv pip install 'flowerpower[ui]'\n</code></pre> </li> <li> <p>All Extras: To install all optional dependencies at once, use the <code>[all]</code> extra:</p> <pre><code>uv pip install 'flowerpower[all]'\n</code></pre> </li> </ul>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":"<p>If you encounter issues during installation, here are a few tips:</p> <ul> <li> <p>Use a Virtual Environment: It is highly recommended to install FlowerPower in a virtual environment to avoid conflicts with other packages. You can create one with <code>uv</code>:</p> <pre><code>uv venv\nsource .venv/bin/activate\n</code></pre> </li> <li> <p>Check Your PATH: Ensure that your Python and script installation directories are in your system's <code>PATH</code>. If you can't run <code>flowerpower</code> from your terminal, this might be the issue.</p> </li> <li> <p>Permissions: If you get a permission error, you might be trying to install the package globally without the necessary privileges. Using a virtual environment is the best way to avoid this.</p> </li> </ul> <p>If you continue to have problems, please open an issue on our GitHub repository.</p>"},{"location":"quickstart/","title":"Quickstart","text":"<p>Welcome to the FlowerPower quickstart guide! This guide will walk you through the process of creating a \"Hello World\" project to demonstrate the core functionalities of the library.</p>"},{"location":"quickstart/#installation","title":"Installation","text":"<p>First, ensure you have FlowerPower installed. We recommend using <code>uv</code> for a fast and reliable installation.</p> <pre><code># Create and activate a virtual environment\nuv venv\nsource .venv/bin/activate\n\n# Install FlowerPower with RQ for job queue support\nuv pip install flowerpower[rq]\n</code></pre>"},{"location":"quickstart/#1-initialize-your-project","title":"1. Initialize Your Project","text":"<p>You can create a new project using either the CLI or the Python API.</p>"},{"location":"quickstart/#using-the-cli","title":"Using the CLI","text":"<pre><code>flowerpower init --name hello-flowerpower --job_queue_type rq\ncd hello-flowerpower\n</code></pre>"},{"location":"quickstart/#using-the-python-api","title":"Using the Python API","text":"<pre><code>from flowerpower import FlowerPowerProject\n\n# Initialize a new project with RQ job queue support\nproject = FlowerPowerProject.init(\n    name='hello-flowerpower',\n    job_queue_type='rq'\n)\n</code></pre> <p>This creates a standard project structure with <code>conf/</code> and <code>pipelines/</code> directories.</p>"},{"location":"quickstart/#2-configure-your-project","title":"2. Configure Your Project","text":"<p>The <code>conf/project.yml</code> file contains global settings for your project, including the job queue configuration.</p> <pre><code># conf/project.yml\nname: hello-flowerpower\njob_queue:\n  type: rq\n  backend:\n    type: redis\n    host: localhost\n    port: 6379\n    queues:\n      - default\n      - high\n      - low\n</code></pre>"},{"location":"quickstart/#3-create-a-pipeline","title":"3. Create a Pipeline","text":"<p>Next, create a pipeline to define your data processing logic.</p>"},{"location":"quickstart/#using-the-cli_1","title":"Using the CLI","text":"<pre><code>flowerpower pipeline new hello_world\n</code></pre>"},{"location":"quickstart/#using-the-python-api_1","title":"Using the Python API","text":"<pre><code>from flowerpower import FlowerPowerProject\n\nproject = FlowerPowerProject.load('.')\nproject.pipeline_manager.new(name='hello_world')\n</code></pre> <p>This generates <code>pipelines/hello_world.py</code> for your pipeline logic and <code>conf/pipelines/hello_world.yml</code> for its configuration.</p>"},{"location":"quickstart/#4-implement-the-pipeline","title":"4. Implement the Pipeline","text":"<p>Open <code>pipelines/hello_world.py</code> and add your Hamilton functions.</p> <pre><code># pipelines/hello_world.py\nfrom pathlib import Path\nfrom hamilton.function_modifiers import parameterize\nfrom flowerpower.cfg import Config\n\n# Load pipeline parameters\nPARAMS = Config.load(\n    Path(__file__).parents[1], pipeline_name=\"hello_world\"\n).pipeline.h_params\n\n@parameterize(**PARAMS.greeting_message)\ndef greeting_message(message: str) -&gt; str:\n    return f\"{message},\"\n\n@parameterize(**PARAMS.target_name)\ndef target_name(name: str) -&gt; str:\n    return f\"{name}!\"\n\ndef full_greeting(greeting_message: str, target_name: str) -&gt; str:\n    \"\"\"Combines the greeting and target.\"\"\"\n    print(f\"Executing pipeline: {greeting_message} {target_name}\")\n    return f\"{greeting_message} {target_name}\"\n</code></pre>"},{"location":"quickstart/#5-configure-the-pipeline","title":"5. Configure the Pipeline","text":"<p>In <code>conf/pipelines/hello_world.yml</code>, define the parameters and execution details for your pipeline.</p> <pre><code># conf/pipelines/hello_world.yml\nparams:\n  greeting_message:\n    message: \"Hello\"\n  target_name:\n    name: \"World\"\n\nrun:\n  final_vars:\n    - full_greeting\n\nschedule:\n  cron: \"0 * * * *\" # Run hourly\n</code></pre>"},{"location":"quickstart/#6-run-the-pipeline","title":"6. Run the Pipeline","text":"<p>You can run your pipeline synchronously for quick tests or asynchronously for scheduled and background jobs.</p>"},{"location":"quickstart/#synchronous-execution","title":"Synchronous Execution","text":"<p>This is useful for debugging and local development.</p>"},{"location":"quickstart/#using-the-cli_2","title":"Using the CLI","text":"<pre><code>flowerpower pipeline run hello_world\n</code></pre>"},{"location":"quickstart/#using-the-python-api_2","title":"Using the Python API","text":"<pre><code>from flowerpower import FlowerPowerProject\n\nproject = FlowerPowerProject.load('.')\nresult = project.run('hello_world')\nprint(result)\n</code></pre>"},{"location":"quickstart/#asynchronous-execution","title":"Asynchronous Execution","text":"<p>For asynchronous execution, you need a running Redis server.</p> <p>Note</p> <p>Ensure Redis is running before proceeding with asynchronous execution. You can use the provided Docker setup for a quick start: <pre><code>cd docker\ndocker-compose up -d redis\n</code></pre></p>"},{"location":"quickstart/#enqueue-a-job","title":"Enqueue a Job","text":"<p>Add your pipeline to the job queue for background processing.</p>"},{"location":"quickstart/#using-the-cli_3","title":"Using the CLI","text":"<pre><code>flowerpower pipeline add-job hello_world\n</code></pre>"},{"location":"quickstart/#using-the-python-api_3","title":"Using the Python API","text":"<pre><code>from flowerpower import FlowerPowerProject\n\nproject = FlowerPowerProject.load('.')\njob_id = project.enqueue('hello_world')\nprint(f\"Job enqueued with ID: {job_id}\")\n</code></pre>"},{"location":"quickstart/#start-a-worker","title":"Start a Worker","text":"<p>Workers are required to process jobs from the queue.</p>"},{"location":"quickstart/#using-the-cli_4","title":"Using the CLI","text":"<pre><code>flowerpower job-queue start-worker\n</code></pre>"},{"location":"quickstart/#using-the-python-api_4","title":"Using the Python API","text":"<pre><code>from flowerpower import FlowerPowerProject\n\nproject = FlowerPowerProject.load('.')\n# Start a worker in the background\nproject.start_worker(background=True)\n</code></pre> <p>For more details on managing your project, refer to the API documentation for <code>FlowerPowerProject</code>, <code>PipelineManager</code>, and <code>JobQueueManager</code>.</p>"},{"location":"api/","title":"API Reference","text":"<p>This section provides a detailed reference for the FlowerPower API.</p>"},{"location":"api/#core-components","title":"Core Components","text":"<ul> <li>FlowerPowerProject</li> <li>PipelineManager</li> <li>JobQueueManager</li> <li>RQManager</li> </ul>"},{"location":"api/#configuration","title":"Configuration","text":"<ul> <li>Configuration</li> </ul>"},{"location":"api/#top-level-functions","title":"Top-Level Functions","text":"<ul> <li>init</li> </ul>"},{"location":"api/#cli-reference","title":"CLI Reference","text":"<ul> <li>CLI Overview</li> <li>CLI Pipeline Commands</li> <li>CLI Job Queue Commands</li> <li>CLI MQTT Commands</li> </ul>"},{"location":"api/cli/","title":"CLI Reference","text":"<p>This section provides a comprehensive reference for the FlowerPower Command Line Interface (CLI).</p>"},{"location":"api/cli/#main-commands","title":"Main Commands","text":""},{"location":"api/cli/#flowerpower-init","title":"<code>flowerpower init</code>","text":"<p>Initialize a new FlowerPower project.</p> <pre><code>This command creates a new FlowerPower project with the necessary directory structure\nand configuration files. If no project name is provided, the current directory name\nwill be used as the project name.\n</code></pre>"},{"location":"api/cli/#usage","title":"Usage","text":"<pre><code>flowerpower init [options]\n</code></pre>"},{"location":"api/cli/#arguments","title":"Arguments","text":"Name Type Description Default project_name str Name of the FlowerPower project to create. If not provided, Required base_dir str Base directory where the project will be created. If not provided, Required storage_options str Storage options for filesystem access, as a JSON or dict string Required job_queue_type str Type of job queue backend to use (rq) Required"},{"location":"api/cli/#examples","title":"Examples","text":"<pre><code>$ flowerpower init\n\n# Create a project with a specific name\n</code></pre> <pre><code>$ flowerpower init --name my-awesome-project\n\n# Create a project in a specific location\n</code></pre> <pre><code>$ flowerpower init --name my-project --base-dir /path/to/projects\n\n# Create a project with RQ as the job queue backend (default)\n</code></pre> <pre><code>$ flowerpower init --job-queue-type rq\n</code></pre>"},{"location":"api/cli/#flowerpower-ui","title":"<code>flowerpower ui</code>","text":"<p>Start the Hamilton UI web application.</p> <pre><code>This command launches the Hamilton UI, which provides a web interface for\nvisualizing and interacting with your FlowerPower pipelines. The UI allows you\nto explore pipeline execution graphs, view results, and manage jobs.\n</code></pre>"},{"location":"api/cli/#usage_1","title":"Usage","text":"<pre><code>flowerpower ui [options]\n</code></pre>"},{"location":"api/cli/#arguments_1","title":"Arguments","text":"Name Type Description Default port str Port to run the UI server on Required base_dir str Base directory where the UI will store its data Required no_migration str Skip running database migrations on startup Required no_open str Prevent automatically opening the browser Required settings_file str Settings profile to use (mini, dev, prod) Required config_file str Optional custom configuration file path Required"},{"location":"api/cli/#examples_1","title":"Examples","text":"<pre><code>$ flowerpower ui\n\n# Run the UI on a specific port\n</code></pre> <pre><code>$ flowerpower ui --port 9000\n\n# Use a custom data directory\n</code></pre> <pre><code>$ flowerpower ui --base-dir ~/my-project/.hamilton-data\n\n# Start without opening a browser\n</code></pre> <pre><code>$ flowerpower ui --no-open\n\n# Use production settings\n</code></pre> <pre><code>$ flowerpower ui --settings prod\n</code></pre>"},{"location":"api/cli_job_queue/","title":"<code>flowerpower job-queue</code> Commands","text":"<p>This section details the commands available under <code>flowerpower job-queue</code>.</p>"},{"location":"api/cli_job_queue/#flowerpower-start_worker","title":"<code>flowerpower job-queue start_worker</code>","text":"<p>Start a worker or worker pool to process jobs.</p> <pre><code>This command starts a worker process (or a pool of worker processes) that will\nexecute jobs from the queue. The worker will continue running until stopped\nor can be run in the background.\n</code></pre>"},{"location":"api/cli_job_queue/#usage","title":"Usage","text":"<pre><code>flowerpower job-queue start_worker [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments","title":"Arguments","text":"Name Type Description Default type str Type of job queue backend (rq) Required name str Name of the scheduler configuration to use Required base_dir str Base directory for the scheduler configuration Required background str Run the worker in the background Required storage_options str Storage options as JSON or key=value pairs Required log_level str Logging level (debug, info, warning, error, critical) Required num_workers str Number of worker processes to start (pool mode) Required"},{"location":"api/cli_job_queue/#examples","title":"Examples","text":"<pre><code>$ flowerpower job-queue start-worker\n\n# Start a worker for a specific backend type\n</code></pre> <pre><code>$ flowerpower job-queue start-worker --type rq\n\n# Start a worker pool with 4 processes\n</code></pre> <pre><code>$ flowerpower job-queue start-worker --num-workers 4\n\n# Run a worker in the background\n</code></pre> <pre><code>$ flowerpower job-queue start-worker --background\n\n# Set a specific logging level\n</code></pre> <pre><code>$ flowerpower job-queue start-worker --log-level debug\n</code></pre>"},{"location":"api/cli_job_queue/#flowerpower-cancel_job","title":"<code>flowerpower job-queue cancel_job</code>","text":"<p>Cancel a job or multiple jobs in the queue.</p> <pre><code>This command stops a job from executing (if it hasn't started yet) or signals\nit to stop (if already running). Canceling is different from deleting as it\nmaintains the job history but prevents execution.\n</code></pre>"},{"location":"api/cli_job_queue/#usage_1","title":"Usage","text":"<pre><code>flowerpower job-queue cancel_job [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments_1","title":"Arguments","text":"Name Type Description Default job_id str ID of the job to cancel (ignored if --all is used) Required all str Cancel all jobs instead of a specific one Required queue_name str For RQ only, specifies the queue to cancel jobs from Required type str Type of job queue backend (rq) Required name str Name of the scheduler configuration to use Required base_dir str Base directory for the scheduler configuration Required storage_options str Storage options as JSON or key=value pairs Required log_level str Logging level (debug, info, warning, error, critical) Required"},{"location":"api/cli_job_queue/#examples_1","title":"Examples","text":"<pre><code>$ flowerpower job-queue cancel-job job-123456\n\n# Cancel all jobs in the default queue\n</code></pre> <pre><code>$ flowerpower job-queue cancel-job --all dummy-id\n\n# Cancel all jobs in a specific queue (RQ only)\n</code></pre> <pre><code>$ flowerpower job-queue cancel-job --all dummy-id --queue-name high-priority\n\n# Specify the backend type explicitly\n</code></pre> <pre><code>$ flowerpower job-queue cancel-job job-123456 --type rq\n</code></pre>"},{"location":"api/cli_job_queue/#flowerpower-cancel_schedule","title":"<code>flowerpower job-queue cancel_schedule</code>","text":"<p>Cancel a specific schedule.</p> <pre><code>Note: This is different from deleting a schedule as it only stops it from running but keeps its configuration.\n</code></pre>"},{"location":"api/cli_job_queue/#usage_2","title":"Usage","text":"<pre><code>flowerpower job-queue cancel_schedule [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments_2","title":"Arguments","text":"Name Type Description Default schedule_id str ID of the schedule to cancel Required all str If True, cancel all schedules Required type str Type of the job queue (rq) Required name str Name of the scheduler Required base_dir str Base directory for the scheduler Required storage_options str Storage options as JSON or key=value pairs Required log_level str Logging level Required"},{"location":"api/cli_job_queue/#flowerpower-delete_job","title":"<code>flowerpower job-queue delete_job</code>","text":"<p>Delete a specific job.</p>"},{"location":"api/cli_job_queue/#usage_3","title":"Usage","text":"<pre><code>flowerpower job-queue delete_job [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments_3","title":"Arguments","text":"Name Type Description Default job_id str ID of the job to delete Required all str If True, delete all jobs Required queue_name str Name of the queue (RQ only). If provided and all is True, delete all jobs in the queue Required type str Type of the job queue (rq) Required name str Name of the scheduler Required base_dir str Base directory for the scheduler Required storage_options str Storage options as JSON or key=value pairs Required log_level str Logging level Required"},{"location":"api/cli_job_queue/#flowerpower-delete_schedule","title":"<code>flowerpower job-queue delete_schedule</code>","text":"<p>Delete a specific schedule.</p>"},{"location":"api/cli_job_queue/#usage_4","title":"Usage","text":"<pre><code>flowerpower job-queue delete_schedule [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments_4","title":"Arguments","text":"Name Type Description Default schedule_id str ID of the schedule to delete Required all str If True, delete all schedules Required type str Type of the job queue (rq) Required name str Name of the scheduler Required base_dir str Base directory for the scheduler Required storage_options str Storage options as JSON or key=value pairs Required log_level str Logging level Required"},{"location":"api/cli_job_queue/#flowerpower-show_job_ids","title":"<code>flowerpower job-queue show_job_ids</code>","text":"<p>Show all job IDs in the job queue.</p> <pre><code>This command displays all job IDs currently in the system, helping you identify\njobs for other operations like getting results, canceling, or deleting jobs.\n</code></pre>"},{"location":"api/cli_job_queue/#usage_5","title":"Usage","text":"<pre><code>flowerpower job-queue show_job_ids [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments_5","title":"Arguments","text":"Name Type Description Default type str Type of job queue backend (rq) Required name str Name of the scheduler configuration to use Required base_dir str Base directory for the scheduler configuration Required storage_options str Storage options as JSON or key=value pairs Required log_level str Logging level (debug, info, warning, error, critical) Required"},{"location":"api/cli_job_queue/#examples_2","title":"Examples","text":"<pre><code>$ flowerpower job-queue show-job-ids\n\n# Show job IDs for a specific queue type\n</code></pre> <pre><code>$ flowerpower job-queue show-job-ids --type rq\n\n# Show job IDs with a custom scheduler configuration\n</code></pre> <pre><code>$ flowerpower job-queue show-job-ids --name my-scheduler\n\n# Show job IDs with debug logging\n</code></pre> <pre><code>$ flowerpower job-queue show-job-ids --log-level debug\n</code></pre>"},{"location":"api/cli_job_queue/#flowerpower-show_schedule_ids","title":"<code>flowerpower job-queue show_schedule_ids</code>","text":"<p>Show all schedule IDs in the job queue.</p> <pre><code>This command displays all schedule IDs currently in the system, helping you\nidentify schedules for other operations like pausing, resuming, or deleting schedules.\n</code></pre>"},{"location":"api/cli_job_queue/#usage_6","title":"Usage","text":"<pre><code>flowerpower job-queue show_schedule_ids [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments_6","title":"Arguments","text":"Name Type Description Default type str Type of job queue backend (rq) Required name str Name of the scheduler configuration to use Required base_dir str Base directory for the scheduler configuration Required storage_options str Storage options as JSON or key=value pairs Required log_level str Logging level (debug, info, warning, error, critical) Required"},{"location":"api/cli_job_queue/#examples_3","title":"Examples","text":"<pre><code>$ flowerpower job-queue show-schedule-ids\n\n# Show schedule IDs for RQ\n</code></pre> <pre><code>$ flowerpower job-queue show-schedule-ids --type rq\n\n# Show schedule IDs with a custom scheduler configuration\n</code></pre> <pre><code>$ flowerpower job-queue show-schedule-ids --name my-scheduler\n\n# Show schedule IDs with debug logging\n</code></pre> <pre><code>$ flowerpower job-queue show-schedule-ids --log-level debug\n</code></pre>"},{"location":"api/cli_job_queue/#flowerpower-pause_schedule","title":"<code>flowerpower job-queue pause_schedule</code>","text":"<p>Pause a schedule or multiple schedules.</p> <pre><code>This command temporarily stops a scheduled job from running while maintaining its\nconfiguration. Paused schedules can be resumed later. Note that this functionality\nis only available for APScheduler workers.\n</code></pre>"},{"location":"api/cli_job_queue/#usage_7","title":"Usage","text":"<pre><code>flowerpower job-queue pause_schedule [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments_7","title":"Arguments","text":"Name Type Description Default schedule_id str ID of the schedule to pause (ignored if --all is used) Required all str Pause all schedules instead of a specific one Required type str Type of job queue backend (rq) Required name str Name of the scheduler configuration to use Required base_dir str Base directory for the scheduler configuration Required storage_options str Storage options as JSON or key=value pairs Required log_level str Logging level (debug, info, warning, error, critical) Required"},{"location":"api/cli_job_queue/#examples_4","title":"Examples","text":"<pre><code>$ flowerpower job-queue pause-schedule schedule-123456\n\n# Pause all schedules\n</code></pre> <pre><code>$ flowerpower job-queue pause-schedule --all dummy-id\n\n# Note: Schedule pausing is not supported for RQ workers\n</code></pre>"},{"location":"api/cli_job_queue/#flowerpower-resume_schedule","title":"<code>flowerpower job-queue resume_schedule</code>","text":"<p>Resume a paused schedule or multiple schedules.</p> <pre><code>This command restarts previously paused schedules, allowing them to run again according\nto their original configuration. Note that this functionality is only available for\nAPScheduler workers.\n</code></pre>"},{"location":"api/cli_job_queue/#usage_8","title":"Usage","text":"<pre><code>flowerpower job-queue resume_schedule [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments_8","title":"Arguments","text":"Name Type Description Default schedule_id str ID of the schedule to resume (ignored if --all is used) Required all str Resume all schedules instead of a specific one Required type str Type of job queue backend (rq) Required name str Name of the scheduler configuration to use Required base_dir str Base directory for the scheduler configuration Required storage_options str Storage options as JSON or key=value pairs Required log_level str Logging level (debug, info, warning, error, critical) Required"},{"location":"api/cli_job_queue/#examples_5","title":"Examples","text":"<pre><code>$ flowerpower job-queue resume-schedule schedule-123456\n\n# Resume all schedules\n</code></pre> <pre><code>$ flowerpower job-queue resume-schedule --all dummy-id\n\n# Note: Schedule resuming is not supported for RQ workers\n\n# Set a specific logging level\n</code></pre> <pre><code>$ flowerpower job-queue resume-schedule schedule-123456 --log-level debug\n</code></pre>"},{"location":"api/cli_job_queue/#flowerpower-show_jobs","title":"<code>flowerpower job-queue show_jobs</code>","text":"<p>Display detailed information about all jobs in the queue.</p> <pre><code>This command shows comprehensive information about jobs including their status,\ncreation time, execution time, and other details in a user-friendly format.\n</code></pre>"},{"location":"api/cli_job_queue/#usage_9","title":"Usage","text":"<pre><code>flowerpower job-queue show_jobs [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments_9","title":"Arguments","text":"Name Type Description Default type str Type of job queue backend (rq) Required queue_name str Name of the queue to show jobs from (RQ only) Required name str Name of the scheduler configuration to use Required base_dir str Base directory for the scheduler configuration Required storage_options str Storage options as JSON or key=value pairs Required log_level str Logging level (debug, info, warning, error, critical) Required format str Output format for the job information Required"},{"location":"api/cli_job_queue/#examples_6","title":"Examples","text":"<pre><code>$ flowerpower job-queue show-jobs\n\n# Show jobs for a specific queue type\n</code></pre> <pre><code>$ flowerpower job-queue show-jobs --type rq\n\n# Show jobs in a specific RQ queue\n</code></pre> <pre><code>$ flowerpower job-queue show-jobs --queue-name high-priority\n\n# Display jobs in JSON format\n</code></pre> <pre><code>$ flowerpower job-queue show-jobs --format json\n</code></pre>"},{"location":"api/cli_job_queue/#flowerpower-show_schedules","title":"<code>flowerpower job-queue show_schedules</code>","text":"<p>Display detailed information about all schedules.</p> <pre><code>This command shows comprehensive information about scheduled jobs including their\ntiming configuration, status, and other details in a user-friendly format.\n</code></pre>"},{"location":"api/cli_job_queue/#usage_10","title":"Usage","text":"<pre><code>flowerpower job-queue show_schedules [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments_10","title":"Arguments","text":"Name Type Description Default type str Type of job queue backend (rq) Required name str Name of the scheduler configuration to use Required base_dir str Base directory for the scheduler configuration Required storage_options str Storage options as JSON or key=value pairs Required log_level str Logging level (debug, info, warning, error, critical) Required format str Output format for the schedule information Required"},{"location":"api/cli_job_queue/#examples_7","title":"Examples","text":"<pre><code>$ flowerpower job-queue show-schedules\n\n# Show schedules for RQ\n</code></pre> <pre><code>$ flowerpower job-queue show-schedules --type rq\n\n# Display schedules in JSON format\n</code></pre> <pre><code>$ flowerpower job-queue show-schedules --format json\n</code></pre>"},{"location":"api/cli_job_queue/#flowerpower-enqueue_pipeline","title":"<code>flowerpower job-queue enqueue_pipeline</code>","text":"<p>Enqueue a pipeline for execution via the job queue.</p> <pre><code>This command queues a pipeline for asynchronous execution using the configured\njob queue backend (RQ). The job can be executed immediately, after a delay,\nor at a specific time.\n</code></pre>"},{"location":"api/cli_job_queue/#usage_11","title":"Usage","text":"<pre><code>flowerpower job-queue enqueue_pipeline [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments_11","title":"Arguments","text":"Name Type Description Default name str Name of the pipeline to enqueue Required base_dir str Base directory containing pipelines and configurations Required inputs str Input parameters for the pipeline Required final_vars str Final variables to request from the pipeline Required storage_options str Options for storage backends Required log_level str Set the logging level Required run_in str Delay before execution (duration format like '5m', '1h', '30s') Required run_at str Specific datetime for execution (ISO format) Required"},{"location":"api/cli_job_queue/#examples_8","title":"Examples","text":"<pre><code>$ flowerpower job-queue enqueue-pipeline my_pipeline\n\n# Enqueue with custom inputs\n</code></pre> <pre><code>$ flowerpower job-queue enqueue-pipeline my_pipeline --inputs '{\"data_path\": \"data/file.csv\"}'\n\n# Enqueue with delay\n</code></pre> <pre><code>$ flowerpower job-queue enqueue-pipeline my_pipeline --run-in \"30m\"\n\n# Enqueue for specific time\n</code></pre> <pre><code>$ flowerpower job-queue enqueue-pipeline my_pipeline --run-at \"2025-01-01T09:00:00\"\n</code></pre>"},{"location":"api/cli_job_queue/#flowerpower-schedule_pipeline","title":"<code>flowerpower job-queue schedule_pipeline</code>","text":"<p>Schedule a pipeline for recurring or future execution.</p> <pre><code>This command sets up recurring or future execution of a pipeline using cron\nexpressions or interval-based scheduling via the configured job queue backend.\n</code></pre>"},{"location":"api/cli_job_queue/#usage_12","title":"Usage","text":"<pre><code>flowerpower job-queue schedule_pipeline [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments_12","title":"Arguments","text":"Name Type Description Default name str Name of the pipeline to schedule Required base_dir str Base directory containing pipelines and configurations Required cron str Cron expression for scheduling (e.g., '0 9 * * *' for 9 AM daily) Required interval str Interval for recurring execution (duration format) Required inputs str Input parameters for the pipeline Required final_vars str Final variables to request from the pipeline Required storage_options str Options for storage backends Required log_level str Set the logging level Required schedule_id str Custom identifier for the schedule Required"},{"location":"api/cli_job_queue/#examples_9","title":"Examples","text":"<pre><code>$ flowerpower job-queue schedule-pipeline my_pipeline --cron \"0 9 * * *\"\n\n# Schedule every 30 minutes\n</code></pre> <pre><code>$ flowerpower job-queue schedule-pipeline my_pipeline --interval \"30m\"\n\n# Schedule with custom inputs and ID\n</code></pre> <pre><code>$ flowerpower job-queue schedule-pipeline my_pipeline --cron \"0 0 * * *\" \\\\\n--inputs '{\"env\": \"prod\"}' --schedule-id \"nightly-prod\"\n</code></pre>"},{"location":"api/cli_job_queue/#flowerpower-run_job","title":"<code>flowerpower job-queue run_job</code>","text":"<p>Execute a specific job by its ID.</p> <pre><code>This command runs a job that has been previously enqueued in the job queue.\nThe job will be executed immediately regardless of its original schedule.\n</code></pre>"},{"location":"api/cli_job_queue/#usage_13","title":"Usage","text":"<pre><code>flowerpower job-queue run_job [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments_13","title":"Arguments","text":"Name Type Description Default job_id str ID of the job to run Required type str Type of job queue backend (rq) Required name str Name of the scheduler configuration to use Required base_dir str Base directory for the scheduler configuration Required storage_options str Storage options as JSON or key=value pairs Required log_level str Logging level (debug, info, warning, error, critical) Required"},{"location":"api/cli_job_queue/#examples_10","title":"Examples","text":"<pre><code>$ flowerpower job-queue run-job job-123456\n\n# Run a job with a specific backend type\n</code></pre> <pre><code>$ flowerpower job-queue run-job job-123456 --type rq\n\n# Run a job with debug logging\n</code></pre> <pre><code>$ flowerpower job-queue run-job job-123456 --log-level debug\n</code></pre>"},{"location":"api/cli_job_queue/#flowerpower-list_schedules","title":"<code>flowerpower job-queue list_schedules</code>","text":"<p>List all schedules with detailed status information.</p> <pre><code>This command provides enhanced schedule listing showing trigger configuration,\nstatus, next run time, and execution history. This is an enhanced version of\nshow-schedules with more detailed information.\n</code></pre>"},{"location":"api/cli_job_queue/#usage_14","title":"Usage","text":"<pre><code>flowerpower job-queue list_schedules [options]\n</code></pre>"},{"location":"api/cli_job_queue/#arguments_14","title":"Arguments","text":"Name Type Description Default type str Type of job queue backend (rq) Required name str Name of the scheduler configuration to use Required base_dir str Base directory for the scheduler configuration Required storage_options str Storage options as JSON or key=value pairs Required log_level str Logging level (debug, info, warning, error, critical) Required format str Output format for the schedule information Required show_status str Include schedule status information Required show_next_run str Include next execution time information Required"},{"location":"api/cli_job_queue/#examples_11","title":"Examples","text":"<pre><code>$ flowerpower job-queue list-schedules\n\n# List schedules in JSON format\n</code></pre> <pre><code>$ flowerpower job-queue list-schedules --format json\n\n# List schedules without status information\n</code></pre> <pre><code>$ flowerpower job-queue list-schedules --no-show-status\n\n# List schedules for a specific backend\n</code></pre> <pre><code>$ flowerpower job-queue list-schedules --type rq\n</code></pre>"},{"location":"api/cli_mqtt/","title":"<code>flowerpower mqtt</code> Commands","text":"<p>This section details the commands available under <code>flowerpower mqtt</code>.</p>"},{"location":"api/cli_mqtt/#flowerpower-start_listener","title":"<code>flowerpower mqtt start_listener</code>","text":"<p>Start an MQTT client to listen to messages on a topic</p> <pre><code>The connection to the MQTT broker is established using the provided configuration o a\nMQTT event broker defined in the project configuration file `conf/project.yml`.\nIf not configuration is found, you have to provide the connection parameters,\nsuch as `host`, `port`, `username`, and `password`.\n\nThe `on_message` module should contain a function `on_message` that will be called\nwith the message payload as argument.\n</code></pre>"},{"location":"api/cli_mqtt/#usage","title":"Usage","text":"<pre><code>flowerpower mqtt start_listener [options]\n</code></pre>"},{"location":"api/cli_mqtt/#arguments","title":"Arguments","text":"Name Type Description Default on_message str Name of the module containing the on_message function Required topic str MQTT topic to listen to Required base_dir str Base directory for the module Required host str MQTT broker host Required port str MQTT broker port Required username str MQTT broker username Required password str MQTT broker password Required"},{"location":"api/cli_mqtt/#examples","title":"Examples","text":"<pre><code>$ flowerpower mqtt start_listener --on-message my_module --topic my_topic --base-dir /path/to/module\n</code></pre>"},{"location":"api/cli_mqtt/#flowerpower-run_pipeline_on_message","title":"<code>flowerpower mqtt run_pipeline_on_message</code>","text":"<p>Run a pipeline on a message</p> <pre><code>This command sets up an MQTT listener that executes a pipeline whenever a message is\nreceived on the specified topic. The pipeline can be configured to retry on failure\nusing exponential backoff with jitter for better resilience.\n</code></pre>"},{"location":"api/cli_mqtt/#usage_1","title":"Usage","text":"<pre><code>flowerpower mqtt run_pipeline_on_message [options]\n</code></pre>"},{"location":"api/cli_mqtt/#arguments_1","title":"Arguments","text":"Name Type Description Default name str Name of the pipeline Required topic str MQTT topic to listen to Required executor str Name of the executor Required base_dir str Base directory for the pipeline Required inputs str Inputs as JSON or key=value pairs or dict string Required final_vars str Final variables as JSON or list Required config str Config for the hamilton pipeline executor Required with_tracker str Enable tracking with hamilton ui Required with_opentelemetry str Enable OpenTelemetry tracing Required with_progressbar str Enable progress bar Required storage_options str Storage options as JSON, dict string or key=value pairs Required as_job str Run as a job in the scheduler Required host str MQTT broker host Required port str MQTT broker port Required username str MQTT broker username Required password str MQTT broker password Required clean_session str Whether to start a clean session with the broker Required qos str MQTT Quality of Service level (0, 1, or 2) Required client_id str Custom MQTT client identifier Required client_id_suffix str Optional suffix to append to client_id Required config_hook str Function to process incoming messages into pipeline config Required max_retries str Maximum number of retry attempts if pipeline execution fails Required retry_delay str Base delay between retries in seconds Required jitter_factor str Random factor (0-1) applied to delay for jitter Required"},{"location":"api/cli_mqtt/#examples_1","title":"Examples","text":"<pre><code>$ flowerpower mqtt run-pipeline-on-message my_pipeline --topic sensors/data\n\n# Configure retries for resilience\n</code></pre> <pre><code>$ flowerpower mqtt run-pipeline-on-message my_pipeline --topic sensors/data --max-retries 5 --retry-delay 2.0\n\n# Run as a job with custom MQTT settings\n</code></pre> <pre><code>$ flowerpower mqtt run-pipeline-on-message my_pipeline --topic events/process --as-job --qos 2 --host mqtt.example.com\n\n# Use a config hook to process messages\n</code></pre> <pre><code>$ flowerpower mqtt run-pipeline-on-message my_pipeline --topic data/incoming --config-hook process_message\n</code></pre>"},{"location":"api/cli_pipeline/","title":"<code>flowerpower pipeline</code> Commands","text":"<p>This section details the commands available under <code>flowerpower pipeline</code>.</p>"},{"location":"api/cli_pipeline/#flowerpower-run","title":"<code>flowerpower pipeline run</code>","text":"<p>Run a pipeline immediately.</p> <pre><code>This command executes a pipeline with the specified configuration and inputs.\nThe pipeline will run synchronously, and the command will wait for completion.\n</code></pre>"},{"location":"api/cli_pipeline/#usage","title":"Usage","text":"<pre><code>flowerpower pipeline run [options]\n</code></pre>"},{"location":"api/cli_pipeline/#arguments","title":"Arguments","text":"Name Type Description Default name str Name of the pipeline to run Required executor str Type of executor to use Required base_dir str Base directory containing pipelines and configurations Required inputs str Input parameters for the pipeline Required final_vars str Final variables to request from the pipeline Required config str Configuration for the Hamilton executor Required cache str Cache configuration for improved performance Required storage_options str Options for storage backends Required log_level str Set the logging level Required with_adapter str Configuration for adapters like trackers or monitors Required max_retries str Maximum number of retry attempts on failure Required retry_delay str Base delay between retries in seconds Required jitter_factor str Random factor applied to delay for jitter (0-1) Required"},{"location":"api/cli_pipeline/#examples","title":"Examples","text":"<pre><code>$ pipeline run my_pipeline\n\n# Run with custom inputs\n</code></pre> <pre><code>$ pipeline run my_pipeline --inputs '{\"data_path\": \"data/myfile.csv\", \"limit\": 100}'\n\n# Specify which final variables to calculate\n</code></pre> <pre><code>$ pipeline run my_pipeline --final-vars '[\"output_table\", \"summary_metrics\"]'\n\n# Configure caching\n</code></pre> <pre><code>$ pipeline run my_pipeline --cache '{\"type\": \"memory\", \"ttl\": 3600}'\n\n# Use a different executor\n</code></pre> <pre><code>$ pipeline run my_pipeline --executor distributed\n\n# Enable adapters for monitoring/tracking\n</code></pre> <pre><code>$ pipeline run my_pipeline --with-adapter '{\"tracker\": true, \"opentelemetry\": true}'\n\n# Set a specific logging level\n</code></pre> <pre><code>$ pipeline run my_pipeline --log-level debug\n\n# Configure automatic retries on failure\n</code></pre> <pre><code>$ pipeline run my_pipeline --max-retries 3 --retry-delay 2.0 --jitter-factor 0.2\n</code></pre>"},{"location":"api/cli_pipeline/#flowerpower-new","title":"<code>flowerpower pipeline new</code>","text":"<p>Create a new pipeline structure.</p> <pre><code>This command creates a new pipeline with the necessary directory structure,\nconfiguration file, and skeleton module file. It prepares all the required\ncomponents for you to start implementing your pipeline logic.\n</code></pre>"},{"location":"api/cli_pipeline/#usage_1","title":"Usage","text":"<pre><code>flowerpower pipeline new [options]\n</code></pre>"},{"location":"api/cli_pipeline/#arguments_1","title":"Arguments","text":"Name Type Description Default name str Name for the new pipeline Required base_dir str Base directory to create the pipeline in Required storage_options str Options for storage backends Required log_level str Set the logging level Required overwrite str Whether to overwrite existing pipeline with the same name Required"},{"location":"api/cli_pipeline/#examples_1","title":"Examples","text":"<pre><code>$ pipeline new my_new_pipeline\n\n# Create a pipeline, overwriting if it exists\n</code></pre> <pre><code>$ pipeline new my_new_pipeline --overwrite\n\n# Create a pipeline in a specific directory\n</code></pre> <pre><code>$ pipeline new my_new_pipeline --base-dir /path/to/project\n</code></pre>"},{"location":"api/cli_pipeline/#flowerpower-delete","title":"<code>flowerpower pipeline delete</code>","text":"<p>Delete a pipeline's configuration and/or module files.</p> <pre><code>This command removes a pipeline's configuration file and/or module file from the project.\nIf neither --cfg nor --module is specified, both will be deleted.\n</code></pre>"},{"location":"api/cli_pipeline/#usage_2","title":"Usage","text":"<pre><code>flowerpower pipeline delete [options]\n</code></pre>"},{"location":"api/cli_pipeline/#arguments_2","title":"Arguments","text":"Name Type Description Default name str Name of the pipeline to delete Required base_dir str Base directory containing the pipeline Required cfg str Delete only the configuration file Required module str Delete only the pipeline module Required storage_options str Options for storage backends Required log_level str Set the logging level Required"},{"location":"api/cli_pipeline/#examples_2","title":"Examples","text":"<pre><code>$ pipeline delete my_pipeline\n\n# Delete only the configuration file\n</code></pre> <pre><code>$ pipeline delete my_pipeline --cfg\n\n# Delete only the module file\n</code></pre> <pre><code>$ pipeline delete my_pipeline --module\n</code></pre>"},{"location":"api/cli_pipeline/#flowerpower-show_dag","title":"<code>flowerpower pipeline show_dag</code>","text":"<p>Show the DAG (Directed Acyclic Graph) of a pipeline.</p> <pre><code>This command generates and displays a visual representation of the pipeline's\nexecution graph, showing how nodes are connected and dependencies between them.\n</code></pre>"},{"location":"api/cli_pipeline/#usage_3","title":"Usage","text":"<pre><code>flowerpower pipeline show_dag [options]\n</code></pre>"},{"location":"api/cli_pipeline/#arguments_3","title":"Arguments","text":"Name Type Description Default name str Name of the pipeline to visualize Required base_dir str Base directory containing the pipeline Required storage_options str Options for storage backends Required log_level str Set the logging level Required format str Output format for the visualization Required"},{"location":"api/cli_pipeline/#examples_3","title":"Examples","text":"<pre><code>$ pipeline show-dag my_pipeline\n\n# Generate SVG format visualization\n</code></pre> <pre><code>$ pipeline show-dag my_pipeline --format svg\n\n# Get raw graphviz object\n</code></pre> <pre><code>$ pipeline show-dag my_pipeline --format raw\n</code></pre>"},{"location":"api/cli_pipeline/#flowerpower-save_dag","title":"<code>flowerpower pipeline save_dag</code>","text":"<p>Save the DAG (Directed Acyclic Graph) of a pipeline to a file.</p> <pre><code>This command generates a visual representation of the pipeline's execution graph\nand saves it to a file in the specified format.\n</code></pre>"},{"location":"api/cli_pipeline/#usage_4","title":"Usage","text":"<pre><code>flowerpower pipeline save_dag [options]\n</code></pre>"},{"location":"api/cli_pipeline/#arguments_4","title":"Arguments","text":"Name Type Description Default name str Name of the pipeline to visualize Required base_dir str Base directory containing the pipeline Required storage_options str Options for storage backends Required log_level str Set the logging level Required format str Output format for the visualization Required output_path str Custom file path to save the output (defaults to pipeline name) Required"},{"location":"api/cli_pipeline/#examples_4","title":"Examples","text":"<pre><code>$ pipeline save-dag my_pipeline\n\n# Save in SVG format\n</code></pre> <pre><code>$ pipeline save-dag my_pipeline --format svg\n\n# Save to a custom location\n</code></pre> <pre><code>$ pipeline save-dag my_pipeline --output-path ./visualizations/my_graph.png\n</code></pre>"},{"location":"api/cli_pipeline/#flowerpower-show_pipelines","title":"<code>flowerpower pipeline show_pipelines</code>","text":"<p>List all available pipelines in the project.</p> <pre><code>This command displays a list of all pipelines defined in the project,\nproviding an overview of what pipelines are available to run or schedule.\n</code></pre>"},{"location":"api/cli_pipeline/#usage_5","title":"Usage","text":"<pre><code>flowerpower pipeline show_pipelines [options]\n</code></pre>"},{"location":"api/cli_pipeline/#arguments_5","title":"Arguments","text":"Name Type Description Default base_dir str Base directory containing pipelines Required storage_options str Options for storage backends Required log_level str Set the logging level Required format str Output format for the list (table, json, yaml) Required"},{"location":"api/cli_pipeline/#examples_5","title":"Examples","text":"<pre><code>$ pipeline show-pipelines\n\n# Output in JSON format\n</code></pre> <pre><code>$ pipeline show-pipelines --format json\n\n# List pipelines from a specific directory\n</code></pre> <pre><code>$ pipeline show-pipelines --base-dir /path/to/project\n</code></pre>"},{"location":"api/cli_pipeline/#flowerpower-show_summary","title":"<code>flowerpower pipeline show_summary</code>","text":"<p>Show summary information for one or all pipelines.</p> <pre><code>This command displays detailed information about pipelines including their\nconfiguration, code structure, and project context. You can view information\nfor a specific pipeline or get an overview of all pipelines.\n</code></pre>"},{"location":"api/cli_pipeline/#usage_6","title":"Usage","text":"<pre><code>flowerpower pipeline show_summary [options]\n</code></pre>"},{"location":"api/cli_pipeline/#arguments_6","title":"Arguments","text":"Name Type Description Default name str Name of specific pipeline to summarize (all if not specified) Required cfg str Include configuration details Required code str Include code/module details Required project str Include project context information Required base_dir str Base directory containing pipelines Required storage_options str Options for storage backends Required log_level str Set the logging level Required to_html str Generate HTML output instead of text Required to_svg str Generate SVG output (where applicable) Required output_file str File path to save the output instead of printing to console Required"},{"location":"api/cli_pipeline/#examples_6","title":"Examples","text":"<pre><code>$ pipeline show-summary\n\n# Show summary for a specific pipeline\n</code></pre> <pre><code>$ pipeline show-summary --name my_pipeline\n\n# Show only configuration information\n</code></pre> <pre><code>$ pipeline show-summary --name my_pipeline --cfg --no-code --no-project\n\n# Generate HTML report\n</code></pre> <pre><code>$ pipeline show-summary --to-html --output-file pipeline_report.html\n</code></pre>"},{"location":"api/cli_pipeline/#flowerpower-add_hook","title":"<code>flowerpower pipeline add_hook</code>","text":"<p>Add a hook to a pipeline configuration.</p> <pre><code>This command adds a hook function to a pipeline's configuration. Hooks are functions\nthat are called at specific points during pipeline execution to perform additional\ntasks like logging, monitoring, or data validation.\n</code></pre>"},{"location":"api/cli_pipeline/#usage_7","title":"Usage","text":"<pre><code>flowerpower pipeline add_hook [options]\n</code></pre>"},{"location":"api/cli_pipeline/#arguments_7","title":"Arguments","text":"Name Type Description Default name str Name of the pipeline to add the hook to Required function_name str Name of the hook function (must be defined in the pipeline module) Required type str Type of hook (determines when the hook is called during execution) Required to str Target node or tag (required for node-specific hooks) Required base_dir str Base directory containing the pipeline Required storage_options str Options for storage backends Required log_level str Set the logging level Required"},{"location":"api/cli_pipeline/#examples_7","title":"Examples","text":"<pre><code>$ pipeline add-hook my_pipeline --function log_results\n\n# Add a pre-run hook\n</code></pre> <pre><code>$ pipeline add-hook my_pipeline --function validate_inputs --type PRE_RUN\n\n# Add a node-specific hook (executed before a specific node runs)\n</code></pre> <pre><code>$ pipeline add-hook my_pipeline --function validate_data --type NODE_PRE_EXECUTE --to data_processor\n\n# Add a hook for all nodes with a specific tag\n</code></pre> <pre><code>$ pipeline add-hook my_pipeline --function log_metrics --type NODE_POST_EXECUTE --to @metrics\n</code></pre>"},{"location":"api/configuration/","title":"Configuration","text":"<p>FlowerPower uses a hierarchical configuration system to manage project and pipeline settings. The main configuration classes are:</p> <ul> <li><code>Config</code></li> <li><code>ProjectConfig</code></li> <li><code>PipelineConfig</code></li> </ul> <p>These classes are designed to be flexible and extensible, allowing you to manage your project's configuration in a clean and organized way.</p>"},{"location":"api/configuration/#classes","title":"Classes","text":""},{"location":"api/configuration/#config","title":"Config","text":"<p>Module: <code>flowerpower.cfg.Config</code></p> <p>The <code>Config</code> class is the main configuration class that combines project and pipeline settings. It serves as the central configuration manager.</p> <p>Attributes:</p> Attribute Type Description <code>pipeline</code> <code>PipelineConfig</code> A <code>PipelineConfig</code> object containing pipeline-specific settings. <code>project</code> <code>ProjectConfig</code> A <code>ProjectConfig</code> object containing project-level settings."},{"location":"api/configuration/#example","title":"Example","text":"<pre><code>from flowerpower.cfg import Config\n\n# Load default configuration\nconfig = Config()\n\n# Access project and pipeline settings\nprint(config.project.name)\nprint(config.pipeline.name)\n</code></pre>"},{"location":"api/configuration/#projectconfig","title":"ProjectConfig","text":"<p>Module: <code>flowerpower.cfg.ProjectConfig</code></p> <p>The <code>ProjectConfig</code> class manages project-level settings, including job queue and adapter configurations.</p> <p>Attributes:</p> Attribute Type Description <code>name</code> <code>str</code> The name of the project. <code>job_queue</code> <code>JobQueueConfig</code> A <code>JobQueueConfig</code> object for the job queue settings. <code>adapter</code> <code>AdapterConfig</code> An <code>AdapterConfig</code> object for the project-level adapter settings."},{"location":"api/configuration/#example_1","title":"Example","text":"<pre><code>from flowerpower.cfg import ProjectConfig\n\n# Load project configuration\nproject_config = ProjectConfig()\n\n# Access project settings\nprint(project_config.name)\nprint(project_config.job_queue.type)\n</code></pre>"},{"location":"api/configuration/#pipelineconfig","title":"PipelineConfig","text":"<p>Module: <code>flowerpower.cfg.PipelineConfig</code></p> <p>The <code>PipelineConfig</code> class manages pipeline-specific settings, including run settings, scheduling, parameters, and adapter configurations.</p> <p>Attributes:</p> Attribute Type Description <code>name</code> <code>str</code> The name of the pipeline. <code>run</code> <code>RunConfig</code> A <code>RunConfig</code> object for pipeline execution settings. <code>schedule</code> <code>ScheduleConfig</code> A <code>ScheduleConfig</code> object for pipeline scheduling. <code>params</code> <code>dict</code> A dictionary of pipeline parameters. <code>adapter</code> <code>AdapterConfig</code> An <code>AdapterConfig</code> object for pipeline-specific adapter settings."},{"location":"api/configuration/#example_2","title":"Example","text":"<pre><code>from flowerpower.cfg import PipelineConfig\n\n# Load pipeline configuration\npipeline_config = PipelineConfig()\n\n# Access pipeline settings\nprint(pipeline_config.name)\nprint(pipeline_config.run.executor)\n</code></pre>"},{"location":"api/configuration/#executorconfig","title":"ExecutorConfig","text":"<p>Module: <code>flowerpower.cfg.ExecutorConfig</code></p> <p>Defines the configuration for the pipeline executor (e.g., \"local\", \"threadpool\").</p> <p>Attributes:</p> Attribute Type Description <code>type</code> <code>str</code> The type of executor (e.g., \"local\", \"threadpool\"). <code>config</code> <code>dict</code> A dictionary of executor-specific configurations."},{"location":"api/configuration/#example_3","title":"Example","text":"<pre><code>from flowerpower.cfg import ExecutorConfig\n\n# Create an ExecutorConfig\nexecutor_config = ExecutorConfig(type=\"threadpool\", config={\"max_workers\": 4})\nprint(executor_config.type)\n</code></pre>"},{"location":"api/configuration/#withadapterconfig","title":"WithAdapterConfig","text":"<p>Module: <code>flowerpower.cfg.WithAdapterConfig</code></p> <p>Defines settings for using adapters during pipeline execution.</p> <p>Attributes:</p> Attribute Type Description <code>adapter_name</code> <code>str</code> The name of the adapter. <code>enabled</code> <code>bool</code> Whether the adapter is enabled. <code>config</code> <code>dict</code> Adapter-specific configurations."},{"location":"api/configuration/#example_4","title":"Example","text":"<pre><code>from flowerpower.cfg import WithAdapterConfig\n\n# Create a WithAdapterConfig\nadapter_config = WithAdapterConfig(adapter_name=\"opentelemetry\", enabled=True)\nprint(adapter_config.enabled)\n</code></pre>"},{"location":"api/configuration/#adapterconfig","title":"AdapterConfig","text":"<p>Module: <code>flowerpower.cfg.AdapterConfig</code></p> <p>A base class for adapter configurations, used for both project and pipeline-level settings.</p> <p>Attributes:</p> Attribute Type Description <code>type</code> <code>str</code> The type of adapter. <code>config</code> <code>dict</code> A dictionary of adapter-specific configurations."},{"location":"api/configuration/#example_5","title":"Example","text":"<pre><code>from flowerpower.cfg import AdapterConfig\n\n# Create an AdapterConfig\nadapter_config = AdapterConfig(type=\"tracker\", config={\"project_id\": \"abc\"})\nprint(adapter_config.type)\n</code></pre>"},{"location":"api/flowerpower/","title":"FlowerPower","text":"<p>Module: <code>flowerpower.flowerpower</code></p> <p>The <code>FlowerPower</code> class is the main entry point for initializing and interacting with FlowerPower projects. It acts as a factory for <code>FlowerPowerProject</code> instances, allowing users to load existing projects or create new ones.</p>"},{"location":"api/flowerpower/#initialization","title":"Initialization","text":""},{"location":"api/flowerpower/#new","title":"new","text":"<pre><code>__new__(cls, name: str | None = None, base_dir: str | None = None, storage_options: dict | BaseStorageOptions | None = {}, fs: AbstractFileSystem | None = None, job_queue_type: str = settings.JOB_QUEUE_TYPE, hooks_dir: str = settings.HOOKS_DIR) -&gt; FlowerPowerProject\n...\n</code></pre> <p>This method is called when you instantiate <code>FlowerPower()</code>. It checks if a project already exists at the specified <code>base_dir</code> and either loads it or initializes a new one.</p> Parameter Type Description Default <code>name</code> <code>str \\| None</code> The name of the project. If <code>None</code>, it defaults to the current directory name. <code>None</code> <code>base_dir</code> <code>str \\| None</code> The base directory where the project will be created or loaded. If <code>None</code>, it defaults to the current working directory. <code>None</code> <code>storage_options</code> <code>dict \\| BaseStorageOptions \\| None</code> Storage options for the filesystem. <code>{}</code> <code>fs</code> <code>AbstractFileSystem \\| None</code> An fsspec-compatible filesystem instance to use for file operations. <code>None</code> <code>job_queue_type</code> <code>str</code> The type of job queue to use for the project (e.g., \"rq\"). <code>settings.JOB_QUEUE_TYPE</code> <code>hooks_dir</code> <code>str</code> The directory where the project hooks will be stored. <code>settings.HOOKS_DIR</code> <p>Returns: <code>FlowerPowerProject</code> - An instance of <code>FlowerPowerProject</code> initialized with the new or loaded project.</p>"},{"location":"api/flowerpower/#example","title":"Example","text":"<pre><code>from flowerpower import FlowerPower\n\n# Initialize or load a project in the current directory\nproject = FlowerPower()\n\n# Initialize or load a project with a specific name and job queue type\nproject = FlowerPower(name=\"my-data-project\", job_queue_type=\"rq\")\n</code></pre>"},{"location":"api/flowerpower/#flowerpowerproject","title":"FlowerPowerProject","text":"<p>Module: <code>flowerpower.flowerpower</code></p> <p>The <code>FlowerPowerProject</code> class represents an initialized FlowerPower project, providing an interface to manage pipelines, job queues, and project-level settings.</p>"},{"location":"api/flowerpower/#initialization_1","title":"Initialization","text":""},{"location":"api/flowerpower/#init","title":"init","text":"<pre><code>__init__(self, pipeline_manager: PipelineManager, job_queue_manager: JobQueueManager | None = None)\n...\n</code></pre> <p>Initializes a <code>FlowerPowerProject</code> instance. This constructor is typically called internally by <code>FlowerPowerProject.load()</code> or <code>FlowerPowerProject.init()</code>.</p> Parameter Type Description <code>pipeline_manager</code> <code>PipelineManager</code> An instance of <code>PipelineManager</code> to manage pipelines within this project. <code>job_queue_manager</code> <code>JobQueueManager \\| None</code> An optional instance of <code>JobQueueManager</code> to handle job queue operations."},{"location":"api/flowerpower/#attributes","title":"Attributes","text":"Attribute Type Description <code>pipeline_manager</code> <code>PipelineManager</code> Manages pipelines within the project. <code>job_queue_manager</code> <code>JobQueueManager \\| None</code> Manages job queue operations, if configured. <code>name</code> <code>str</code> The name of the current project. <code>_base_dir</code> <code>str</code> The base directory of the project. <code>_fs</code> <code>AbstractFileSystem</code> The fsspec-compatible filesystem instance used by the project. <code>_storage_options</code> <code>dict \\| Munch \\| BaseStorageOptions</code> Storage options for the filesystem. <code>job_queue_type</code> <code>str \\| None</code> The type of job queue configured for the project (e.g., \"rq\"). <code>job_queue_backend</code> <code>Any \\| None</code> The backend instance for the job queue, if configured."},{"location":"api/flowerpower/#methods","title":"Methods","text":""},{"location":"api/flowerpower/#run","title":"run","text":"<pre><code>run(self, name: str, inputs: dict | None = None, final_vars: list[str] | None = None, config: dict | None = None, cache: dict | None = None, executor_cfg: str | dict | ExecutorConfig | None = None, with_adapter_cfg: dict | WithAdapterConfig | None = None, pipeline_adapter_cfg: dict | PipelineAdapterConfig | None = None, project_adapter_cfg: dict | ProjectAdapterConfig | None = None, adapter: dict[str, Any] | None = None, reload: bool = False, log_level: str | None = None, max_retries: int | None = None, retry_delay: float | None = None, jitter_factor: float | None = None, retry_exceptions: tuple | list | None = None, on_success: Callable | tuple[Callable, tuple | None, dict | None] | None = None, on_failure: Callable | tuple[Callable, tuple | None, dict | None] | None = None) -&gt; dict[str, Any]\n...\n</code></pre> <p>Execute a pipeline synchronously and return its results.</p> <p>This is a convenience method that delegates to the pipeline manager. It provides the same functionality as <code>self.pipeline_manager.run()</code>.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to run. Must be a valid identifier. <code>inputs</code> <code>dict \\| None</code> Override pipeline input values. Example: <code>{\"data_date\": \"2025-04-28\"}</code> <code>None</code> <code>final_vars</code> <code>list[str] \\| None</code> Specify which output variables to return. Example: <code>[\"model\", \"metrics\"]</code> <code>None</code> <code>config</code> <code>dict \\| None</code> Configuration for Hamilton pipeline executor. Example: <code>{\"model\": \"LogisticRegression\"}</code> <code>None</code> <code>cache</code> <code>dict \\| None</code> Cache configuration for results. Example: <code>{\"recompute\": [\"node1\", \"final_node\"]}</code> <code>None</code> <code>executor_cfg</code> <code>str \\| dict \\| ExecutorConfig \\| None</code> Execution configuration, can be: - <code>str</code>: Executor name, e.g. \"threadpool\", \"local\" - <code>dict</code>: Raw config, e.g. <code>{\"type\": \"threadpool\", \"max_workers\": 4}</code> - <code>ExecutorConfig</code>: Structured config object <code>None</code> <code>with_adapter_cfg</code> <code>dict \\| WithAdapterConfig \\| None</code> Adapter settings for pipeline execution. Example: <code>{\"opentelemetry\": True, \"tracker\": False}</code> <code>None</code> <code>pipeline_adapter_cfg</code> <code>dict \\| PipelineAdapterConfig \\| None</code> Pipeline-specific adapter settings. Example: <code>{\"tracker\": {\"project_id\": \"123\", \"tags\": {\"env\": \"prod\"}}}</code> <code>None</code> <code>project_adapter_cfg</code> <code>dict \\| ProjectAdapterConfig \\| None</code> Project-level adapter settings. Example: <code>{\"opentelemetry\": {\"host\": \"http://localhost:4317\"}}</code> <code>None</code> <code>adapter</code> <code>dict[str, Any] \\| None</code> Custom adapter instance for pipeline Example: <code>{\"ray_graph_adapter\": RayGraphAdapter()}</code> <code>None</code> <code>reload</code> <code>bool</code> Force reload of pipeline configuration. <code>False</code> <code>log_level</code> <code>str \\| None</code> Logging level for the execution. Valid values: \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\" <code>None</code> <code>max_retries</code> <code>int \\| None</code> Maximum number of retries for execution. <code>None</code> <code>retry_delay</code> <code>float \\| None</code> Delay between retries in seconds. <code>None</code> <code>jitter_factor</code> <code>float \\| None</code> Random jitter factor to add to retry delay <code>None</code> <code>retry_exceptions</code> <code>tuple \\| list \\| None</code> Exceptions that trigger a retry. <code>None</code> <code>on_success</code> <code>Callable \\| tuple[Callable, tuple | None, dict | None] \\| None</code> Callback to run on successful pipeline execution. <code>None</code> <code>on_failure</code> <code>Callable \\| tuple[Callable, tuple | None, dict | None] \\| None</code> Callback to run on pipeline execution failure. <code>None</code> <p>Returns: <code>dict[str, Any]</code> - Pipeline execution results, mapping output variable names to their computed values.</p> <p>Raises: - <code>ValueError</code>: If pipeline name doesn't exist or configuration is invalid. - <code>ImportError</code>: If pipeline module cannot be imported. - <code>RuntimeError</code>: If execution fails due to pipeline or adapter errors.</p>"},{"location":"api/flowerpower/#example_1","title":"Example","text":"<pre><code>from flowerpower import FlowerPowerProject\n\nproject = FlowerPowerProject.load(\".\")\n\n# Simple execution\nresult = project.run(\"my_pipeline\")\n\n# With custom inputs\nresult = project.run(\n    \"ml_pipeline\",\n    inputs={\"data_date\": \"2025-01-01\"},\n    final_vars=[\"model\", \"metrics\"]\n)\n</code></pre>"},{"location":"api/flowerpower/#enqueue","title":"enqueue","text":"<pre><code>enqueue(self, name: str, *args, **kwargs)\n...\n</code></pre> <p>Enqueue a pipeline for execution via the job queue.</p> <p>This is a convenience method that delegates to the job queue manager's <code>enqueue_pipeline</code> method. It provides asynchronous pipeline execution.</p> Parameter Type Description <code>name</code> <code>str</code> Name of the pipeline to enqueue. <code>*args</code> <code>Any</code> Additional positional arguments for job execution. <code>**kwargs</code> <code>Any</code> Keyword arguments for pipeline execution and job queue options. Supports all parameters from <code>pipeline_manager.run()</code> plus job queue specific options: - <code>run_in</code>: Schedule the job to run after a delay - <code>run_at</code>: Schedule the job to run at a specific datetime - <code>queue_name</code>: Queue to use (for RQ) - <code>timeout</code>: Job execution timeout - <code>retry</code>: Number of retries - <code>result_ttl</code>: Result time to live - <code>ttl</code>: Job time to live <p>Returns: <code>Job</code> - Job ID or result depending on implementation, or <code>None</code> if job queue not configured.</p> <p>Raises: <code>RuntimeError</code>: If job queue manager is not configured.</p>"},{"location":"api/flowerpower/#example_2","title":"Example","text":"<pre><code>from flowerpower import FlowerPowerProject\nfrom datetime import datetime\n\nproject = FlowerPowerProject.load(\".\")\n\n# Immediate execution via job queue\njob_id = project.enqueue(\"my_pipeline\", inputs={\"date\": \"today\"})\n\n# Delayed execution\njob_id = project.enqueue(\"my_pipeline\", inputs={\"date\": \"today\"}, run_in=300)\n\n# Scheduled execution\njob_id = project.enqueue(\n    \"my_pipeline\",\n    inputs={\"date\": \"today\"},\n    run_at=datetime(2025, 1, 1, 9, 0)\n)\n</code></pre>"},{"location":"api/flowerpower/#schedule","title":"schedule","text":"<pre><code>schedule(self, name: str, *args, **kwargs)\n...\n</code></pre> <p>Schedule a pipeline for recurring or future execution.</p> <p>This is a convenience method that delegates to the job queue manager's <code>schedule_pipeline</code> method. It provides scheduled pipeline execution.</p> Parameter Type Description <code>name</code> <code>str</code> Name of the pipeline to schedule. <code>*args</code> <code>Any</code> Additional positional arguments for scheduling. <code>**kwargs</code> <code>Any</code> Keyword arguments for pipeline execution and scheduling options. Supports all parameters from <code>pipeline_manager.run()</code> plus scheduling options: - <code>cron</code>: Cron expression for recurring execution (e.g., \"0 9 * * *\") - <code>interval</code>: Time interval for recurring execution (int seconds or dict) - <code>date</code>: Future date for one-time execution (datetime or ISO string) - <code>schedule_id</code>: Unique identifier for the schedule - <code>overwrite</code>: Whether to overwrite existing schedule with same ID <p>Returns: <code>ScheduledJob</code> - Schedule ID or job ID depending on implementation, or <code>None</code> if job queue not configured.</p> <p>Raises: <code>RuntimeError</code>: If job queue manager is not configured.</p>"},{"location":"api/flowerpower/#example_3","title":"Example","text":"<pre><code>from flowerpower import FlowerPowerProject\nfrom datetime import datetime, timedelta\n\nproject = FlowerPowerProject.load(\".\")\n\n# Daily schedule with cron\nschedule_id = project.schedule(\n    \"daily_metrics\",\n    cron=\"0 9 * * *\",  # 9 AM daily\n    inputs={\"date\": \"{{ execution_date }}\"}\n)\n\n# Interval-based schedule\nschedule_id = project.schedule(\n    \"monitoring\",\n    interval={\"minutes\": 15},\n    inputs={\"check_type\": \"health\"}\n)\n\n# Future one-time execution\nfuture_date = datetime.now() + timedelta(days=1)\nschedule_id = project.schedule(\n    \"batch_process\",\n    date=future_date,\n    inputs={\"process_date\": \"tomorrow\"}\n)\n</code></pre>"},{"location":"api/flowerpower/#start_worker","title":"start_worker","text":"<pre><code>start_worker(self, background: bool = False, queue_names: list[str] | None = None, with_scheduler: bool = True, **kwargs: Any) -&gt; None\n...\n</code></pre> <p>Start a worker process for processing jobs from the queues.</p> <p>This is a convenience method that delegates to the job queue manager's <code>start_worker</code> method.</p> Parameter Type Description Default <code>background</code> <code>bool</code> If <code>True</code>, runs the worker in a non-blocking background mode. If <code>False</code>, runs in the current process and blocks until stopped. <code>False</code> <code>queue_names</code> <code>list[str] \\| None</code> List of queue names to process. If <code>None</code>, processes all queues defined in the backend configuration. <code>None</code> <code>with_scheduler</code> <code>bool</code> Whether to include the scheduler queue for processing scheduled jobs (if supported by the backend). <code>True</code> <code>**kwargs</code> <code>Any</code> Additional worker configuration options specific to the job queue backend. <p>Raises: <code>RuntimeError</code>: If job queue manager is not configured.</p>"},{"location":"api/flowerpower/#example_4","title":"Example","text":"<pre><code>from flowerpower import FlowerPowerProject\n\nproject = FlowerPowerProject.load(\".\")\n\n# Start worker in foreground (blocks)\nproject.start_worker()\n\n# Start worker in background\nproject.start_worker(background=True)\n\n# Start worker for specific queues\nproject.start_worker(queue_names=[\"high_priority\", \"default\"])\n</code></pre>"},{"location":"api/flowerpower/#stop_worker","title":"stop_worker","text":"<pre><code>stop_worker(self) -&gt; None\n...\n</code></pre> <p>Stop the worker process.</p> <p>This is a convenience method that delegates to the job queue manager's <code>stop_worker</code> method.</p> <p>Raises: <code>RuntimeError</code>: If job queue manager is not configured.</p>"},{"location":"api/flowerpower/#example_5","title":"Example","text":"<pre><code>from flowerpower import FlowerPowerProject\n\nproject = FlowerPowerProject.load(\".\")\nproject.stop_worker()\n</code></pre>"},{"location":"api/flowerpower/#start_worker_pool","title":"start_worker_pool","text":"<pre><code>start_worker_pool(self, num_workers: int | None = None, background: bool = False, queue_names: list[str] | None = None, with_scheduler: bool = True, **kwargs: Any) -&gt; None\n...\n</code></pre> <p>Start a pool of worker processes to handle jobs in parallel.</p> <p>This is a convenience method that delegates to the job queue manager's <code>start_worker_pool</code> method.</p> Parameter Type Description Default <code>num_workers</code> <code>int \\| None</code> Number of worker processes to start. If <code>None</code>, uses CPU count or backend-specific default. <code>None</code> <code>background</code> <code>bool</code> If <code>True</code>, runs the worker pool in a non-blocking background mode. If <code>False</code>, runs in the current process and blocks until stopped. <code>False</code> <code>queue_names</code> <code>list[str] \\| None</code> List of queue names to process. If <code>None</code>, processes all queues defined in the backend configuration. <code>None</code> <code>with_scheduler</code> <code>bool</code> Whether to include the scheduler queue for processing scheduled jobs (if supported by the backend). <code>True</code> <code>**kwargs</code> <code>Any</code> Additional worker pool configuration options specific to the job queue backend. <p>Raises: <code>RuntimeError</code>: If job queue manager is not configured.</p>"},{"location":"api/flowerpower/#example_6","title":"Example","text":"<pre><code>from flowerpower import FlowerPowerProject\n\nproject = FlowerPowerProject.load(\".\")\n\n# Start worker pool with default number of workers\nproject.start_worker_pool()\n\n# Start 4 workers in background\nproject.start_worker_pool(num_workers=4, background=True)\n\n# Start worker pool for specific queues\nproject.start_worker_pool(\n    num_workers=2,\n    queue_names=[\"high_priority\", \"default\"]\n)\n</code></pre>"},{"location":"api/flowerpower/#stop_worker_pool","title":"stop_worker_pool","text":"<pre><code>stop_worker_pool(self) -&gt; None\n...\n</code></pre> <p>Stop all worker processes in the worker pool.</p> <p>This is a convenience method that delegates to the job queue manager's <code>stop_worker_pool</code> method.</p> <p>Raises: <code>RuntimeError</code>: If job queue manager is not configured.</p>"},{"location":"api/flowerpower/#example_7","title":"Example","text":"<pre><code>from flowerpower import FlowerPowerProject\n\nproject = FlowerPowerProject.load(\".\")\nproject.stop_worker_pool()\n</code></pre>"},{"location":"api/flowerpower/#load","title":"load","text":"<pre><code>load(cls, base_dir: str | None = None, storage_options: dict | BaseStorageOptions | None = {}, fs: AbstractFileSystem | None = None, log_level: str | None = None) -&gt; \"FlowerPowerProject\"\n...\n</code></pre> <p>Load an existing FlowerPower project.</p> <p>If the project does not exist, it will raise an error.</p> Parameter Type Description Default <code>base_dir</code> <code>str \\| None</code> The base directory of the project. If <code>None</code>, it defaults to the current working directory. <code>None</code> <code>storage_options</code> <code>dict \\| BaseStorageOptions \\| None</code> Storage options for the filesystem. <code>{}</code> <code>fs</code> <code>AbstractFileSystem \\| None</code> An instance of <code>AbstractFileSystem</code> to use for file operations. <code>None</code> <code>log_level</code> <code>str \\| None</code> The logging level to set for the project. If <code>None</code>, it uses the default log level. <code>None</code> <p>Returns: <code>FlowerPowerProject</code> - An instance of <code>FlowerPowerProject</code> if the project exists, otherwise <code>None</code>.</p> <p>Raises: <code>FileNotFoundError</code>: If the project does not exist at the specified base directory.</p>"},{"location":"api/flowerpower/#example_8","title":"Example","text":"<pre><code>from flowerpower import FlowerPowerProject\n\n# Load a project from the current directory\nproject = FlowerPowerProject.load(\".\")\n\n# Load a project from a specific path\nproject = FlowerPowerProject.load(\"/path/to/my/project\")\n</code></pre>"},{"location":"api/flowerpower/#init_1","title":"init","text":"<pre><code>init(cls, name: str | None = None, base_dir: str | None = None, storage_options: dict | BaseStorageOptions | None = {}, fs: AbstractFileSystem | None = None, job_queue_type: str = settings.JOB_QUEUE_TYPE, hooks_dir: str = settings.HOOKS_DIR, log_level: str | None = None) -&gt; \"FlowerPowerProject\"\n...\n</code></pre> <p>Initialize a new FlowerPower project.</p> Parameter Type Description Default <code>name</code> <code>str \\| None</code> The name of the project. If <code>None</code>, it defaults to the current directory name. <code>None</code> <code>base_dir</code> <code>str \\| None</code> The base directory where the project will be created. If <code>None</code>, it defaults to the current working directory. <code>None</code> <code>storage_options</code> <code>dict \\| BaseStorageOptions \\| None</code> Storage options for the filesystem. <code>{}</code> <code>fs</code> <code>AbstractFileSystem \\| None</code> An instance of <code>AbstractFileSystem</code> to use for file operations. <code>None</code> <code>job_queue_type</code> <code>str</code> The type of job queue to use for the project. <code>settings.JOB_QUEUE_TYPE</code> <code>hooks_dir</code> <code>str</code> The directory where the project hooks will be stored. <code>settings.HOOKS_DIR</code> <code>log_level</code> <code>str \\| None</code> The logging level to set for the project. If <code>None</code>, it uses the default log level. <code>None</code> <p>Returns: <code>FlowerPowerProject</code> - An instance of <code>FlowerPowerProject</code> initialized with the new project.</p> <p>Raises: <code>FileExistsError</code>: If the project already exists at the specified base directory.</p>"},{"location":"api/flowerpower/#example_9","title":"Example","text":"<p>```python from flowerpower import FlowerPowerProject</p>"},{"location":"api/flowerpower/#initialize-a-new-project-in-the-current-directory","title":"Initialize a new project in the current directory","text":"<p>project = FlowerPowerProject.init()</p>"},{"location":"api/flowerpower/#initialize-a-new-project-with-a-specific-name-and-job-queue-type","title":"Initialize a new project with a specific name and job queue type","text":"<p>project = FlowerPowerProject.init(name=\"my-new-project\", job_queue_type=\"rq\")</p>"},{"location":"api/init/","title":"init","text":"<p>Module: <code>flowerpower.init</code></p> <p>The <code>init</code> function is a top-level function that initializes a new FlowerPower project. It is a convenient alias for <code>FlowerPowerProject.init()</code>.</p> <pre><code>init(name: str | None = None, base_dir: str | None = None, storage_options: dict | BaseStorageOptions | None = None, fs: AbstractFileSystem | None = None, job_queue_type: str = settings.JOB_QUEUE_TYPE, hooks_dir: str = settings.HOOKS_DIR)\n</code></pre> <p>Initializes a new FlowerPower project.</p> Parameter Type Description <code>name</code> <code>str</code> | <code>None</code> The name of the project. Defaults to the current directory name. <code>base_dir</code> <code>str</code> | <code>None</code> The base directory for the project. Defaults to the current working directory. <code>storage_options</code> <code>dict</code> | <code>BaseStorageOptions</code> | <code>None</code> Storage options for the filesystem. <code>fs</code> <code>AbstractFileSystem</code> | <code>None</code> An fsspec-compatible filesystem instance. <code>job_queue_type</code> <code>str</code> The type of job queue to use (e.g., \"rq\"). <code>hooks_dir</code> <code>str</code> The directory for project hooks. <p>Returns: A <code>FlowerPowerProject</code> instance.</p> <p>Raises: <code>FileExistsError</code> if the project already exists.</p>"},{"location":"api/init/#example","title":"Example","text":"<p>```python from flowerpower import init</p>"},{"location":"api/init/#initialize-a-new-project","title":"Initialize a new project","text":"<p>project = init(name=\"my-new-project\", job_queue_type=\"rq\")</p>"},{"location":"api/jobqueuemanager/","title":"JobQueueManager","text":"<p>Module: <code>flowerpower.job_queue.JobQueueManager</code></p> <p>The <code>JobQueueManager</code> is an abstract base class that defines the interface for job queue operations in FlowerPower. It is responsible for enqueuing, scheduling, and managing jobs.</p>"},{"location":"api/jobqueuemanager/#initialization","title":"Initialization","text":""},{"location":"api/jobqueuemanager/#init","title":"init","text":"<pre><code>__init__(self, type: str | None = None, name: str | None = None, base_dir: str | None = None, backend: BaseBackend | None = None, storage_options: dict | None = None, fs: AbstractFileSystem | None = None, **kwargs)\n</code></pre> <p>Initializes the <code>JobQueueManager</code>.</p> Parameter Type Description Default <code>type</code> <code>str \\| None</code> The type of job queue backend (e.g., \"rq\"). <code>None</code> <code>name</code> <code>str \\| None</code> The name of the scheduler. <code>None</code> <code>base_dir</code> <code>str \\| None</code> The base directory of the project. <code>None</code> <code>backend</code> <code>BaseBackend \\| None</code> A backend instance. <code>None</code> <code>storage_options</code> <code>dict \\| None</code> Storage options for the filesystem. <code>None</code> <code>fs</code> <code>AbstractFileSystem \\| None</code> An fsspec-compatible filesystem instance. <code>None</code>"},{"location":"api/jobqueuemanager/#attributes","title":"Attributes","text":"Attribute Type Description <code>is_worker_running</code> <code>bool</code> Indicates if a worker is currently running. <code>is_scheduler_running</code> <code>bool</code> Indicates if the scheduler is currently running."},{"location":"api/jobqueuemanager/#methods","title":"Methods","text":""},{"location":"api/jobqueuemanager/#enqueue_pipeline","title":"enqueue_pipeline","text":"<pre><code>enqueue_pipeline(self, name: str, *args, **kwargs)\n</code></pre> <p>Enqueues a pipeline for immediate execution.</p> Parameter Type Description <code>name</code> <code>str</code> The name of the pipeline. <code>*args</code> <code>Any</code> Positional arguments for the job. <code>**kwargs</code> <code>Any</code> Keyword arguments for the job. <p>Returns: <code>Job</code> - The enqueued job object.</p> <p>Raises: <code>ValueError</code>: If the pipeline name is invalid.</p>"},{"location":"api/jobqueuemanager/#example","title":"Example","text":"<pre><code>from flowerpower.job_queue import JobQueueManager\n\n# Assuming manager is an instance of a concrete JobQueueManager subclass\njob = manager.enqueue_pipeline(\"my_data_pipeline\", data_path=\"/data/new.csv\")\nprint(f\"Enqueued job: {job.id}\")\n</code></pre>"},{"location":"api/jobqueuemanager/#schedule_pipeline","title":"schedule_pipeline","text":"<pre><code>schedule_pipeline(self, name: str, *args, **kwargs)\n</code></pre> <p>Schedules a pipeline for future or recurring execution.</p> Parameter Type Description <code>name</code> <code>str</code> The name of the pipeline. <code>*args</code> <code>Any</code> Positional arguments for the job. <code>**kwargs</code> <code>Any</code> Keyword arguments for the job (e.g., <code>cron_string</code>, <code>interval</code>). <p>Returns: <code>ScheduledJob</code> - The scheduled job object.</p> <p>Raises: <code>ValueError</code>: If the pipeline name is invalid or scheduling parameters are insufficient.</p>"},{"location":"api/jobqueuemanager/#example_1","title":"Example","text":"<pre><code>from flowerpower.job_queue import JobQueueManager\n\n# Schedule a pipeline to run every day at midnight\nscheduled_job = manager.schedule_pipeline(\n    \"daily_report_pipeline\",\n    cron_string=\"0 0 * * *\"\n)\nprint(f\"Scheduled job: {scheduled_job.id}\")\n</code></pre>"},{"location":"api/jobqueuemanager/#start_worker","title":"start_worker","text":"<pre><code>start_worker(self, queue_name: str | list[str] | None = None, **kwargs)\n</code></pre> <p>Starts a worker process to process jobs from the queue.</p> Parameter Type Description <code>queue_name</code> <code>str \\| list[str] \\| None</code> The name(s) of the queue(s) to listen to. Defaults to all queues. <code>**kwargs</code> <code>Any</code> Additional keyword arguments for the worker. <p>Returns: <code>None</code></p> <p>Raises: <code>RuntimeError</code>: If the worker fails to start.</p>"},{"location":"api/jobqueuemanager/#example_2","title":"Example","text":"<pre><code>from flowerpower.job_queue import JobQueueManager\n\n# Start a worker for a specific queue\nmanager.start_worker(\"high_priority_queue\")\n\n# Start a worker for multiple queues\nmanager.start_worker([\"default\", \"low_priority\"])\n</code></pre>"},{"location":"api/jobqueuemanager/#stop_worker","title":"stop_worker","text":"<pre><code>stop_worker(self)\n</code></pre> <p>Stops the currently running worker process.</p> <p>Returns: <code>None</code></p> <p>Raises: <code>RuntimeError</code>: If stopping the worker fails.</p>"},{"location":"api/jobqueuemanager/#example_3","title":"Example","text":"<pre><code>from flowerpower.job_queue import JobQueueManager\n\nmanager.stop_worker()\n</code></pre>"},{"location":"api/jobqueuemanager/#start_worker_pool","title":"start_worker_pool","text":"<pre><code>start_worker_pool(self, num_workers: int = 1, queue_name: str | list[str] | None = None, **kwargs)\n</code></pre> <p>Starts a pool of worker processes.</p> Parameter Type Description <code>num_workers</code> <code>int</code> The number of worker processes to start. <code>queue_name</code> <code>str \\| list[str] \\| None</code> The name(s) of the queue(s) for the workers to listen to. Defaults to all queues. <code>**kwargs</code> <code>Any</code> Additional keyword arguments for the worker processes. <p>Returns: <code>None</code></p> <p>Raises: <code>RuntimeError</code>: If the worker pool fails to start.</p>"},{"location":"api/jobqueuemanager/#example_4","title":"Example","text":"<pre><code>from flowerpower.job_queue import JobQueueManager\n\n# Start a pool of 4 workers\nmanager.start_worker_pool(num_workers=4)\n</code></pre>"},{"location":"api/jobqueuemanager/#stop_worker_pool","title":"stop_worker_pool","text":"<pre><code>stop_worker_pool(self)\n</code></pre> <p>Stops all worker processes in the pool.</p> <p>Returns: <code>None</code></p> <p>Raises: <code>RuntimeError</code>: If stopping the worker pool fails.</p>"},{"location":"api/jobqueuemanager/#example_5","title":"Example","text":"<pre><code>from flowerpower.job_queue import JobQueueManager\n\nmanager.stop_worker_pool()\n</code></pre>"},{"location":"api/jobqueuemanager/#enqueue","title":"enqueue","text":"<pre><code>enqueue(self, func: Callable, *args, **kwargs)\n</code></pre> <p>Enqueues a job for immediate, delayed, or scheduled execution.</p> Parameter Type Description <code>func</code> <code>Callable</code> The function to execute. <code>*args</code> <code>Any</code> Positional arguments for the function. <code>**kwargs</code> <code>Any</code> Keyword arguments for the function and job (e.g., <code>job_id</code>, <code>timeout</code>). <p>Returns: <code>Job</code> - The enqueued job object.</p> <p>Raises: <code>ValueError</code>: If <code>func</code> is not callable.</p>"},{"location":"api/jobqueuemanager/#example_6","title":"Example","text":"<pre><code>from flowerpower.job_queue import JobQueueManager\n\ndef my_task(x, y):\n    return x + y\n\njob = manager.enqueue(my_task, 1, 2, job_id=\"my_sum_job\")\nprint(f\"Enqueued job: {job.id}\")\n</code></pre>"},{"location":"api/jobqueuemanager/#enqueue_in","title":"enqueue_in","text":"<pre><code>enqueue_in(self, delay: timedelta | int | str, func: Callable, *args, **kwargs)\n</code></pre> <p>Enqueues a job to run after a specified delay.</p> Parameter Type Description <code>delay</code> <code>timedelta | int | str</code> The delay before execution. Can be a <code>timedelta</code> object, an integer (seconds), or a string (e.g., \"1m\" for 1 minute). <code>func</code> <code>Callable</code> The function to execute. <code>*args</code> <code>Any</code> Positional arguments for the function. <code>**kwargs</code> <code>Any</code> Keyword arguments for the function and job. <p>Returns: <code>Job</code> - The enqueued job object.</p> <p>Raises: <code>ValueError</code>: If <code>delay</code> is invalid or <code>func</code> is not callable.</p>"},{"location":"api/jobqueuemanager/#example_7","title":"Example","text":"<pre><code>from flowerpower.job_queue import JobQueueManager\nfrom datetime import timedelta\n\ndef send_notification(message):\n    print(f\"Notification: {message}\")\n\n# Enqueue a job to run in 5 minutes\njob = manager.enqueue_in(timedelta(minutes=5), send_notification, \"Your report is ready!\")\n\n# Enqueue a job to run in 30 seconds (integer delay)\njob = manager.enqueue_in(30, send_notification, \"Quick update!\")\n\n# Enqueue a job to run in 1 hour (string delay)\njob = manager.enqueue_in(\"1h\", send_notification, \"Hourly reminder!\")\n</code></pre>"},{"location":"api/jobqueuemanager/#enqueue_at","title":"enqueue_at","text":"<pre><code>enqueue_at(self, datetime_obj: datetime, func: Callable, *args, **kwargs)\n</code></pre> <p>Enqueues a job to run at a specific datetime.</p> Parameter Type Description <code>datetime_obj</code> <code>datetime</code> The datetime to execute the job. <code>func</code> <code>Callable</code> The function to execute. <code>*args</code> <code>Any</code> Positional arguments for the function. <code>**kwargs</code> <code>Any</code> Keyword arguments for the function and job. <p>Returns: <code>Job</code> - The enqueued job object.</p> <p>Raises: <code>ValueError</code>: If <code>datetime_obj</code> is in the past or <code>func</code> is not callable.</p>"},{"location":"api/jobqueuemanager/#example_8","title":"Example","text":"<pre><code>from flowerpower.job_queue import JobQueueManager\nfrom datetime import datetime\n\ndef generate_monthly_report(month, year):\n    print(f\"Generating report for {month}/{year}\")\n\n# Enqueue a job to run at a specific future date and time\ntarget_time = datetime(2025, 1, 1, 9, 0, 0)\njob = manager.enqueue_at(target_time, generate_monthly_report, 1, 2025)\n</code></pre>"},{"location":"api/jobqueuemanager/#add_schedule","title":"add_schedule","text":"<pre><code>add_schedule(self, id: str, func: Callable, cron_string: str | None = None, interval: int | None = None, repeat: int | None = None, enabled: bool = True, **kwargs)\n</code></pre> <p>Schedules a job for repeated or one-time execution.</p> Parameter Type Description <code>id</code> <code>str</code> A unique identifier for the scheduled job. <code>func</code> <code>Callable</code> The function to execute. <code>cron_string</code> <code>str | None</code> A cron string for recurring schedules (e.g., \"0 0 * * *\" for daily at midnight). <code>interval</code> <code>int | None</code> Interval in seconds for recurring schedules. <code>repeat</code> <code>int | None</code> Number of times to repeat the job. <code>None</code> for infinite. <code>enabled</code> <code>bool</code> Whether the schedule is active. <code>**kwargs</code> <code>Any</code> Additional keyword arguments for the function and job. <p>Returns: <code>ScheduledJob</code> - The scheduled job object.</p> <p>Raises: <code>ValueError</code>: If scheduling parameters are invalid or insufficient.</p>"},{"location":"api/jobqueuemanager/#example_9","title":"Example","text":"<pre><code>from flowerpower.job_queue import JobQueueManager\n\ndef clean_temp_files():\n    print(\"Cleaning temporary files...\")\n\n# Schedule a job to clean temp files every hour\nscheduled_job = manager.add_schedule(\n    id=\"hourly_cleanup\",\n    func=clean_temp_files,\n    interval=3600 # Every hour\n)\n\n# Schedule a job using a cron string (every Monday at 9 AM)\nscheduled_job = manager.add_schedule(\n    id=\"weekly_summary\",\n    func=lambda: print(\"Generating weekly summary...\"),\n    cron_string=\"0 9 * * MON\"\n)\n</code></pre>"},{"location":"api/jobqueuemanager/#get_job_result","title":"get_job_result","text":"<pre><code>get_job_result(self, job: str | Job, delete_result: bool = False)\n</code></pre> <p>Gets the result of a completed job.</p> Parameter Type Description <code>job</code> <code>str | Job</code> The job ID or <code>Job</code> object. <code>delete_result</code> <code>bool</code> If <code>True</code>, deletes the result after retrieval. <p>Returns: <code>Any</code> - The result of the job execution.</p> <p>Raises: - <code>JobNotFinishedError</code>: If the job has not completed yet. - <code>JobDoesNotExistError</code>: If the job ID is not found.</p>"},{"location":"api/jobqueuemanager/#example_10","title":"Example","text":"<pre><code>from flowerpower.job_queue import JobQueueManager\n\n# Assuming 'my_job_id' is the ID of a completed job\nresult = manager.get_job_result(\"my_job_id\")\nprint(f\"Job result: {result}\")\n</code></pre>"},{"location":"api/jobqueuemanager/#get_jobs","title":"get_jobs","text":"<pre><code>get_jobs(self, queue_name: str | list[str] | None = None)\n</code></pre> <p>Gets all jobs from specified queues.</p> Parameter Type Description <code>queue_name</code> <code>str | list[str] | None</code> The name of the queue(s). Defaults to all queues. <p>Returns: <code>list[Job]</code> - A list of job objects.</p>"},{"location":"api/jobqueuemanager/#example_11","title":"Example","text":"<pre><code>from flowerpower.job_queue import JobQueueManager\n\n# Get all jobs from the default queue\nall_jobs = manager.get_jobs(\"default\")\n\n# Get jobs from multiple queues\npriority_jobs = manager.get_jobs([\"high_priority\", \"medium_priority\"])\n</code></pre>"},{"location":"api/jobqueuemanager/#get_schedules","title":"get_schedules","text":"<pre><code>get_schedules(self, id: str | list[str] | None = None)\n</code></pre> <p>Gets all schedules from the scheduler.</p> Parameter Type Description <code>id</code> <code>str | list[str] | None</code> The ID(s) of the schedule(s). Defaults to all schedules. <p>Returns: <code>list[ScheduledJob]</code> - A list of scheduled job objects.</p>"},{"location":"api/jobqueuemanager/#example_12","title":"Example","text":"<pre><code>from flowerpower.job_queue import JobQueueManager\n\n# Get all active schedules\nall_schedules = manager.get_schedules()\n\n# Get a specific schedule\nmy_schedule = manager.get_schedules(id=\"hourly_cleanup\")\n</code></pre>"},{"location":"api/pipelinemanager/","title":"PipelineManager","text":"<p>Module: <code>flowerpower.pipeline.PipelineManager</code></p> <p>The <code>PipelineManager</code> is the central class for managing pipeline operations in FlowerPower. It provides a unified interface for creating, running, and managing pipelines.</p>"},{"location":"api/pipelinemanager/#initialization","title":"Initialization","text":""},{"location":"api/pipelinemanager/#init","title":"init","text":"<pre><code>__init__(self, base_dir: str | None = None, storage_options: dict | Munch | BaseStorageOptions | None = None, fs: AbstractFileSystem | None = None, cfg_dir: str | None = None, pipelines_dir: str | None = None, job_queue_type: str = settings.JOB_QUEUE_TYPE, log_level: str | None = None)\n</code></pre> <p>Initializes the <code>PipelineManager</code>.</p> Parameter Type Description <code>base_dir</code> <code>str \\| None</code> The base directory of the project. Defaults to the current working directory. <code>storage_options</code> <code>dict \\| Munch \\| BaseStorageOptions \\| None</code> Storage options for the filesystem. <code>fs</code> <code>AbstractFileSystem \\| None</code> An fsspec-compatible filesystem instance. <code>cfg_dir</code> <code>str \\| None</code> The directory for configuration files. <code>pipelines_dir</code> <code>str \\| None</code> The directory for pipeline modules. <code>job_queue_type</code> <code>str</code> The type of job queue to use for the project. <code>log_level</code> <code>str \\| None</code> The logging level for the manager. <p>Example:</p> <pre><code>from flowerpower.pipeline import PipelineManager\n\n# Initialize a manager for the project in the current directory\nmanager = PipelineManager()\n</code></pre>"},{"location":"api/pipelinemanager/#methods","title":"Methods","text":""},{"location":"api/pipelinemanager/#attributes","title":"Attributes","text":"Attribute Type Description <code>registry</code> <code>PipelineRegistry</code> Handles pipeline registration and discovery. <code>scheduler</code> <code>PipelineScheduler</code> Manages job scheduling and execution. <code>visualizer</code> <code>PipelineVisualizer</code> Handles pipeline visualization. <code>io</code> <code>PipelineIOManager</code> Manages pipeline import/export operations. <code>project_cfg</code> <code>ProjectConfig</code> Current project configuration. <code>pipeline_cfg</code> <code>PipelineConfig</code> Current pipeline configuration. <code>pipelines</code> <code>list[str]</code> List of available pipeline names. <code>current_pipeline_name</code> <code>str</code> Name of the currently loaded pipeline. <code>summary</code> <code>dict[str, dict \\| str]</code> Summary of all pipelines. <code>_base_dir</code> <code>str</code> The base directory of the project. <code>_fs</code> <code>AbstractFileSystem</code> The filesystem instance used by the manager. <code>_storage_options</code> <code>dict \\| Munch \\| BaseStorageOptions</code> Storage options for the filesystem. <code>_cfg_dir</code> <code>str</code> The directory for configuration files. <code>_pipelines_dir</code> <code>str</code> The directory for pipeline modules. <code>_project_context</code> <code>FlowerPowerProject \\| None</code> Reference to the FlowerPowerProject instance."},{"location":"api/pipelinemanager/#methods_1","title":"Methods","text":""},{"location":"api/pipelinemanager/#run","title":"run","text":"<pre><code>run(self, name: str, inputs: dict | None = None, final_vars: list[str] | None = None, config: dict | None = None, cache: dict | None = None, executor_cfg: str | dict | ExecutorConfig | None = None, with_adapter_cfg: dict | WithAdapterConfig | None = None, pipeline_adapter_cfg: dict | PipelineAdapterConfig | None = None, project_adapter_cfg: dict | ProjectAdapterConfig | None = None, adapter: dict[str, Any] | None = None, reload: bool = False, log_level: str | None = None, max_retries: int | None = None, retry_delay: float | None = None, jitter_factor: float | None = None, retry_exceptions: tuple | list | None = None, on_success: Callable | tuple[Callable, tuple | None, dict | None] | None = None, on_failure: Callable | tuple[Callable, tuple | None, dict | None] | None = None)\n</code></pre> <p>Execute a pipeline synchronously and return its results.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to run. Must be a valid identifier. <code>inputs</code> <code>dict \\| None</code> Override pipeline input values. Example: <code>{\"data_date\": \"2025-04-28\"}</code> <code>None</code> <code>final_vars</code> <code>list[str] \\| None</code> Specify which output variables to return. Example: <code>[\"model\", \"metrics\"]</code> <code>None</code> <code>config</code> <code>dict \\| None</code> Configuration for Hamilton pipeline executor. Example: <code>{\"model\": \"LogisticRegression\"}</code> <code>None</code> <code>cache</code> <code>dict \\| None</code> Cache configuration for results. Example: <code>{\"recompute\": [\"node1\", \"final_node\"]}</code> <code>None</code> <code>executor_cfg</code> <code>str \\| dict \\| ExecutorConfig \\| None</code> Execution configuration, can be: - <code>str</code>: Executor name, e.g. \"threadpool\", \"local\" - <code>dict</code>: Raw config, e.g. <code>{\"type\": \"threadpool\", \"max_workers\": 4}</code> - <code>ExecutorConfig</code>: Structured config object <code>None</code> <code>with_adapter_cfg</code> <code>dict \\| WithAdapterConfig \\| None</code> Adapter settings for pipeline execution. Example: <code>{\"opentelemetry\": True, \"tracker\": False}</code> <code>None</code> <code>pipeline_adapter_cfg</code> <code>dict \\| PipelineAdapterConfig \\| None</code> Pipeline-specific adapter settings. Example: <code>{\"tracker\": {\"project_id\": \"123\", \"tags\": {\"env\": \"prod\"}}}</code> <code>None</code> <code>project_adapter_cfg</code> <code>dict \\| ProjectAdapterConfig \\| None</code> Project-level adapter settings. Example: <code>{\"opentelemetry\": {\"host\": \"http://localhost:4317\"}}</code> <code>None</code> <code>adapter</code> <code>dict[str, Any] \\| None</code> Custom adapter instance for pipeline Example: <code>{\"ray_graph_adapter\": RayGraphAdapter()}</code> <code>None</code> <code>reload</code> <code>bool</code> Force reload of pipeline configuration. <code>False</code> <code>log_level</code> <code>str \\| None</code> Logging level for the execution. Valid values: \"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\" <code>None</code> <code>max_retries</code> <code>int \\| None</code> Maximum number of retries for execution. <code>None</code> <code>retry_delay</code> <code>float \\| None</code> Delay between retries in seconds. <code>None</code> <code>jitter_factor</code> <code>float \\| None</code> Random jitter factor to add to retry delay <code>None</code> <code>retry_exceptions</code> <code>tuple \\| list \\| None</code> Exceptions that trigger a retry. <code>None</code> <code>on_success</code> <code>Callable \\| tuple[Callable, tuple \\| None, dict \\| None] \\| None</code> Callback to run on successful pipeline execution. <code>None</code> <code>on_failure</code> <code>Callable \\| tuple[Callable, tuple \\| None, dict \\| None] \\| None</code> Callback to run on pipeline execution failure. <code>None</code> <p>Returns: <code>dict[str, Any]</code> - Pipeline execution results, mapping output variable names to their computed values.</p> <p>Raises: - <code>ValueError</code>: If pipeline name doesn't exist or configuration is invalid. - <code>ImportError</code>: If pipeline module cannot be imported. - <code>RuntimeError</code>: If execution fails due to pipeline or adapter errors.</p>"},{"location":"api/pipelinemanager/#example","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\nmanager = PipelineManager()\n\n# Simple execution\nresult = manager.run(\"my_pipeline\")\n\n# With custom inputs\nresult = manager.run(\n    \"ml_pipeline\",\n    inputs={\"data_date\": \"2025-01-01\"},\n    final_vars=[\"model\", \"metrics\"]\n)\n</code></pre>"},{"location":"api/pipelinemanager/#new","title":"new","text":"<pre><code>new(self, name: str, overwrite: bool = False)\n</code></pre> <p>Create a new pipeline with the given name.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name for the new pipeline. Must be a valid Python identifier. <code>overwrite</code> <code>bool</code> Whether to overwrite existing pipeline with same name. <code>False</code> <p>Returns: <code>None</code></p> <p>Raises: - <code>ValueError</code>: If name is invalid or pipeline exists and overwrite=<code>False</code>. - <code>RuntimeError</code>: If file creation fails. - <code>PermissionError</code>: If lacking write permissions.</p>"},{"location":"api/pipelinemanager/#example_1","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\n# Create new pipeline\nmanager = PipelineManager()\nmanager.new(\"data_transformation\")\n\n# Overwrite existing pipeline\nmanager.new(\"data_transformation\", overwrite=True)\n</code></pre>"},{"location":"api/pipelinemanager/#delete","title":"delete","text":"<pre><code>delete(self, name: str)\n</code></pre> <p>Delete an existing pipeline.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to delete. <p>Returns: <code>None</code></p> <p>Raises: - <code>FileNotFoundError</code>: If the pipeline does not exist. - <code>RuntimeError</code>: If deletion fails.</p>"},{"location":"api/pipelinemanager/#example_2","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\nmanager = PipelineManager()\nmanager.delete(\"old_pipeline\")\n</code></pre>"},{"location":"api/pipelinemanager/#show_pipelines","title":"show_pipelines","text":"<pre><code>show_pipelines(self, format: str = \"table\")\n</code></pre> <p>Display a summary of all available pipelines.</p> Parameter Type Description Default <code>format</code> <code>str</code> Output format for the list (\"table\", \"json\", \"yaml\"). <code>\"table\"</code> <p>Returns: <code>None</code></p>"},{"location":"api/pipelinemanager/#example_3","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\nmanager = PipelineManager()\n\n# Show pipelines in table format (default)\nmanager.show_pipelines()\n\n# Show pipelines in JSON format\nmanager.show_pipelines(format=\"json\")\n</code></pre>"},{"location":"api/pipelinemanager/#add_hook","title":"add_hook","text":"<pre><code>add_hook(self, name: str, type: HookType, to: str, function_name: str)\n</code></pre> <p>Add a hook to a specific pipeline.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to add the hook to. <code>type</code> <code>HookType</code> Type of the hook (e.g., <code>HookType.MQTT_BUILD_CONFIG</code>). <code>to</code> <code>str</code> Destination of the hook (e.g., \"mqtt\"). <code>function_name</code> <code>str</code> Name of the function to be called as the hook. <p>Returns: <code>None</code></p> <p>Raises: - <code>ValueError</code>: If the pipeline does not exist or hook type is invalid. - <code>FileExistsError</code>: If a hook with the same name and type already exists.</p>"},{"location":"api/pipelinemanager/#example_4","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager, HookType\n\nmanager = PipelineManager()\nmanager.add_hook(\n    name=\"my_pipeline\",\n    type=HookType.MQTT_BUILD_CONFIG,\n    to=\"mqtt\",\n    function_name=\"build_mqtt_config\"\n)\n</code></pre>"},{"location":"api/pipelinemanager/#remove_hook","title":"remove_hook","text":"<pre><code>remove_hook(self, name: str, type: HookType, function_name: str)\n</code></pre> <p>Remove a hook from a specific pipeline.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to remove the hook from. <code>type</code> <code>HookType</code> Type of the hook to remove. <code>function_name</code> <code>str</code> Name of the function that was used as the hook. <p>Returns: <code>None</code></p> <p>Raises: <code>FileNotFoundError</code>: If the pipeline or hook does not exist.</p>"},{"location":"api/pipelinemanager/#example_5","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager, HookType\n\nmanager = PipelineManager()\nmanager.remove_hook(\n    name=\"my_pipeline\",\n    type=HookType.MQTT_BUILD_CONFIG,\n    function_name=\"build_mqtt_config\"\n)\n</code></pre>"},{"location":"api/pipelinemanager/#import_pipeline","title":"import_pipeline","text":"<pre><code>import_pipeline(self, name: str, src_base_dir: str, src_fs: AbstractFileSystem | None = None, src_storage_options: dict | BaseStorageOptions | None = None, overwrite: bool = False)\n</code></pre> <p>Import a pipeline from another FlowerPower project.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name for the new pipeline in the current project. <code>src_base_dir</code> <code>str</code> Source FlowerPower project directory or URI. Examples: - Local: <code>\"/path/to/other/project\"</code> - S3: <code>\"s3://bucket/project\"</code> - GitHub: <code>\"github://org/repo/project\"</code> <code>src_fs</code> <code>AbstractFileSystem \\| None</code> Pre-configured source filesystem. Example: <code>S3FileSystem(anon=False)</code> <code>None</code> <code>src_storage_options</code> <code>dict \\| BaseStorageOptions \\| None</code> Options for source filesystem access. Example: <code>{\"key\": \"ACCESS_KEY\", \"secret\": \"SECRET_KEY\"}</code> <code>None</code> <code>overwrite</code> <code>bool</code> Whether to replace existing pipeline if name exists. <code>False</code> <p>Returns: <code>None</code></p> <p>Raises: - <code>ValueError</code>: If pipeline name exists and <code>overwrite=False</code>. - <code>FileNotFoundError</code>: If source pipeline not found. - <code>RuntimeError</code>: If import fails.</p>"},{"location":"api/pipelinemanager/#example_6","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\nfrom s3fs import S3FileSystem\n\nmanager = PipelineManager()\n\n# Import from local filesystem\nmanager.import_pipeline(\n    \"new_pipeline\",\n    \"/path/to/other/project\"\n)\n\n# Import from S3 with custom filesystem\ns3 = S3FileSystem(anon=False)\nmanager.import_pipeline(\n    \"s3_pipeline\",\n    \"s3://bucket/project\",\n    src_fs=s3\n)\n</code></pre>"},{"location":"api/pipelinemanager/#import_many","title":"import_many","text":"<pre><code>import_many(self, names: list[str], src_base_dir: str, src_fs: AbstractFileSystem | None = None, src_storage_options: dict | BaseStorageOptions | None = None, overwrite: bool = False)\n</code></pre> <p>Import multiple pipelines from another FlowerPower project.</p> Parameter Type Description Default <code>names</code> <code>list[str]</code> List of pipeline names to import. <code>src_base_dir</code> <code>str</code> Source FlowerPower project directory or URI. Examples: - Local: <code>\"/path/to/other/project\"</code> - S3: <code>\"s3://bucket/project\"</code> - GitHub: <code>\"github://org/repo/project\"</code> <code>src_fs</code> <code>AbstractFileSystem \\| None</code> Pre-configured source filesystem. Example: <code>S3FileSystem(anon=False)</code> <code>None</code> <code>src_storage_options</code> <code>dict \\| BaseStorageOptions \\| None</code> Options for source filesystem access. Example: <code>{\"key\": \"ACCESS_KEY\", \"secret\": \"SECRET_KEY\"}</code> <code>None</code> <code>overwrite</code> <code>bool</code> Whether to replace existing pipelines if names exist. <code>False</code> <p>Returns: <code>None</code></p> <p>Raises: - <code>ValueError</code>: If any pipeline name exists and <code>overwrite=False</code>. - <code>FileNotFoundError</code>: If any source pipeline not found. - <code>RuntimeError</code>: If import fails.</p>"},{"location":"api/pipelinemanager/#example_7","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\nmanager = PipelineManager()\n\n# Import multiple pipelines\nmanager.import_many(\n    names=[\"pipeline1\", \"pipeline2\"],\n    src_base_dir=\"/path/to/other/project\"\n)\n\n# Import multiple pipelines from S3\nmanager.import_many(\n    names=[\"s3_pipeline_a\", \"s3_pipeline_b\"],\n    src_base_dir=\"s3://bucket/source\",\n    src_storage_options={\n        \"key\": \"ACCESS_KEY\",\n        \"secret\": \"SECRET_KEY\"\n    }\n)\n</code></pre>"},{"location":"api/pipelinemanager/#export_pipeline","title":"export_pipeline","text":"<pre><code>export_pipeline(self, name: str, dest_base_dir: str, dest_fs: AbstractFileSystem | None = None, dest_storage_options: dict | BaseStorageOptions | None = None, overwrite: bool = False)\n</code></pre> <p>Export a pipeline to another FlowerPower project.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to export. <code>dest_base_dir</code> <code>str</code> Destination FlowerPower project directory or URI. Examples: - Local: <code>\"/path/to/backup\"</code> - S3: <code>\"s3://bucket/backups\"</code> - GCS: <code>\"gs://bucket/backups\"</code> <code>dest_fs</code> <code>AbstractFileSystem \\| None</code> Pre-configured destination filesystem. Example: <code>GCSFileSystem(project='my-project')</code> <code>None</code> <code>dest_storage_options</code> <code>dict \\| BaseStorageOptions \\| None</code> Options for destination filesystem access. Example: <code>{\"token\": \"my_token\"}</code> <code>None</code> <code>overwrite</code> <code>bool</code> Whether to replace existing pipeline in destination if name exists. <code>False</code> <p>Returns: <code>None</code></p> <p>Raises: - <code>FileNotFoundError</code>: If the pipeline does not exist in the current project. - <code>FileExistsError</code>: If destination pipeline exists and <code>overwrite=False</code>. - <code>RuntimeError</code>: If export fails.</p>"},{"location":"api/pipelinemanager/#example_8","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\nfrom gcsfs import GCSFileSystem\n\nmanager = PipelineManager()\n\n# Export to local backup\nmanager.export_pipeline(\n    \"my_pipeline\",\n    \"/path/to/backup\"\n)\n\n# Export to Google Cloud Storage\ngcs = GCSFileSystem(project='my-project')\nmanager.export_pipeline(\n    \"prod_pipeline\",\n    \"gs://my-bucket/backups\",\n    dest_fs=gcs\n)\n</code></pre>"},{"location":"api/pipelinemanager/#export_many","title":"export_many","text":"<pre><code>export_many(self, names: list[str], dest_base_dir: str, dest_fs: AbstractFileSystem | None = None, dest_storage_options: dict | BaseStorageOptions | None = None, overwrite: bool = False)\n</code></pre> <p>Export multiple pipelines to another FlowerPower project.</p> Parameter Type Description Default <code>names</code> <code>list[str]</code> List of pipeline names to export. <code>dest_base_dir</code> <code>str</code> Destination FlowerPower project directory or URI. Examples: - Local: <code>\"/path/to/backup\"</code> - S3: <code>\"s3://bucket/backups\"</code> - GCS: <code>\"gs://bucket/backups\"</code> <code>dest_fs</code> <code>AbstractFileSystem \\| None</code> Pre-configured destination filesystem. Example: <code>GCSFileSystem(project='my-project')</code> <code>None</code> <code>dest_storage_options</code> <code>dict \\| BaseStorageOptions \\| None</code> Options for destination filesystem access. Example: <code>{\"token\": \"my_token\"}</code> <code>None</code> <code>overwrite</code> <code>bool</code> Whether to replace existing pipelines in destination if names exist. <code>False</code> <p>Returns: <code>None</code></p> <p>Raises: - <code>FileNotFoundError</code>: If any pipeline does not exist in the current project. - <code>FileExistsError</code>: If any destination pipeline exists and <code>overwrite=False</code>. - <code>RuntimeError</code>: If export fails.</p>"},{"location":"api/pipelinemanager/#example_9","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\nmanager = PipelineManager()\n\n# Export multiple pipelines\nmanager.export_many(\n    names=[\"pipeline1\", \"pipeline2\"],\n    dest_base_dir=\"/path/to/backup\"\n)\n\n# Export multiple pipelines from S3\nmanager.export_many(\n    names=[\"s3_pipeline_a\", \"s3_pipeline_b\"],\n    dest_base_dir=\"s3://bucket/backups\",\n    dest_storage_options={\n        \"key\": \"ACCESS_KEY\",\n        \"secret\": \"SECRET_KEY\"\n    }\n)\n</code></pre>"},{"location":"api/pipelinemanager/#show_dag","title":"show_dag","text":"<pre><code>show_dag(self, name: str, format: str = \"png\", show_outputs: bool = False, display_html: bool = False)\n</code></pre> <p>Generate and display the Directed Acyclic Graph (DAG) of a pipeline.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to visualize. <code>format</code> <code>str</code> Output format for the DAG (\"png\", \"svg\", \"html\", \"dot\"). <code>\"png\"</code> <code>show_outputs</code> <code>bool</code> Whether to include output nodes in the DAG. <code>False</code> <code>display_html</code> <code>bool</code> Whether to display the HTML directly in the notebook (only for \"html\" format). <code>False</code> <p>Returns: <code>None</code> (displays the DAG directly or saves it to a file).</p> <p>Raises: - <code>FileNotFoundError</code>: If the pipeline does not exist. - <code>ValueError</code>: If format is invalid or visualization fails.</p>"},{"location":"api/pipelinemanager/#example_10","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\nmanager = PipelineManager()\n\n# Show DAG as PNG\nmanager.show_dag(\"my_pipeline\")\n\n# Show DAG as SVG with outputs\nmanager.show_dag(\"ml_pipeline\", format=\"svg\", show_outputs=True)\n</code></pre>"},{"location":"api/pipelinemanager/#show_execution_graph","title":"show_execution_graph","text":"<pre><code>show_execution_graph(self, name: str, format: str = \"png\", show_outputs: bool = False, display_html: bool = False, inputs: dict | None = None, config: dict | None = None)\n</code></pre> <p>Generate and display the execution graph of a pipeline, considering inputs and configuration.</p> Parameter Type Description Default <code>name</code> <code>str</code> Name of the pipeline to visualize. <code>format</code> <code>str</code> Output format for the graph (\"png\", \"svg\", \"html\", \"dot\"). <code>\"png\"</code> <code>show_outputs</code> <code>bool</code> Whether to include output nodes in the graph. <code>False</code> <code>display_html</code> <code>bool</code> Whether to display the HTML directly in the notebook (only for \"html\" format). <code>False</code> <code>inputs</code> <code>dict \\| None</code> Input values to consider for graph generation. <code>None</code> <code>config</code> <code>dict \\| None</code> Configuration for Hamilton pipeline executor. <code>None</code> <p>Returns: <code>None</code> (displays the graph directly or saves it to a file).</p> <p>Raises: - <code>FileNotFoundError</code>: If the pipeline does not exist. - <code>ValueError</code>: If format is invalid or visualization fails.</p>"},{"location":"api/pipelinemanager/#example_11","title":"Example","text":"<pre><code>from flowerpower.pipeline import PipelineManager\n\nmanager = PipelineManager()\n\n# Show execution graph\nmanager.show_execution_graph(\"my_pipeline\", inputs={\"data_date\": \"2025-01-01\"})\n</code></pre>"},{"location":"api/rqmanager/","title":"RQManager","text":"<p>Module: <code>flowerpower.job_queue.rq.RQManager</code></p> <p>The <code>RQManager</code> is the implementation of <code>JobQueueManager</code> for Redis Queue (RQ). It handles the specifics of interacting with an RQ backend.</p>"},{"location":"api/rqmanager/#initialization","title":"Initialization","text":""},{"location":"api/rqmanager/#init","title":"init","text":"<pre><code>__init__(self, name: str, base_dir: str | None = None, backend: RQBackend | None = None, storage_options: dict | None = None, fs: AbstractFileSystem | None = None, log_level: str | None = None)\n</code></pre> <p>Initializes the <code>RQManager</code>.</p> Parameter Type Description Default <code>name</code> <code>str</code> The name of the scheduler instance. <code>base_dir</code> <code>str \\| None</code> The base directory of the project. <code>None</code> <code>backend</code> <code>RQBackend \\| None</code> An <code>RQBackend</code> instance for Redis connection configuration. <code>None</code> <code>storage_options</code> <code>dict \\| None</code> Storage options for the filesystem. <code>None</code> <code>fs</code> <code>AbstractFileSystem \\| None</code> An fsspec-compatible filesystem instance. <code>None</code> <code>log_level</code> <code>str \\| None</code> The logging level. <code>None</code>"},{"location":"api/rqmanager/#methods","title":"Methods","text":""},{"location":"api/rqmanager/#add_job","title":"add_job","text":"<pre><code>add_job(self, func: Callable, func_args: list | None = None, func_kwargs: dict | None = None, job_id: str | None = None, result_ttl: int | None = None, ttl: int | None = None, timeout: int | None = None, queue_name: str | None = None, run_at: datetime | None = None, run_in: timedelta | int | str | None = None, retry: Retry | None = None, repeat: int | None = None, meta: dict | None = None, failure_ttl: int | None = None, group_id: str | None = None, on_success: Callable | tuple[Callable, tuple | None, dict | None] | None = None, on_failure: Callable | tuple[Callable, tuple | None, dict | None] | None = None, on_stopped: Callable | tuple[Callable, tuple | None, dict | None] | None = None, **job_kwargs)\n</code></pre> <p>Adds a job to the queue for immediate or scheduled execution.</p> <p>Warning</p> <p>This method is deprecated. Use <code>enqueue</code>, <code>enqueue_in</code>, or <code>enqueue_at</code> instead.</p> Parameter Type Description Default <code>func</code> <code>Callable</code> The function to execute. <code>func_args</code> <code>list | None</code> Positional arguments for the function. <code>None</code> <code>func_kwargs</code> <code>dict | None</code> Keyword arguments for the function. <code>None</code> <code>job_id</code> <code>str | None</code> Unique identifier for the job. <code>None</code> <code>result_ttl</code> <code>int | None</code> Time to live for job result (seconds). <code>None</code> <code>ttl</code> <code>int | None</code> Total time to live for the job (seconds). <code>None</code> <code>timeout</code> <code>int | None</code> Job execution timeout (seconds). <code>None</code> <code>queue_name</code> <code>str | None</code> The name of the RQ queue to use. <code>None</code> <code>run_at</code> <code>datetime | None</code> Specific datetime to run the job. <code>None</code> <code>run_in</code> <code>timedelta | int | str | None</code> Delay before running the job. <code>None</code> <code>retry</code> <code>Retry | None</code> Retry policy for the job. <code>None</code> <code>repeat</code> <code>int | None</code> Number of times to repeat the job. <code>None</code> <code>meta</code> <code>dict | None</code> Arbitrary metadata for the job. <code>None</code> <code>failure_ttl</code> <code>int | None</code> Time to live for failed job result (seconds). <code>None</code> <code>group_id</code> <code>str | None</code> Group ID for the job. <code>None</code> <code>on_success</code> <code>Callable | tuple[Callable, tuple | None, dict | None] | None</code> Callback on job success. <code>None</code> <code>on_failure</code> <code>Callable | tuple[Callable, tuple | None, dict | None] | None</code> Callback on job failure. <code>None</code> <code>on_stopped</code> <code>Callable | tuple[Callable, tuple | None, dict | None] | None</code> Callback on job stopped. <code>None</code> <code>**job_kwargs</code> <code>Any</code> Additional keyword arguments for RQ's <code>Job</code> class. <p>Returns: <code>Job</code> - The enqueued job object.</p> <p>Raises: <code>ValueError</code>: If required parameters are missing or invalid.</p>"},{"location":"api/rqmanager/#example","title":"Example","text":"<pre><code>from flowerpower.job_queue.rq import RQManager\nfrom datetime import datetime, timedelta\n\nmanager = RQManager(name=\"my_rq_manager\")\n\n# Enqueue a simple job\ndef my_task(x, y):\n    return x + y\n\njob = manager.add_job(my_task, func_args=[1, 2], queue_name=\"default\")\nprint(f\"Enqueued job {job.id}\")\n\n# Schedule a job to run in 5 minutes\njob = manager.add_job(my_task, func_args=[3, 4], run_in=timedelta(minutes=5), queue_name=\"default\")\n\n# Schedule a job to run at a specific time\ntarget_time = datetime(2025, 1, 1, 10, 0, 0)\njob = manager.add_job(my_task, func_args=[5, 6], run_at=target_time, queue_name=\"default\")\n</code></pre>"},{"location":"api/rqmanager/#start_worker","title":"start_worker","text":"<pre><code>start_worker(self, background: bool = False, queue_names: list[str] | None = None, with_scheduler: bool = False, **kwargs)\n</code></pre> <p>Starts a worker process for the job queue.</p> Parameter Type Description Default <code>background</code> <code>bool</code> If <code>True</code>, runs the worker in the background. <code>False</code> <code>queue_names</code> <code>list[str] \\| None</code> A list of RQ queues to listen to. Defaults to all queues. <code>None</code> <code>with_scheduler</code> <code>bool</code> If <code>True</code>, the worker also processes scheduled jobs. <code>False</code> <code>**kwargs</code> <code>Any</code> Additional arguments for RQ's <code>Worker</code> class. <p>Returns: <code>None</code></p> <p>Raises: <code>RuntimeError</code>: If the worker fails to start.</p>"},{"location":"api/rqmanager/#example_1","title":"Example","text":"<pre><code>from flowerpower.job_queue.rq import RQManager\n\nmanager = RQManager(name=\"my_rq_manager\")\n\n# Start a worker in the foreground, listening to the 'default' queue\nmanager.start_worker(queue_names=[\"default\"])\n\n# Start a worker in the background with scheduler enabled\nmanager.start_worker(background=True, with_scheduler=True)\n</code></pre>"}]}